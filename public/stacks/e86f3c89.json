{
  "info": {
    "id": "e86f3c89",
    "title": "Algèbre bilinéaire - preuves (A)",
    "type": "proofs",
    "level": "regular",
    "chapter": "Algèbre bilinéaire",
    "course": "Algèbre",
    "tags": [
      "Algèbre bilinéaire",
      "Dualité",
      "Formes bilinéaires",
      "Formes quadratiques",
      "Espaces euclidiens",
      "Diagonalisation",
      "Gram-Schmidt"
    ],
    "count": 10
  },
  "cards": [
    {
      "id": "1",
      "stackId": "e86f3c89",
      "content": "#### Formule de Polarisation\n\nProuver que pour toute forme quadratique $q$ associée à une forme bilinéaire symétrique $\\varphi$ sur un espace vectoriel $V$ (où le corps $K$ est de caractéristique différente de 2), on peut retrouver $\\varphi$ par la formule :\n\n$$\\varphi(u, v) = \\frac{1}{2} (q(u + v) - q(u) - q(v))$$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nRappelez-vous la définition d'une forme quadratique : $q(x) = \\varphi(x, x)$.\n\nDéveloppez l'expression $q(u + v) = \\varphi(u + v, u + v)$ en utilisant la bilinéarité (linéarité par rapport aux deux variables) et la symétrie de $\\varphi$.\n\n</details>",
      "solution": "\n\nSoit $\\varphi$ une forme bilinéaire symétrique et $q$ la forme quadratique associée, définie par $q(x) = \\varphi(x, x)$.\n\n**Étape 1 : Développement de $q(u+v)$**\n\nCalculons $q(u + v)$ en utilisant la définition :\n\n$$q(u + v) = \\varphi(u + v, u + v)$$\n\nPar la propriété de bilinéarité (distributivité), nous développons l'expression :\n\n$$\\varphi(u + v, u + v) = \\varphi(u, u) + \\varphi(u, v) + \\varphi(v, u) + \\varphi(v, v)$$\n\n**Étape 2 : Utilisation de la symétrie**\n\nComme $\\varphi$ est symétrique, on a $\\varphi(v, u) = \\varphi(u, v)$. De plus, par définition, $\\varphi(u, u) = q(u)$ et $\\varphi(v, v) = q(v)$.\n\nL'expression devient :\n\n$$q(u + v) = q(u) + 2\\varphi(u, v) + q(v)$$\n\n**Conclusion :**\n\nEn isolant le terme $\\varphi(u, v)$, on obtient :\n\n$$2\\varphi(u, v) = q(u + v) - q(u) - q(v)$$\n\n$$\\varphi(u, v) = \\frac{1}{2} (q(u + v) - q(u) - q(v))$$\n\n",
      "options": []
    },
    {
      "id": "2",
      "stackId": "e86f3c89",
      "content": "#### Changement de base pour une forme bilinéaire\n\nSoit $\\varphi$ une forme bilinéaire sur $V$. Soient $\\mathfrak{B}$ et $\\mathcal{C}$ deux bases de $V$, et $P$ la matrice de passage de $\\mathfrak{B}$ à $\\mathcal{C}$.\n\nProuver que si $A$ est la matrice de $\\varphi$ dans la base $\\mathfrak{B}$ et $A'$ est la matrice de $\\varphi$ dans la base $\\mathcal{C}$, alors :\n\n$$A' = {}^t P A P$$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nUtilisez l'expression matricielle de la forme bilinéaire. Si $X$ et $Y$ sont les vecteurs colonnes des coordonnées dans $\\mathfrak{B}$, et $X', Y'$ ceux dans $\\mathcal{C}$, rappelez-vous la relation de changement de base : $X = PX'$.\n\nSubstituez cette relation dans l'expression $\\varphi(u, v) = {}^t X A Y$.\n\n</details>",
      "solution": "\n\nSoient $u, v$ deux vecteurs de $V$.\n\nNotons $X, Y$ leurs matrices colonnes de coordonnées dans la base $\\mathfrak{B}$, et $X', Y'$ leurs coordonnées dans la base $\\mathcal{C}$.\n\n**Étape 1 : Expression matricielle et changement de coordonnées**\n\nLa valeur de la forme bilinéaire peut être calculée dans la base $\\mathfrak{B}$ par :\n\n$$\\varphi(u, v) = {}^t X A Y$$\n\nLa formule de changement de base pour les vecteurs est $X = P X'$ et $Y = P Y'$.\n\n**Étape 2 : Substitution**\n\nRemplaçons $X$ et $Y$ dans l'expression de $\\varphi$ :\n\n$$\\varphi(u, v) = {}^t (P X') A (P Y')$$\n\nUtilisons la propriété de la transposition $^t(MN) = {}^tN {}^tM$ :\n\n$$\\varphi(u, v) = ({}^t X' {}^t P) A (P Y') = {}^t X' ({}^t P A P) Y'$$\n\n**Conclusion :**\n\nPar définition de la matrice $A'$ dans la base $\\mathcal{C}$, on doit avoir $\\varphi(u, v) = {}^t X' A' Y'$ pour tous vecteurs $u, v$ (donc pour tous $X', Y'$).\n\nEn identifiant les termes, on obtient :\n\n$$A' = {}^t P A P$$\n\n",
      "options": []
    },
    {
      "id": "3",
      "stackId": "e86f3c89",
      "content": "#### Inégalité de Cauchy-Schwarz\n\nSoit $E$ un espace euclidien muni d'un produit scalaire noté $(x | y)$ et de la norme associée $\\|x\\| = \\sqrt{(x | x)}$.\n\nProuver que pour tous $x, y \\in E$ :\n\n$$|(x | y)| \\le \\|x\\| \\cdot \\|y\\|$$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nConsidérez la fonction réelle $P(t) = \\|x + ty\\|^2$ pour un réel $t$.\n\nCette fonction est toujours positive ou nulle. Développez-la pour obtenir un polynôme du second degré en $t$. Que pouvez-vous dire de son discriminant ?\n\n</details>",
      "solution": "\n\nSoient $x, y \\in E$.\n\n**Étape 1 : Cas trivial**\n\nSi $y = 0$, alors $(x | 0) = 0$ et $\\|x\\| \\cdot \\|0\\| = 0$. L'égalité $0 \\le 0$ est vérifiée. Supposons donc $y \\ne 0$.\n\n**Étape 2 : Étude du polynôme quadratique**\n\nPour tout réel $t \\in \\mathbb{R}$, considérons le vecteur $x + ty$. Par la propriété de positivité du produit scalaire :\n\n$$\\|x + ty\\|^2 = (x + ty | x + ty) \\ge 0$$\n\nDéveloppons cette expression grâce à la bilinéarité et la symétrie :\n\n$$(x | x) + 2t(x | y) + t^2(y | y) \\ge 0$$\n\n$$\\|x\\|^2 + 2t(x | y) + t^2\\|y\\|^2 \\ge 0$$\n\n**Étape 3 : Discriminant**\n\nIl s'agit d'un polynôme du second degré en $t$ de la forme $At^2 + Bt + C$ avec $A = \\|y\\|^2$, $B = 2(x | y)$ et $C = \\|x\\|^2$.\n\nPuisque ce polynôme est toujours positif ou nul pour tout $t \\in \\mathbb{R}$, il ne peut pas avoir deux racines réelles distinctes. Son discriminant $\\Delta$ doit donc être négatif ou nul ($\\Delta \\le 0$).\n\n$$\\Delta = B^2 - 4AC = (2(x | y))^2 - 4\\|y\\|^2 \\|x\\|^2 \\le 0$$\n\n$$4(x | y)^2 - 4\\|x\\|^2 \\|y\\|^2 \\le 0$$\n\n**Conclusion :**\n\nEn divisant par 4 et en réarrangeant :\n\n$$(x | y)^2 \\le \\|x\\|^2 \\|y\\|^2$$\n\nEn prenant la racine carrée (croissante sur $\\mathbb{R}^+$) :\n\n$$|(x | y)| \\le \\|x\\| \\cdot \\|y\\|$$\n\n",
      "options": []
    },
    {
      "id": "4",
      "stackId": "e86f3c89",
      "content": "#### Coordonnées dans une base orthonormée\n\nSoit $(e_1, \\dots, e_n)$ une base orthonormée d'un espace euclidien $E$.\n\nProuver que pour tout vecteur $x \\in E$, ses coordonnées sont données par les produits scalaires avec les vecteurs de la base, c'est-à-dire :\n\n$$x = \\sum_{i=1}^n (x | e_i) e_i$$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nÉcrivez $x$ comme une combinaison linéaire quelconque $x = \\sum_{j=1}^n \\lambda_j e_j$.\n\nCalculez le produit scalaire $(x | e_i)$ en utilisant cette expression et la propriété d'orthonormalité $(e_j | e_i) = \\delta_{ji}$.\n\n</details>",
      "solution": "\n\nSoit $x \\in E$. Puisque $(e_1, \\dots, e_n)$ est une base, il existe des scalaires uniques $\\lambda_1, \\dots, \\lambda_n$ tels que :\n\n$$x = \\sum_{j=1}^n \\lambda_j e_j$$\n\n**Étape 1 : Calcul du produit scalaire**\n\nFixons un indice $i \\in \\{1, \\dots, n\\}$ et calculons le produit scalaire $(x | e_i)$ :\n\n$$(x | e_i) = \\left( \\sum_{j=1}^n \\lambda_j e_j \\;\\Bigg|\\; e_i \\right)$$\n\n**Étape 2 : Utilisation de la linéarité**\n\nPar linéarité à gauche du produit scalaire :\n\n$$(x | e_i) = \\sum_{j=1}^n \\lambda_j (e_j | e_i)$$\n\n**Étape 3 : Utilisation de l'orthonormalité**\n\nLa famille est orthonormée, donc $(e_j | e_i) = \\delta_{ji}$ (vaut 1 si $j=i$, 0 sinon).\n\nDans la somme, tous les termes sont nuls sauf celui où $j=i$ :\n\n$$(x | e_i) = \\lambda_i (e_i | e_i) = \\lambda_i \\cdot 1 = \\lambda_i$$\n\n**Conclusion :**\n\nNous avons montré que le coefficient $\\lambda_i$ est exactement $(x | e_i)$. Ainsi :\n\n$$x = \\sum_{i=1}^n (x | e_i) e_i$$\n\n",
      "options": []
    },
    {
      "id": "5",
      "stackId": "e86f3c89",
      "content": "#### Orthogonalité des sous-espaces propres (Matrices symétriques)\n\nSoit $A$ une matrice symétrique réelle (${}^tA = A$) représentant un endomorphisme $u$ dans une base orthonormée.\n\nProuver que si $v_1$ et $v_2$ sont deux vecteurs propres de $A$ associés à des valeurs propres distinctes $\\lambda_1$ et $\\lambda_2$, alors $v_1$ et $v_2$ sont orthogonaux.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nConsidérez le produit scalaire $(Av_1 | v_2)$ (qui matriciellement est ${}^t(Av_1)v_2$).\n\nCalculez ce produit de deux façons :\n\n1. En utilisant $Av_1 = \\lambda_1 v_1$.\n2. En utilisant la propriété de symétrie $(Av_1 | v_2) = (v_1 | Av_2)$ et $Av_2 = \\lambda_2 v_2$.\n\nComparez les résultats.\n\n</details>",
      "solution": "\n\nSoient $v_1, v_2$ tels que $Av_1 = \\lambda_1 v_1$ et $Av_2 = \\lambda_2 v_2$ avec $\\lambda_1 \\ne \\lambda_2$.\n\nDans $\\mathbb{R}^n$, le produit scalaire canonique est $(x|y) = {}^tx y$.\n\n**Étape 1 : Calcul du produit scalaire $(Av_1 | v_2)$**\n\nEn remplaçant $Av_1$ :\n\n$$(Av_1 | v_2) = (\\lambda_1 v_1 | v_2) = \\lambda_1 (v_1 | v_2)$$\n\n**Étape 2 : Utilisation de la symétrie de la matrice**\n\nPour une matrice symétrique réelle $A$, on a l'identité $(Ax | y) = (x | Ay)$ pour tout $x, y$.\n\nEn effet : ${}^t(Ax)y = {}^tx {}^tA y = {}^tx A y = (x | Ay)$.\n\nDonc :\n\n$$(Av_1 | v_2) = (v_1 | Av_2)$$\n\nEn remplaçant $Av_2$ :\n\n$$(v_1 | Av_2) = (v_1 | \\lambda_2 v_2) = \\lambda_2 (v_1 | v_2)$$\n\n**Étape 3 : Comparaison**\n\nNous avons obtenu :\n\n$$\\lambda_1 (v_1 | v_2) = \\lambda_2 (v_1 | v_2)$$\n\nCe qui équivaut à :\n\n$$(\\lambda_1 - \\lambda_2) (v_1 | v_2) = 0$$\n\n**Conclusion :**\n\nPuisque $\\lambda_1 \\ne \\lambda_2$, le terme $(\\lambda_1 - \\lambda_2)$ n'est pas nul. On peut diviser par ce terme, ce qui impose :\n\n$$(v_1 | v_2) = 0$$\n\nLes vecteurs propres sont donc orthogonaux.\n\n",
      "options": []
    },
    {
      "id": "6",
      "stackId": "e86f3c89",
      "content": "#### Minimisation de la distance (Projection Orthogonale)\n\nSoit $F$ un sous-espace vectoriel d'un espace euclidien $E$. Soit $x \\in E$ et $\\pi_F(x)$ sa projection orthogonale sur $F$.\n\nProuver que $\\pi_F(x)$ est la meilleure approximation de $x$ dans $F$, c'est-à-dire :\n\n$$\\forall y \\in F, \\quad \\|x - \\pi_F(x)\\| \\le \\|x - y\\|$$\n\net que l'égalité n'a lieu que si $y = \\pi_F(x)$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nÉcrivez le vecteur différence $x - y$ comme $(x - \\pi_F(x)) + (\\pi_F(x) - y)$.\n\nRemarquez que le premier terme est dans $F^\\perp$ et le second est dans $F$.\n\nAppliquez le théorème de Pythagore.\n\n</details>",
      "solution": "\n\nSoit $y$ un vecteur quelconque de $F$.\n\n**Étape 1 : Décomposition du vecteur**\n\nIntroduisons $\\pi_F(x)$ dans la norme que nous voulons minimiser :\n\n$$x - y = (x - \\pi_F(x)) + (\\pi_F(x) - y)$$\n\nPosons $u = x - \\pi_F(x)$ et $v = \\pi_F(x) - y$.\n\n**Étape 2 : Vérification de l'orthogonalité**\n\n*   Le vecteur $u = x - \\pi_F(x)$ appartient à $F^\\perp$ par définition de la projection orthogonale.\n*   Le vecteur $v = \\pi_F(x) - y$ appartient à $F$ car $\\pi_F(x) \\in F$ et $y \\in F$, et $F$ est un sous-espace vectoriel.\n\nDonc $u$ et $v$ sont orthogonaux : $(u | v) = 0$.\n\n**Étape 3 : Théorème de Pythagore**\n\nPuisque $u \\perp v$, on a :\n\n$$\\|x - y\\|^2 = \\|u + v\\|^2 = \\|u\\|^2 + \\|v\\|^2$$\n\n$$\\|x - y\\|^2 = \\|x - \\pi_F(x)\\|^2 + \\|\\pi_F(x) - y\\|^2$$\n\n**Conclusion :**\n\nComme $\\|\\pi_F(x) - y\\|^2 \\ge 0$, on obtient directement :\n\n$$\\|x - y\\|^2 \\ge \\|x - \\pi_F(x)\\|^2$$\n\nDonc $\\|x - y\\| \\ge \\|x - \\pi_F(x)\\|$.\n\nL'égalité a lieu si et seulement si le terme positif ajouté est nul, c'est-à-dire $\\|\\pi_F(x) - y\\|^2 = 0$, soit $y = \\pi_F(x)$.\n\n",
      "options": []
    },
    {
      "id": "7",
      "stackId": "e86f3c89",
      "content": "#### Caractérisation des isométries et produit scalaire\n\nSoit $u$ un endomorphisme d'un espace euclidien $E$.\n\nProuver que $u$ conserve la norme ($\\forall x, \\|u(x)\\| = \\|x\\|$) si et seulement si $u$ conserve le produit scalaire ($\\forall x, y, (u(x) | u(y)) = (x | y)$).\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\n*   Pour le sens \"conserve le produit scalaire $\\implies$ conserve la norme\", c'est immédiat par définition de la norme.\n*   Pour le sens inverse, utilisez l'identité de polarisation qui exprime le produit scalaire en fonction de la norme : $(x|y) = \\frac{1}{2}(\\|x+y\\|^2 - \\|x\\|^2 - \\|y\\|^2)$.\n\n</details>",
      "solution": "\n\n**Sens direct ($\\Longleftarrow$) :**\n\nSupposons que $u$ conserve le produit scalaire : $\\forall x, y \\in E, (u(x) | u(y)) = (x | y)$.\n\nEn prenant $y = x$, on obtient :\n\n$$(u(x) | u(x)) = (x | x) \\implies \\|u(x)\\|^2 = \\|x\\|^2$$\n\nComme la norme est positive, $\\|u(x)\\| = \\|x\\|$.\n\n**Sens réciproque ($\\Longrightarrow$) :**\n\nSupposons que $u$ conserve la norme : $\\forall v \\in E, \\|u(v)\\| = \\|v\\|$.\n\nUtilisons l'identité de polarisation pour le produit scalaire réel :\n\n$$(x | y) = \\frac{1}{2} \\left( \\|x+y\\|^2 - \\|x\\|^2 - \\|y\\|^2 \\right)$$\n\nCalculons $(u(x) | u(y))$ :\n\n$$(u(x) | u(y)) = \\frac{1}{2} \\left( \\|u(x)+u(y)\\|^2 - \\|u(x)\\|^2 - \\|u(y)\\|^2 \\right)$$\n\nPar linéarité de $u$, $u(x)+u(y) = u(x+y)$, donc :\n\n$$(u(x) | u(y)) = \\frac{1}{2} \\left( \\|u(x+y)\\|^2 - \\|u(x)\\|^2 - \\|u(y)\\|^2 \\right)$$\n\nPar l'hypothèse de conservation de la norme, $\\|u(v)\\| = \\|v\\|$ pour tout $v$, donc :\n\n$$(u(x) | u(y)) = \\frac{1}{2} \\left( \\|x+y\\|^2 - \\|x\\|^2 - \\|y\\|^2 \\right)$$\n\nLe membre de droite est exactement la définition de $(x | y)$.\n\nDonc $(u(x) | u(y)) = (x | y)$.\n\n",
      "options": []
    },
    {
      "id": "8",
      "stackId": "e86f3c89",
      "content": "#### Caractérisation des matrices orthogonales\n\nProuver qu'une matrice carrée réelle $M$ est orthogonale (c'est-à-dire que ses colonnes forment une base orthonormée pour le produit scalaire canonique) si et seulement si :\n\n$${}^t M M = I_n$$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nNotez $C_1, \\dots, C_n$ les colonnes de $M$.\n\nExprimez l'élément $(i, j)$ de la matrice produit ${}^t M M$ en fonction des colonnes de $M$. Rappelez-vous que le produit scalaire canonique de deux vecteurs colonnes $U$ et $V$ est ${}^t U V$.\n\n</details>",
      "solution": "\n\nSoit $M \\in M_n(\\mathbb{R})$. Notons $C_1, \\dots, C_n$ les vecteurs colonnes de $M$.\n\nCalculons le produit $P = {}^t M M$.\n\n**Étape 1 : Expression des coefficients du produit**\n\nL'élément à la ligne $i$ et colonne $j$ de la matrice $P$, noté $P_{ij}$, est le produit de la ligne $i$ de ${}^t M$ par la colonne $j$ de $M$.\n\nLa ligne $i$ de ${}^t M$ est la transposée de la colonne $i$ de $M$, soit ${}^t C_i$.\n\nDonc :\n\n$$P_{ij} = {}^t C_i C_j$$\n\nOr, pour le produit scalaire canonique sur $\\mathbb{R}^n$, on a $(C_i | C_j) = {}^t C_i C_j$.\n\nAinsi, $P_{ij} = (C_i | C_j)$.\n\n**Étape 2 : Condition d'orthonormalité**\n\nLa famille des colonnes $(C_1, \\dots, C_n)$ est une base orthonormée si et seulement si :\n\n$$(C_i | C_j) = \\delta_{ij} = \\begin{cases} 1 & \\text{si } i=j \\\\ 0 & \\text{si } i \\ne j \\end{cases}$$\n\n**Conclusion :**\n\nCette condition est équivalente à dire que $P_{ij} = \\delta_{ij}$ pour tout $i, j$, ce qui signifie exactement que la matrice $P$ est la matrice identité $I_n$.\n\nD'où l'équivalence :\n\n$$(C_1, \\dots, C_n) \\text{ est orthonormée} \\iff {}^t M M = I_n$$\n\n",
      "options": []
    },
    {
      "id": "9",
      "stackId": "e86f3c89",
      "content": "#### Dimension de l'orthogonal\n\nSoit $F$ un sous-espace vectoriel d'un espace euclidien $E$ de dimension finie $n$.\n\nProuver que :\n\n$$\\dim(F^\\perp) = n - \\dim(F)$$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nConsidérez une base orthonormée $(e_1, \\dots, e_p)$ de $F$ (que l'on peut obtenir par Gram-Schmidt).\n\nComplétez cette base en une base orthonormée $(e_1, \\dots, e_n)$ de $E$ entier.\n\nMontrez que $(e_{p+1}, \\dots, e_n)$ est une base de $F^\\perp$.\n\n</details>",
      "solution": "\n\nSoit $p = \\dim(F)$.\n\n**Étape 1 : Base adaptée**\n\nIl existe une base orthonormée de $F$, notons-la $(e_1, \\dots, e_p)$.\n\nD'après le théorème de la base incomplète (version orthonormée), on peut compléter cette famille en une base orthonormée $\\mathfrak{B} = (e_1, \\dots, e_p, e_{p+1}, \\dots, e_n)$ de l'espace entier $E$.\n\n**Étape 2 : Identification de $F^\\perp$**\n\nMontrons que $G = \\text{Vect}(e_{p+1}, \\dots, e_n)$ est égal à $F^\\perp$.\n\n*   **Inclusion $G \\subset F^\\perp$ :**\n\n    Soit $v \\in G$. $v$ est combinaison linéaire de $e_{p+1}, \\dots, e_n$.\n\n    Pour tout $u \\in F$, $u$ est combinaison linéaire de $e_1, \\dots, e_p$.\n\n    Comme la base $\\mathfrak{B}$ est orthonormée, tout vecteur de $\\{e_{p+1}, \\dots, e_n\\}$ est orthogonal à tout vecteur de $\\{e_1, \\dots, e_p\\}$. Par bilinéarité, $v \\perp u$. Donc $v \\in F^\\perp$.\n\n*   **Dimension :**\n\n    La famille $(e_{p+1}, \\dots, e_n)$ est libre (sous-famille d'une base) et engendre $G$. Donc $\\dim(G) = n - p$.\n\n**Étape 3 : Argument de somme directe**\n\nOn sait que $F \\cap F^\\perp = \\{0\\}$ (si un vecteur est dans $F$ et orthogonal à $F$, il est orthogonal à lui-même, donc nul par définition du produit scalaire défini positif).\n\nDonc $\\dim(F \\oplus F^\\perp) = \\dim(F) + \\dim(F^\\perp) \\le n$.\n\nComme $G \\subset F^\\perp$, on a $\\dim(F^\\perp) \\ge n - p$.\n\nEn réalité, dans un espace euclidien, $E = F \\oplus F^\\perp$.\n\nTout $x$ s'écrit $x = \\sum_{i=1}^n (x|e_i)e_i = \\underbrace{\\sum_{i=1}^p (x|e_i)e_i}_{\\in F} + \\underbrace{\\sum_{i=p+1}^n (x|e_i)e_i}_{\\in G}$.\n\nComme $x$ quelconque se décompose, $F^\\perp$ est exactement $G$.\n\n**Conclusion :**\n\n$$\\dim(F^\\perp) = \\dim(G) = n - p = n - \\dim(F)$$\n\n",
      "options": []
    },
    {
      "id": "10",
      "stackId": "e86f3c89",
      "content": "#### Base Duale\n\nSoit $V$ un espace vectoriel de dimension $n$ et $\\mathfrak{B} = (e_1, \\dots, e_n)$ une base de $V$.\n\nProuver qu'il existe une unique famille de formes linéaires $(\\varphi_1, \\dots, \\varphi_n)$ telle que $\\varphi_i(e_j) = \\delta_{i,j}$, et que cette famille forme une base de $V^*$ (l'espace dual).\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nPour l'existence et l'unicité, rappelez-vous qu'une application linéaire est entièrement déterminée par ses valeurs sur une base.\n\nPour montrer que c'est une base, prouvez que la famille est libre, puis utilisez un argument de dimension ($\\dim V^* = \\dim V = n$).\n\n</details>",
      "solution": "\n\n**Étape 1 : Existence et Unicité des $\\varphi_i$**\n\nUne forme linéaire est une application linéaire de $V$ dans $K$. Une application linéaire est définie de manière unique par les images des vecteurs d'une base.\n\nPour chaque $i$ fixé, définissons $\\varphi_i$ par ses valeurs sur la base $\\mathfrak{B}$ :\n\n$$\\varphi_i(e_j) = \\delta_{i,j} = \\begin{cases} 1 & \\text{si } i=j \\\\ 0 & \\text{si } i \\ne j \\end{cases}$$\n\nCette définition assure l'existence et l'unicité de chaque $\\varphi_i$.\n\n**Étape 2 : Liberté de la famille**\n\nSoit $\\lambda_1, \\dots, \\lambda_n$ des scalaires tels que la combinaison linéaire soit nulle :\n\n$$\\sum_{i=1}^n \\lambda_i \\varphi_i = 0_{V^*}$$\n\nCela signifie que pour tout vecteur $v \\in V$, $\\sum \\lambda_i \\varphi_i(v) = 0$.\n\nAppliquons cette égalité au vecteur de base $e_k$ :\n\n$$\\sum_{i=1}^n \\lambda_i \\varphi_i(e_k) = 0$$\n\nPar définition, $\\varphi_i(e_k) = \\delta_{i,k}$. Seul le terme $i=k$ survit :\n\n$$\\lambda_k \\cdot 1 = 0 \\implies \\lambda_k = 0$$\n\nCeci étant vrai pour tout $k \\in \\{1, \\dots, n\\}$, la famille est libre.\n\n**Étape 3 : Conclusion (Base)**\n\nLa famille $(\\varphi_1, \\dots, \\varphi_n)$ est une famille libre de $n$ vecteurs dans $V^*$.\n\nComme $\\dim(V^*) = \\dim(V) = n$, toute famille libre de $n$ éléments est une base.\n\nCette base est appelée la **base duale** de $\\mathfrak{B}$.\n\n",
      "options": []
    }
  ]
}