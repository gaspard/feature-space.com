{
  "info": {
    "id": "e9d6c32b",
    "title": "Normes sur Rⁿ et suites convergentes - fiches de révision (B)",
    "type": "cards",
    "level": "pro",
    "chapter": "Normes sur Rⁿ et suites convergentes",
    "course": "Topologie",
    "tags": [
      "normes",
      "suites",
      "convergence",
      "topologie",
      "analyse"
    ],
    "count": 10
  },
  "cards": [
    {
      "id": "1",
      "stackId": "e9d6c32b",
      "content": "Démontrer que pour toute norme $N$ sur un espace vectoriel $E$, on a l'inégalité triangulaire renversée : $|N(x) - N(y)| \\le N(x - y)$ pour tous $x, y \\in E$.",
      "solution": "\n\nLa démonstration repose sur une application judicieuse de l'inégalité triangulaire standard.\n\n1.  On écrit $x$ comme $x = (x - y) + y$. En appliquant l'inégalité triangulaire, on obtient :\n\n    $N(x) = N((x - y) + y) \\le N(x - y) + N(y)$.\n\n    En réarrangeant les termes, cela nous donne une première inégalité :\n\n    $N(x) - N(y) \\le N(x - y)$.\n\n2.  De manière symétrique, on écrit $y$ comme $y = (y - x) + x$. L'inégalité triangulaire donne :\n\n    $N(y) = N((y - x) + x) \\le N(y - x) + N(x)$.\n\n    En utilisant la propriété d'homogénéité absolue, $N(y-x) = N((-1)(x-y)) = |-1|N(x-y) = N(x-y)$.\n\n    L'inégalité devient donc $N(y) \\le N(x - y) + N(x)$, ce qui se réarrange en :\n\n    $N(y) - N(x) \\le N(x - y)$.\n\n    Ceci est équivalent à $-(N(x) - N(y)) \\le N(x - y)$.\n\n3.  En combinant les deux inégalités obtenues, $N(x) - N(y) \\le N(x - y)$ et $-(N(x) - N(y)) \\le N(x - y)$, on conclut que :\n\n    $|N(x) - N(y)| \\le N(x - y)$.\n\n",
      "options": []
    },
    {
      "id": "2",
      "stackId": "e9d6c32b",
      "content": "Énoncer le théorème de l'équivalence des normes en dimension finie et esquisser les grandes lignes de sa preuve.",
      "solution": "\n\n**Théorème :** Sur un espace vectoriel réel de dimension finie, toutes les normes sont équivalentes.\n\n**Esquisse de la preuve :**\n\nSoit $E$ un $\\mathbb{R}$-espace vectoriel de dimension finie $n$. Il suffit de montrer que toute norme $N$ sur $E$ est équivalente à une norme de référence, par exemple la norme infinie $\\|\\cdot\\|_\\infty$ relative à une base fixée $(e_1, \\dots, e_n)$.\n\nSoit $x = \\sum_{i=1}^n x_i e_i \\in E$, on pose $\\|x\\|_\\infty = \\max_{1 \\le i \\le n} |x_i|$. On doit trouver $\\alpha, \\beta > 0$ tels que $\\alpha \\|x\\|_\\infty \\le N(x) \\le \\beta \\|x\\|_\\infty$.\n\n1.  **Majoration de $N(x)$ :**\n\n    En utilisant l'inégalité triangulaire et l'homogénéité de $N$ :\n\n    $N(x) = N(\\sum x_i e_i) \\le \\sum N(x_i e_i) = \\sum |x_i| N(e_i)$.\n\n    Comme $|x_i| \\le \\|x\\|_\\infty$ pour tout $i$, on a :\n\n    $N(x) \\le \\sum \\|x\\|_\\infty N(e_i) = \\|x\\|_\\infty \\left( \\sum N(e_i) \\right)$.\n\n    En posant $\\beta = \\sum_{i=1}^n N(e_i)$, qui est une constante positive finie, on a $N(x) \\le \\beta \\|x\\|_\\infty$.\n\n2.  **Minoration de $N(x)$ :**\n\n    C'est la partie la plus délicate. Elle repose sur un argument de compacité.\n\n    -   On montre d'abord que l'application $N: (E, \\|\\cdot\\|_\\infty) \\to \\mathbb{R}$ est continue. En utilisant l'inégalité triangulaire renversée et la majoration déjà établie :\n\n        $|N(x) - N(y)| \\le N(x-y) \\le \\beta \\|x-y\\|_\\infty$.\n\n        Ceci prouve que $N$ est $\\beta$-lipschitzienne, donc continue.\n\n    -   Considérons la sphère unité pour la norme infinie : $S_\\infty = \\{x \\in E \\mid \\|x\\|_\\infty = 1\\}$.\n    -   En dimension finie, la sphère unité $S_\\infty$ est une partie fermée et bornée. Par le théorème de Borel-Lebesgue, $S_\\infty$ est compacte.\n    -   La fonction $N$, étant continue sur le compact $S_\\infty$, y atteint son minimum. Soit $\\alpha = \\min_{x \\in S_\\infty} N(x)$.\n    -   Par la propriété de séparation de la norme, $N(x) > 0$ pour tout $x \\in S_\\infty$ (car $x \\neq 0_E$). Comme $S_\\infty$ est compact, ce minimum est strictement positif : $\\alpha > 0$.\n    -   Pour tout $x \\in E, x \\neq 0_E$, le vecteur $u = \\frac{x}{\\|x\\|_\\infty}$ est sur la sphère $S_\\infty$.\n    -   On a donc $N(u) \\ge \\alpha$. Par homogénéité de $N$:\n\n        $N\\left(\\frac{x}{\\|x\\|_\\infty}\\right) = \\frac{N(x)}{\\|x\\|_\\infty} \\ge \\alpha \\implies N(x) \\ge \\alpha \\|x\\|_\\infty$.\n\n    L'inégalité est aussi vraie pour $x=0_E$.\n\nOn a bien montré l'existence de $\\alpha, \\beta > 0$ vérifiant l'encadrement.\n\n",
      "options": []
    },
    {
      "id": "3",
      "stackId": "e9d6c32b",
      "content": "Comment prouver l'inégalité de Cauchy-Schwarz dans $\\mathbb{R}^n$ et quel est le cas d'égalité ?",
      "solution": "\n\n**Proposition (Inégalité de Cauchy-Schwarz) :**\n\nPour tous vecteurs $x, y \\in \\mathbb{R}^n$, $|\\langle x, y \\rangle| \\le \\|x\\|_2 \\|y\\|_2$. L'égalité a lieu si et seulement si $x$ et $y$ sont colinéaires.\n\n**Démonstration :**\n\nLa preuve repose sur l'étude du signe d'un polynôme du second degré.\n\n1.  Pour tout scalaire $t \\in \\mathbb{R}$, considérons la norme au carré du vecteur $x+ty$ :\n\n    $P(t) = \\|x + ty\\|_2^2 = \\langle x+ty, x+ty \\rangle$.\n\n2.  Par la bilinéarité du produit scalaire, on développe l'expression :\n\n    $P(t) = \\langle x,x \\rangle + 2t\\langle x,y \\rangle + t^2\\langle y,y \\rangle = \\|x\\|_2^2 + 2\\langle x, y \\rangle t + \\|y\\|_2^2 t^2$.\n\n3.  Par définition d'une norme, $\\|x+ty\\|_2^2 \\ge 0$ pour tout $t \\in \\mathbb{R}$. Donc, le polynôme $P(t)$ est toujours positif ou nul.\n\n4.  Un polynôme du second degré $At^2 + Bt + C$ est de signe constant si et seulement si son discriminant $\\Delta = B^2 - 4AC$ est négatif ou nul.\n\n    Ici, $A = \\|y\\|_2^2$, $B = 2\\langle x, y \\rangle$, et $C = \\|x\\|_2^2$.\n\n    Le discriminant est $\\Delta = (2\\langle x, y \\rangle)^2 - 4(\\|y\\|_2^2)(\\|x\\|_2^2) \\le 0$.\n\n5.  Cette inégalité se simplifie en $4\\langle x, y \\rangle^2 \\le 4\\|x\\|_2^2 \\|y\\|_2^2$, ce qui donne $\\langle x, y \\rangle^2 \\le \\|x\\|_2^2 \\|y\\|_2^2$. En prenant la racine carrée, on obtient $|\\langle x, y \\rangle| \\le \\|x\\|_2 \\|y\\|_2$.\n\n**Cas d'égalité :**\n\nL'égalité a lieu si et seulement si $\\Delta = 0$.\n\n-   Si $y = 0_E$, l'égalité est triviale ($0=0$) et les vecteurs sont colinéaires.\n-   Si $y \\neq 0_E$, $\\Delta = 0$ signifie que le polynôme $P(t)$ a une racine réelle unique $t_0 = -\\frac{\\langle x, y \\rangle}{\\|y\\|_2^2}$.\n-   Pour cette valeur $t_0$, on a $P(t_0) = \\|x + t_0 y\\|_2^2 = 0$.\n-   Par la propriété de séparation de la norme, $\\|x + t_0 y\\|_2 = 0$ est équivalent à $x + t_0 y = 0_E$.\n-   Ceci signifie que $x = -t_0 y$, donc les vecteurs $x$ et $y$ sont colinéaires.\n\nRéciproquement, si $x = \\lambda y$ pour un scalaire $\\lambda$, on peut vérifier que $|\\langle \\lambda y, y \\rangle| = |\\lambda| \\|y\\|_2^2$ et $\\|\\lambda y\\|_2 \\|y\\|_2 = |\\lambda| \\|y\\|_2^2$, donc il y a égalité.\n\n",
      "options": []
    },
    {
      "id": "4",
      "stackId": "e9d6c32b",
      "content": "En utilisant l'identité du parallélogramme, montrez que la norme 1, $\\|x\\|_1 = \\sum_{i=1}^n |x_i|$, sur $\\mathbb{R}^n$ (pour $n \\ge 2$) n'est pas induite par un produit scalaire.",
      "solution": "\n\nUne norme $\\|\\cdot\\|$ est induite par un produit scalaire si et seulement si elle vérifie l'**identité du parallélogramme** pour tous les vecteurs $x, y$ de l'espace :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = 2(\\|x\\|^2 + \\|y\\|^2) $$\n\nPour montrer que $\\|\\cdot\\|_1$ n'est pas induite par un produit scalaire, il suffit de trouver un contre-exemple à cette identité.\n\nPrenons l'espace $\\mathbb{R}^n$ avec $n \\ge 2$. Choisissons deux vecteurs simples de la base canonique, par exemple $e_1 = (1, 0, \\dots, 0)$ et $e_2 = (0, 1, \\dots, 0)$.\n\nCalculons les termes de l'identité pour $x = e_1$ et $y = e_2$ avec la norme $\\|\\cdot\\|_1$ :\n\n-   $\\|e_1\\|_1 = |1| + |0| + \\dots = 1$.\n-   $\\|e_2\\|_1 = |0| + |1| + \\dots = 1$.\n-   $e_1 + e_2 = (1, 1, 0, \\dots, 0)$, donc $\\|e_1 + e_2\\|_1 = |1| + |1| + \\dots = 2$.\n-   $e_1 - e_2 = (1, -1, 0, \\dots, 0)$, donc $\\|e_1 - e_2\\|_1 = |1| + |-1| + \\dots = 2$.\n\nMaintenant, évaluons les deux côtés de l'identité du parallélogramme :\n\n-   **Membre de gauche :** $\\|e_1+e_2\\|_1^2 + \\|e_1-e_2\\|_1^2 = 2^2 + 2^2 = 4 + 4 = 8$.\n-   **Membre de droite :** $2(\\|e_1\\|_1^2 + \\|e_2\\|_1^2) = 2(1^2 + 1^2) = 2(1 + 1) = 4$.\n\nPuisque $8 \\neq 4$, l'identité du parallélogramme n'est pas vérifiée. Par conséquent, la norme $\\|\\cdot\\|_1$ sur $\\mathbb{R}^n$ (pour $n \\ge 2$) n'est induite par aucun produit scalaire.\n\n",
      "options": []
    },
    {
      "id": "5",
      "stackId": "e9d6c32b",
      "content": "Expliquez la relation entre une norme et la géométrie de sa boule unité, en mentionnant les concepts de convexité, symétrie et absorption. Comment la jauge de Minkowski formalise-t-elle cette relation ?",
      "solution": "\n\nLa géométrie de la boule unité fermée $B = \\{x \\in E \\mid \\|x\\| \\le 1\\}$ d'un espace vectoriel normé $(E, \\|\\cdot\\|)$ capture entièrement les propriétés de la norme.\n\n**Propriétés géométriques de la boule unité :**\n\n1.  **Convexité :** $B$ est un ensemble convexe.\n\n    *Démonstration :* Soient $x, y \\in B$ (i.e., $\\|x\\| \\le 1$ et $\\|y\\| \\le 1$) et $t \\in [0, 1]$. On doit montrer que $tx + (1-t)y \\in B$.\n\n    Par l'inégalité triangulaire et l'homogénéité :\n\n    $\\|tx + (1-t)y\\| \\le \\|tx\\| + \\|(1-t)y\\| = t\\|x\\| + (1-t)\\|y\\| \\le t(1) + (1-t)(1) = 1$.\n\n    Donc $tx + (1-t)y \\in B$.\n\n2.  **Symétrie par rapport à l'origine (ensemble équilibré) :** Si $x \\in B$, alors $-x \\in B$.\n\n    *Démonstration :* Si $\\|x\\| \\le 1$, alors $\\|-x\\| = |-1|\\|x\\| = \\|x\\| \\le 1$, donc $-x \\in B$. Plus généralement, si $|\\lambda| \\le 1$, alors $\\lambda x \\in B$.\n\n3.  **Partie absorbante contenant l'origine en son intérieur :** L'origine $0_E$ est dans l'intérieur de $B$. Cela signifie qu'il existe un \"voisinage\" de $0_E$ entièrement contenu dans $B$. De manière équivalente, pour tout $x \\in E$, il existe $\\lambda > 0$ tel que $\\lambda x \\in B$.\n\n**La jauge de Minkowski (ou fonctionnelle de jauge) :**\n\nLa relation est en fait une dualité. Réciproquement, toute partie $C \\subset E$ qui est convexe, équilibrée, et absorbante peut être utilisée pour définir une norme. Cette norme est appelée la **jauge de Minkowski** de $C$, notée $p_C$, et est définie par :\n\n$$ p_C(x) = \\inf \\{ \\lambda > 0 \\mid x \\in \\lambda C \\} $$\n\noù $\\lambda C = \\{\\lambda y \\mid y \\in C\\}$.\n\n-   Si $C$ possède ces propriétés, alors $p_C$ est une semi-norme.\n-   Si, de plus, $C$ est bornée (au sens topologique usuel, par exemple dans $\\mathbb{R}^n$), alors $p_C$ est une norme.\n\nLa boule unité de la norme $p_C$ est précisément l'ensemble $C$ (ou son adhérence si $C$ n'est pas fermée). Ainsi, la notion de norme et celle d'ensemble convexe, équilibré et absorbant sont intimement liées.\n\n",
      "options": []
    },
    {
      "id": "6",
      "stackId": "e9d6c32b",
      "content": "Démontrer que si deux normes $N_1$ et $N_2$ sur un espace $E$ sont équivalentes, alors une suite $(x^k)$ converge vers $a$ pour $N_1$ si et seulement si elle converge vers $a$ pour $N_2$.",
      "solution": "\n\n**Hypothèse :** Les normes $N_1$ et $N_2$ sont équivalentes. Il existe donc deux constantes réelles $\\alpha, \\beta > 0$ telles que pour tout $x \\in E$ :\n\n$$ \\alpha N_1(x) \\le N_2(x) \\le \\beta N_1(x) $$\n\n**$(\\implies)$ Supposons que $(x^k)$ converge vers $a$ pour la norme $N_1$.**\n\nPar définition, cela signifie que $\\lim_{k \\to \\infty} N_1(x^k - a) = 0$.\n\nFormellement, $\\forall \\varepsilon > 0, \\exists K \\in \\mathbb{N}$ tel que pour tout $k \\ge K$, $N_1(x^k - a) < \\varepsilon$.\n\nNous voulons montrer que $\\lim_{k \\to \\infty} N_2(x^k - a) = 0$.\n\nEn utilisant la partie droite de l'inégalité d'équivalence sur le vecteur $x^k - a$, on a :\n\n$$ 0 \\le N_2(x^k - a) \\le \\beta N_1(x^k - a) $$\n\nPuisque $N_1(x^k - a) \\to 0$ et $\\beta$ est une constante positive, le produit $\\beta N_1(x^k - a)$ tend également vers 0.\n\nPar le théorème des gendarmes (ou théorème d'encadrement), on conclut que $\\lim_{k \\to \\infty} N_2(x^k - a) = 0$.\n\nLa suite $(x^k)$ converge donc bien vers $a$ pour la norme $N_2$.\n\n**$(\\impliedby)$ Supposons que $(x^k)$ converge vers $a$ pour la norme $N_2$.**\n\nLa démarche est symétrique. Par définition, $\\lim_{k \\to \\infty} N_2(x^k - a) = 0$.\n\nNous voulons montrer que $\\lim_{k \\to \\infty} N_1(x^k - a) = 0$.\n\nEn utilisant la partie gauche de l'inégalité d'équivalence, $\\alpha N_1(x^k - a) \\le N_2(x^k - a)$, on peut la réécrire comme :\n\n$$ 0 \\le N_1(x^k - a) \\le \\frac{1}{\\alpha} N_2(x^k - a) $$\n\nPuisque $N_2(x^k - a) \\to 0$ et $1/\\alpha$ est une constante positive, le produit $\\frac{1}{\\alpha} N_2(x^k - a)$ tend vers 0.\n\nDe nouveau, par le théorème des gendarmes, on conclut que $\\lim_{k \\to \\infty} N_1(x^k - a) = 0$.\n\nLa suite $(x^k)$ converge donc bien vers $a$ pour la norme $N_1$.\n\n**Conclusion :** L'équivalence des normes préserve la notion de convergence et la limite elle-même. C'est pourquoi en dimension finie, où toutes les normes sont équivalentes, la topologie (et donc les notions de convergence, continuité, ouverts, etc.) est unique.\n\n",
      "options": []
    },
    {
      "id": "7",
      "stackId": "e9d6c32b",
      "content": "Prouver que la convergence d'une suite de vecteurs dans $\\mathbb{R}^n$ est équivalente à la convergence de chacune de ses suites de coordonnées.",
      "solution": "\n\nSoit $(x^k)_{k \\in \\mathbb{N}}$ une suite de vecteurs de $\\mathbb{R}^n$, où $x^k = (x_1^k, x_2^k, \\dots, x_n^k)$, et soit $a = (a_1, a_2, \\dots, a_n) \\in \\mathbb{R}^n$. Nous devons prouver l'équivalence suivante :\n\n$$ \\lim_{k \\to \\infty} x^k = a \\iff \\forall j \\in \\{1, \\dots, n\\}, \\lim_{k \\to \\infty} x_j^k = a_j $$\n\nLa preuve repose sur l'utilisation de la norme infinie $\\|\\cdot\\|_\\infty$ et de ses propriétés. La convergence dans $\\mathbb{R}^n$ étant indépendante de la norme choisie (car toutes sont équivalentes), nous pouvons travailler avec $\\|\\cdot\\|_\\infty$ sans perte de généralité.\n\nPar définition, $\\lim_{k \\to \\infty} x^k = a$ est équivalent à $\\lim_{k \\to \\infty} \\|x^k - a\\|_\\infty = 0$.\n\nRappelons que $\\|x^k - a\\|_\\infty = \\max_{1 \\le j \\le n} |x_j^k - a_j|$.\n\n**$(\\implies)$ Convergence vectorielle implique convergence des coordonnées :**\n\nSupposons que $\\lim_{k \\to \\infty} x^k = a$, c'est-à-dire $\\lim_{k \\to \\infty} \\|x^k - a\\|_\\infty = 0$.\n\nPour n'importe quel indice $j \\in \\{1, \\dots, n\\}$, nous avons l'inégalité suivante par définition du maximum :\n\n$$ 0 \\le |x_j^k - a_j| \\le \\max_{1 \\le i \\le n} |x_i^k - a_i| = \\|x^k - a\\|_\\infty $$\n\nPuisque $\\|x^k - a\\|_\\infty \\to 0$ lorsque $k \\to \\infty$, le théorème d'encadrement (ou des gendarmes) implique que $|x_j^k - a_j| \\to 0$ pour chaque $j$.\n\nCela signifie que $\\lim_{k \\to \\infty} x_j^k = a_j$ pour tout $j \\in \\{1, \\dots, n\\}$.\n\n**$(\\impliedby)$ Convergence des coordonnées implique convergence vectorielle :**\n\nSupposons que pour tout $j \\in \\{1, \\dots, n\\}$, on a $\\lim_{k \\to \\infty} x_j^k = a_j$.\n\nCela signifie que $\\lim_{k \\to \\infty} |x_j^k - a_j| = 0$ pour chaque $j$.\n\nNous voulons montrer que $\\lim_{k \\to \\infty} \\|x^k - a\\|_\\infty = 0$.\n\nSoit $\\varepsilon > 0$. Pour chaque $j \\in \\{1, \\dots, n\\}$, il existe un rang $K_j \\in \\mathbb{N}$ tel que pour tout $k \\ge K_j$, on a $|x_j^k - a_j| < \\varepsilon$.\n\nPosons $K = \\max(K_1, K_2, \\dots, K_n)$. Pour tout $k \\ge K$, l'inégalité $|x_j^k - a_j| < \\varepsilon$ est vraie simultanément pour *tous* les $j \\in \\{1, \\dots, n\\}$.\n\nPar conséquent, pour $k \\ge K$, on a :\n\n$$ \\|x^k - a\\|_\\infty = \\max_{1 \\le j \\le n} |x_j^k - a_j| < \\varepsilon $$\n\nCeci est la définition formelle de $\\lim_{k \\to \\infty} \\|x^k - a\\|_\\infty = 0$. La suite $(x^k)$ converge donc vers $a$.\n\n",
      "options": []
    },
    {
      "id": "8",
      "stackId": "e9d6c32b",
      "content": "Construire une suite de fonctions dans l'espace $C([0, 1], \\mathbb{R})$ qui démontre que les normes $\\| \\cdot \\|_\\infty$ et $\\| \\cdot \\|_1$ ne sont pas équivalentes.",
      "solution": "\n\nPour montrer que les normes $\\|f\\|_\\infty = \\sup_{t \\in [0, 1]} |f(t)|$ et $\\|f\\|_1 = \\int_0^1 |f(t)|dt$ ne sont pas équivalentes sur $C([0, 1], \\mathbb{R})$, il faut montrer qu'il n'existe pas de constante $\\alpha > 0$ telle que $\\alpha \\|f\\|_\\infty \\le \\|f\\|_1$ pour toute fonction $f$. Pour ce faire, nous construisons une suite de fonctions $(f_n)_{n \\in \\mathbb{N}}$ pour laquelle le rapport $\\frac{\\|f_n\\|_1}{\\|f_n\\|_\\infty}$ tend vers 0.\n\nConsidérons la suite de fonctions $(f_n)_{n \\ge 1}$ définies par $f_n(t) = t^n$.\n\nChaque $f_n$ est un polynôme, donc elle est continue sur $[0, 1]$.\n\nCalculons les normes $\\|\\cdot\\|_\\infty$ et $\\|\\cdot\\|_1$ pour $f_n$:\n\n1.  **Norme infinie ($\\| \\cdot \\|_\\infty$) :**\n\n    La fonction $f_n(t) = t^n$ est croissante et positive sur $[0, 1]$. Son maximum est donc atteint en $t=1$.\n\n    $\\|f_n\\|_\\infty = \\sup_{t \\in [0, 1]} |t^n| = 1^n = 1$.\n\n    La norme infinie de chaque fonction de la suite est constante et égale à 1.\n\n2.  **Norme 1 ($\\| \\cdot \\|_1$) :**\n\n    On calcule l'intégrale de $|f_n(t)|$. Puisque $t \\ge 0$ sur $[0,1]$, $|t^n|=t^n$.\n\n    $\\|f_n\\|_1 = \\int_0^1 t^n dt = \\left[ \\frac{t^{n+1}}{n+1} \\right]_0^1 = \\frac{1}{n+1} - 0 = \\frac{1}{n+1}$.\n\n    La norme 1 de la fonction $f_n$ tend vers 0 lorsque $n \\to \\infty$.\n\n**Argument de non-équivalence :**\n\nSupposons par l'absurde que les normes sont équivalentes. Il existerait alors une constante $\\alpha > 0$ telle que pour toute fonction $f \\in C([0, 1], \\mathbb{R})$:\n\n$$ \\alpha \\|f\\|_\\infty \\le \\|f\\|_1 $$\n\nAppliquons cette inégalité à notre suite de fonctions $(f_n)$:\n\n$$ \\alpha \\|f_n\\|_\\infty \\le \\|f_n\\|_1 \\implies \\alpha \\cdot 1 \\le \\frac{1}{n+1} $$\n\nCette inégalité, $\\alpha \\le \\frac{1}{n+1}$, devrait être vraie pour tout $n \\ge 1$.\n\nCependant, lorsque $n \\to \\infty$, le terme $\\frac{1}{n+1}$ tend vers 0.\n\nEn passant à la limite, on obtiendrait $\\alpha \\le 0$.\n\nCeci contredit notre hypothèse que $\\alpha$ est une constante *strictement positive*.\n\nLa supposition de l'équivalence des normes mène à une contradiction. Donc, les normes $\\| \\cdot \\|_\\infty$ et $\\| \\cdot \\|_1$ ne sont pas équivalentes sur $C([0, 1], \\mathbb{R})$.\n\n",
      "options": []
    },
    {
      "id": "9",
      "stackId": "e9d6c32b",
      "content": "Démontrer que dans tout espace vectoriel normé $(E, \\|\\cdot\\|)$, une suite convergente est nécessairement une suite de Cauchy.",
      "solution": "\n\nSoit $(x^k)_{k \\in \\mathbb{N}}$ une suite d'éléments de $E$ qui converge vers une limite $a \\in E$.\n\nPar définition de la convergence, on a :\n\n$$ \\forall \\varepsilon' > 0, \\exists K \\in \\mathbb{N}, \\forall k \\ge K \\implies \\|x^k - a\\| < \\varepsilon' $$\n\nNous voulons démontrer que $(x^k)$ est une suite de Cauchy, c'est-à-dire :\n\n$$ \\forall \\varepsilon > 0, \\exists K' \\in \\mathbb{N}, \\forall p, q \\ge K' \\implies \\|x^p - x^q\\| < \\varepsilon $$\n\n**Démonstration :**\n\nSoit $\\varepsilon > 0$ un réel quelconque.\n\nPosons $\\varepsilon' = \\varepsilon/2$. Puisque $\\varepsilon' > 0$, la définition de la convergence de $(x^k)$ vers $a$ nous assure qu'il existe un rang $K \\in \\mathbb{N}$ tel que pour tout indice $k \\ge K$, on a :\n\n$$ \\|x^k - a\\| < \\frac{\\varepsilon}{2} $$\n\nMaintenant, considérons deux indices quelconques $p$ et $q$ tels que $p \\ge K$ et $q \\ge K$.\n\nNous voulons majorer la distance $\\|x^p - x^q\\|$. Pour ce faire, nous utilisons l'astuce d'introduire la limite $a$ et d'appliquer l'inégalité triangulaire :\n\n$$ \\|x^p - x^q\\| = \\|(x^p - a) + (a - x^q)\\| \\le \\|x^p - a\\| + \\|a - x^q\\| $$\n\nPar homogénéité, $\\|a - x^q\\| = \\|(-1)(x^q - a)\\| = |-1|\\|x^q - a\\| = \\|x^q - a\\|$.\n\nL'inégalité devient :\n\n$$ \\|x^p - x^q\\| \\le \\|x^p - a\\| + \\|x^q - a\\| $$\n\nPuisque $p \\ge K$ et $q \\ge K$, nous pouvons utiliser la propriété issue de la convergence :\n\n-   $\\|x^p - a\\| < \\varepsilon/2$\n-   $\\|x^q - a\\| < \\varepsilon/2$\n\nEn substituant ces majorations, on obtient :\n\n$$ \\|x^p - x^q\\| < \\frac{\\varepsilon}{2} + \\frac{\\varepsilon}{2} = \\varepsilon $$\n\nNous avons donc montré que pour tout $\\varepsilon > 0$, en choisissant $K' = K$ (le rang donné par la convergence pour $\\varepsilon/2$), on a bien :\n\n$$ \\forall p, q \\ge K', \\quad \\|x^p - x^q\\| < \\varepsilon $$\n\nCeci est précisément la définition d'une suite de Cauchy.\n\n",
      "options": []
    },
    {
      "id": "10",
      "stackId": "e9d6c32b",
      "content": "Pourquoi l'application $f(x) = (\\sum_{i=1}^n |x_i|^p)^{1/p}$ pour $0 < p < 1$ ne définit-elle pas une norme sur $\\mathbb{R}^n$ (pour $n \\ge 2$) ?",
      "solution": "\n\nL'application $f(x) = \\|x\\|_p$ pour $0 < p < 1$ ne définit pas une norme car elle viole l'**inégalité triangulaire**. Les axiomes de séparation et d'homogénéité absolue sont, eux, bien vérifiés.\n\nPour le démontrer, il suffit de fournir un contre-exemple explicite dans $\\mathbb{R}^n$ (avec $n \\ge 2$).\n\nPrenons l'espace $\\mathbb{R}^2$ et choisissons $p = 1/2$.\n\nConsidérons les vecteurs de la base canonique $x = (1, 0)$ et $y = (0, 1)$.\n\nCalculons les \"p-normes\" de ces vecteurs et de leur somme :\n\n-   **Pour $x = (1, 0)$ :**\n\n    $\\|x\\|_{1/2} = (|1|^{1/2} + |0|^{1/2})^{1/(1/2)} = (1 + 0)^2 = 1^2 = 1$.\n\n-   **Pour $y = (0, 1)$ :**\n\n    $\\|y\\|_{1/2} = (|0|^{1/2} + |1|^{1/2})^{1/(1/2)} = (0 + 1)^2 = 1^2 = 1$.\n\n-   **Pour la somme $x+y = (1, 1)$ :**\n\n    $\\|x+y\\|_{1/2} = (|1|^{1/2} + |1|^{1/2})^{1/(1/2)} = (1 + 1)^2 = 2^2 = 4$.\n\nMaintenant, testons l'inégalité triangulaire $\\|x+y\\|_p \\le \\|x\\|_p + \\|y\\|_p$ :\n\n-   $\\|x+y\\|_{1/2} = 4$.\n-   $\\|x\\|_{1/2} + \\|y\\|_{1/2} = 1 + 1 = 2$.\n\nOn observe que $4 > 2$, c'est-à-dire :\n\n$$ \\|x+y\\|_{1/2} > \\|x\\|_{1/2} + \\|y\\|_{1/2} $$\n\nL'inégalité triangulaire est violée. Par conséquent, $\\|x\\|_p$ pour $0 < p < 1$ n'est pas une norme.\n\n**Note conceptuelle :**\n\nLa fonction $t \\mapsto t^p$ est concave pour $0 < p < 1$, alors qu'elle est convexe pour $p \\ge 1$. La convexité est la propriété sous-jacente qui garantit l'inégalité triangulaire pour les normes p (via l'inégalité de Minkowski). L'échec de la convexité pour $p<1$ conduit à l'échec de l'inégalité triangulaire. Ces objets sont parfois appelés des **quasi-normes**.\n\n",
      "options": []
    }
  ]
}