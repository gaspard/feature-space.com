{
  "info": {
    "id": "a76472c4",
    "title": "Espaces Euclidiens et Hermitiens - preuves (A)",
    "type": "proofs",
    "level": "regular",
    "chapter": "Espaces Euclidiens et Hermitiens",
    "course": "Géométrie",
    "tags": [
      "Espaces Euclidiens",
      "Espaces Hermitiens",
      "Produit scalaire",
      "Gram-Schmidt",
      "Projection orthogonale",
      "Endomorphismes adjoints",
      "Théorème de Riesz"
    ],
    "count": 10
  },
  "cards": [
    {
      "id": "1",
      "stackId": "a76472c4",
      "content": "#### Propriété de Réalité de la Forme Quadratique Hermitienne\n\nProuver que pour une forme sesquilinéaire hermitienne $\\varphi$ sur un $\\mathbb{C}$-espace vectoriel $E$, la valeur $\\varphi(x, x)$ est un nombre réel pour tout vecteur $x \\in E$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nUtilisez la définition de la symétrie hermitienne, qui relie $\\varphi(x, y)$ à $\\varphi(y, x)$.\n\nAppliquez cette propriété au cas particulier où $y = x$.\n\nRappelez-vous qu'un nombre complexe $z$ est réel si et seulement si $z = \\bar{z}$.\n\n</details>",
      "solution": "\n\nSoit $\\varphi: E \\times E \\to \\mathbb{C}$ une forme sesquilinéaire hermitienne.\n\n**Étape 1 : Rappel de la définition de la symétrie hermitienne**\n\nPar définition, une forme sesquilinéaire $\\varphi$ est hermitienne si pour tous vecteurs $x, y \\in E$, on a :\n\n$$ \\varphi(x, y) = \\overline{\\varphi(y, x)} $$\n\n**Étape 2 : Appliquer la définition au cas $y=x$**\n\nNous nous intéressons à la valeur $\\varphi(x, x)$. Appliquons la propriété de symétrie hermitienne en posant $y = x$. On obtient :\n\n$$ \\varphi(x, x) = \\overline{\\varphi(x, x)} $$\n\n**Étape 3 : Conclure sur la nature de $\\varphi(x, x)$**\n\nSoit $z = \\varphi(x, x)$. L'équation de l'étape 2 s'écrit $z = \\bar{z}$.\n\nUn nombre complexe est égal à son propre conjugué si et seulement si sa partie imaginaire est nulle. C'est la définition d'un nombre réel.\n\n**Conclusion :**\n\nPar conséquent, pour tout $x \\in E$, la valeur $\\varphi(x, x)$ est un nombre réel.\n\n",
      "options": []
    },
    {
      "id": "2",
      "stackId": "a76472c4",
      "content": "#### Inégalité de Cauchy-Schwarz (Cas Réel)\n\nSoit $(E, \\langle \\cdot, \\cdot \\rangle)$ un espace euclidien. Prouver que pour tous vecteurs $x, y \\in E$, on a :\n\n$$ |\\langle x, y \\rangle| \\le \\|x\\| \\|y\\| $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nConsidérez le vecteur $x + \\lambda y$ pour un scalaire réel $\\lambda$.\n\nUtilisez la propriété de positivité du produit scalaire, qui stipule que $\\langle v, v \\rangle \\ge 0$ pour tout vecteur $v \\in E$.\n\nDéveloppez $\\langle x + \\lambda y, x + \\lambda y \\rangle$ et analysez l'expression obtenue comme un polynôme du second degré en $\\lambda$. Quel doit être le signe de son discriminant ?\n\n</details>",
      "solution": "\n\nSoient $x, y \\in E$.\n\n**Cas 1 : $y = 0_E$**\n\nSi $y$ est le vecteur nul, alors $\\langle x, y \\rangle = \\langle x, 0_E \\rangle = 0$ et $\\|y\\| = 0$. L'inégalité devient $0 \\le 0$, ce qui est vrai.\n\n**Cas 2 : $y \\neq 0_E$**\n\nSoit $\\lambda \\in \\mathbb{R}$ un scalaire quelconque. Considérons le vecteur $v = x + \\lambda y$.\n\n**Étape 1 : Utiliser la positivité de la norme**\n\nPar définition de la norme associée à un produit scalaire, nous savons que $\\|v\\|^2 = \\langle v, v \\rangle \\ge 0$.\n\nDonc, pour tout $\\lambda \\in \\mathbb{R}$ :\n\n$$ \\langle x + \\lambda y, x + \\lambda y \\rangle \\ge 0 $$\n\n**Étape 2 : Développer l'expression**\n\nEn utilisant la bilinéarité du produit scalaire réel :\n\n$$ \\langle x + \\lambda y, x + \\lambda y \\rangle = \\langle x, x \\rangle + \\langle x, \\lambda y \\rangle + \\langle \\lambda y, x \\rangle + \\langle \\lambda y, \\lambda y \\rangle $$\n\n$$ = \\langle x, x \\rangle + \\lambda \\langle x, y \\rangle + \\lambda \\langle y, x \\rangle + \\lambda^2 \\langle y, y \\rangle $$\n\nComme le produit scalaire est symétrique ($\\langle x, y \\rangle = \\langle y, x \\rangle$), cela se simplifie en :\n\n$$ = \\langle x, x \\rangle + 2\\lambda \\langle x, y \\rangle + \\lambda^2 \\langle y, y \\rangle $$\n\nEn notation de norme, on a le polynôme $P(\\lambda)$:\n\n$$ P(\\lambda) = \\|y\\|^2 \\lambda^2 + 2\\langle x, y \\rangle \\lambda + \\|x\\|^2 $$\n\n**Étape 3 : Analyser le signe du discriminant**\n\nNous avons établi que $P(\\lambda) \\ge 0$ pour tout $\\lambda \\in \\mathbb{R}$. C'est un polynôme du second degré en $\\lambda$ qui est toujours positif ou nul. Cela signifie qu'il a au plus une racine réelle. Par conséquent, son discriminant $\\Delta$ doit être négatif ou nul.\n\nLe discriminant de $A\\lambda^2 + B\\lambda + C$ est $\\Delta = B^2 - 4AC$. Ici, $A=\\|y\\|^2$, $B=2\\langle x, y \\rangle$, $C=\\|x\\|^2$.\n\n$$ \\Delta = (2\\langle x, y \\rangle)^2 - 4 (\\|y\\|^2) (\\|x\\|^2) \\le 0 $$\n\n$$ 4 \\langle x, y \\rangle^2 - 4 \\|x\\|^2 \\|y\\|^2 \\le 0 $$\n\n$$ \\langle x, y \\rangle^2 \\le \\|x\\|^2 \\|y\\|^2 $$\n\n**Étape 4 : Conclure**\n\nEn prenant la racine carrée des deux côtés (qui sont des nombres réels positifs), on obtient :\n\n$$ \\sqrt{\\langle x, y \\rangle^2} \\le \\sqrt{\\|x\\|^2 \\|y\\|^2} $$\n\n$$ |\\langle x, y \\rangle| \\le \\|x\\| \\|y\\| $$\n\n**Conclusion :**\n\nL'inégalité est donc prouvée pour tous les vecteurs $x, y$ de l'espace euclidien $E$.\n\n",
      "options": []
    },
    {
      "id": "3",
      "stackId": "a76472c4",
      "content": "#### Cas d'Égalité de l'Inégalité de Cauchy-Schwarz\n\nProuver que dans l'inégalité de Cauchy-Schwarz $|\\langle x, y \\rangle| \\le \\|x\\| \\|y\\|$, l'égalité a lieu si et seulement si les vecteurs $x$ et $y$ sont colinéaires (c'est-à-dire, linéairement dépendants).\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nReprenez la démonstration de l'inégalité de Cauchy-Schwarz. L'égalité se produit lorsque le discriminant du polynôme $P(\\lambda) = \\|x+\\lambda y\\|^2$ est nul.\n\nQue signifie, pour un polynôme du second degré toujours positif, d'avoir un discriminant nul ? Cela signifie qu'il admet une unique racine réelle $\\lambda_0$.\n\nQuelle est la signification de $P(\\lambda_0) = \\|x+\\lambda_0 y\\|^2 = 0$ ? Utilisez la propriété de séparation de la norme (ou le caractère défini du produit scalaire).\n\n</details>",
      "solution": "\n\nNous devons prouver l'équivalence : $|\\langle x, y \\rangle| = \\|x\\| \\|y\\| \\iff (x \\text{ et } y \\text{ sont colinéaires})$.\n\n**Partie 1 : (Colinéarité $\\implies$ Égalité)**\n\nSupposons que $x$ et $y$ sont colinéaires. Il existe donc un scalaire $k$ tel que $x = ky$.\n\nCalculons les deux membres de l'inégalité :\n\n- $|\\langle x, y \\rangle| = |\\langle ky, y \\rangle| = |k \\langle y, y \\rangle| = |k| \\langle y, y \\rangle = |k| \\|y\\|^2$.\n- $\\|x\\| \\|y\\| = \\|ky\\| \\|y\\| = (|k| \\|y\\|) \\|y\\| = |k| \\|y\\|^2$.\n\nLes deux membres sont égaux. Donc, si les vecteurs sont colinéaires, il y a égalité.\n\n**Partie 2 : (Égalité $\\implies$ Colinéarité)**\n\nSupposons que $|\\langle x, y \\rangle| = \\|x\\| \\|y\\|$. Cela équivaut à $\\langle x, y \\rangle^2 = \\|x\\|^2 \\|y\\|^2$.\n\nReprenons la preuve de Cauchy-Schwarz, basée sur le polynôme $P(\\lambda) = \\|x+\\lambda y\\|^2 = \\|y\\|^2 \\lambda^2 + 2\\langle x, y \\rangle \\lambda + \\|x\\|^2$.\n\nL'hypothèse d'égalité signifie que le discriminant $\\Delta$ de ce polynôme est nul :\n\n$$ \\Delta = (2\\langle x, y \\rangle)^2 - 4 \\|y\\|^2 \\|x\\|^2 = 4(\\langle x, y \\rangle^2 - \\|x\\|^2 \\|y\\|^2) = 0 $$\n\nSi $y=0_E$, $x$ et $y$ sont colinéaires (car $y=0x$). Supposons donc $y \\neq 0_E$.\n\nUn polynôme du second degré avec un discriminant nul admet une unique racine réelle, notée $\\lambda_0$.\n\nPour cette valeur $\\lambda_0$, on a $P(\\lambda_0) = 0$.\n\n$$ P(\\lambda_0) = \\|x + \\lambda_0 y\\|^2 = 0 $$\n\nPar la propriété de séparation de la norme (ou le caractère défini du produit scalaire), une norme nulle implique un vecteur nul :\n\n$$ \\|x + \\lambda_0 y\\| = 0 \\iff x + \\lambda_0 y = 0_E $$\n\nCette dernière égalité s'écrit $x = -\\lambda_0 y$. Ceci est la définition de la colinéarité de $x$ et $y$.\n\n**Conclusion :**\n\nNous avons montré les deux implications. L'égalité dans l'inégalité de Cauchy-Schwarz est vérifiée si et seulement si les vecteurs $x$ et $y$ sont colinéaires.\n\n",
      "options": []
    },
    {
      "id": "4",
      "stackId": "a76472c4",
      "content": "#### Inégalité Triangulaire pour la Norme\n\nSoit $(E, \\langle \\cdot, \\cdot \\rangle)$ un espace préhilbertien. Prouver que la norme associée $\\|x\\| = \\sqrt{\\langle x, x \\rangle}$ vérifie l'inégalité triangulaire :\n\n$$ \\|x+y\\| \\le \\|x\\| + \\|y\\| $$\n\npour tous vecteurs $x, y \\in E$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nComme la norme est toujours positive, l'inégalité est équivalente à $\\|x+y\\|^2 \\le (\\|x\\| + \\|y\\|)^2$.\n\nCommencez par développer $\\|x+y\\|^2 = \\langle x+y, x+y \\rangle$.\n\nDans l'expression obtenue, utilisez l'inégalité de Cauchy-Schwarz sur le terme $\\langle x, y \\rangle$. Dans le cas complexe, vous devrez manipuler le terme $\\langle x,y \\rangle + \\overline{\\langle x,y \\rangle} = 2 \\text{Re}(\\langle x,y \\rangle)$.\n\n</details>",
      "solution": "\n\nSoient $x, y \\in E$.\n\n**Étape 1 : Travailler avec le carré de la norme**\n\nLes termes de l'inégalité sont positifs, il est donc équivalent de prouver $\\|x+y\\|^2 \\le (\\|x\\| + \\|y\\|)^2$.\n\nDéveloppons le membre de gauche en utilisant les propriétés du produit scalaire :\n\n$$ \\|x+y\\|^2 = \\langle x+y, x+y \\rangle = \\langle x,x \\rangle + \\langle x,y \\rangle + \\langle y,x \\rangle + \\langle y,y \\rangle $$\n\nEn utilisant la symétrie (hermitienne), on sait que $\\langle y,x \\rangle = \\overline{\\langle x,y \\rangle}$.\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + \\langle x,y \\rangle + \\overline{\\langle x,y \\rangle} + \\|y\\|^2 $$\n\nRappelons que pour tout nombre complexe $z$, $z + \\bar{z} = 2 \\text{Re}(z)$.\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + 2 \\text{Re}(\\langle x,y \\rangle) + \\|y\\|^2 $$\n\n(Dans le cas réel, $\\text{Re}(\\langle x,y \\rangle) = \\langle x,y \\rangle$, la formule reste donc juste).\n\n**Étape 2 : Appliquer l'inégalité de Cauchy-Schwarz**\n\nPour tout nombre complexe $z$, on a $\\text{Re}(z) \\le |z|$. Donc :\n\n$$ 2 \\text{Re}(\\langle x,y \\rangle) \\le 2 |\\langle x,y \\rangle| $$\n\nL'inégalité de Cauchy-Schwarz nous dit que $|\\langle x,y \\rangle| \\le \\|x\\|\\|y\\|$. En combinant ces deux inégalités :\n\n$$ 2 \\text{Re}(\\langle x,y \\rangle) \\le 2 \\|x\\|\\|y\\| $$\n\n**Étape 3 : Substituer et conclure**\n\nEn substituant ce résultat dans l'expression de $\\|x+y\\|^2$ :\n\n$$ \\|x+y\\|^2 \\le \\|x\\|^2 + 2 \\|x\\|\\|y\\| + \\|y\\|^2 $$\n\nOn reconnaît le développement d'une identité remarquable :\n\n$$ \\|x+y\\|^2 \\le (\\|x\\| + \\|y\\|)^2 $$\n\n**Étape 4 : Revenir à la norme**\n\nPuisque la norme est une quantité positive, on peut prendre la racine carrée des deux côtés de l'inégalité pour obtenir le résultat final :\n\n$$ \\|x+y\\| \\le \\|x\\| + \\|y\\| $$\n\n**Conclusion :**\n\nLa norme induite par un produit scalaire satisfait bien l'inégalité triangulaire.\n\n",
      "options": []
    },
    {
      "id": "5",
      "stackId": "a76472c4",
      "content": "#### Identité du Parallélogramme\n\nSoit $(E, \\langle \\cdot, \\cdot \\rangle)$ un espace préhilbertien. Prouver que pour tous vecteurs $x, y \\in E$, la norme associée au produit scalaire vérifie l'identité du parallélogramme :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = 2(\\|x\\|^2 + \\|y\\|^2) $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nExprimez les termes $\\|x+y\\|^2$ et $\\|x-y\\|^2$ en utilisant la définition de la norme, c'est-à-dire $\\|v\\|^2 = \\langle v, v \\rangle$.\n\nDéveloppez les deux expressions $\\langle x+y, x+y \\rangle$ et $\\langle x-y, x-y \\rangle$ en utilisant la linéarité (et semi-linéarité) du produit scalaire.\n\nAdditionnez les deux expressions développées et observez les simplifications.\n\n</details>",
      "solution": "\n\nSoient $x, y \\in E$.\n\n**Étape 1 : Développer $\\|x+y\\|^2$**\n\nEn utilisant la définition de la norme et les propriétés du produit scalaire :\n\n$$ \\|x+y\\|^2 = \\langle x+y, x+y \\rangle = \\langle x,x \\rangle + \\langle x,y \\rangle + \\langle y,x \\rangle + \\langle y,y \\rangle $$\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + \\langle x,y \\rangle + \\langle y,x \\rangle + \\|y\\|^2 \\quad (1) $$\n\n**Étape 2 : Développer $\\|x-y\\|^2$**\n\nDe manière similaire :\n\n$$ \\|x-y\\|^2 = \\langle x-y, x-y \\rangle = \\langle x,x \\rangle - \\langle x,y \\rangle - \\langle y,x \\rangle + \\langle y,y \\rangle $$\n\n$$ \\|x-y\\|^2 = \\|x\\|^2 - \\langle x,y \\rangle - \\langle y,x \\rangle + \\|y\\|^2 \\quad (2) $$\n\n**Étape 3 : Additionner les deux expressions**\n\nAdditionnons les équations (1) et (2) :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = (\\|x\\|^2 + \\langle x,y \\rangle + \\langle y,x \\rangle + \\|y\\|^2) + (\\|x\\|^2 - \\langle x,y \\rangle - \\langle y,x \\rangle + \\|y\\|^2) $$\n\nLes termes \"croisés\" $\\langle x,y \\rangle$ et $\\langle y,x \\rangle$ s'annulent :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = \\|x\\|^2 + \\|y\\|^2 + \\|x\\|^2 + \\|y\\|^2 $$\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = 2\\|x\\|^2 + 2\\|y\\|^2 $$\n\n**Conclusion :**\n\nEn factorisant le membre de droite, on obtient l'identité du parallélogramme :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = 2(\\|x\\|^2 + \\|y\\|^2) $$\n\n",
      "options": []
    },
    {
      "id": "6",
      "stackId": "a76472c4",
      "content": "#### Théorème de Pythagore\n\nSoit $(E, \\langle \\cdot, \\cdot \\rangle)$ un espace préhilbertien. Prouver que si deux vecteurs $x, y \\in E$ sont orthogonaux, alors :\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + \\|y\\|^2 $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nCommencez par développer $\\|x+y\\|^2$ en utilisant sa définition en termes de produit scalaire : $\\langle x+y, x+y \\rangle$.\n\nUtilisez la définition de l'orthogonalité. Que vaut $\\langle x, y \\rangle$ si $x$ et $y$ sont orthogonaux ?\n\n</details>",
      "solution": "\n\nSoient $x, y \\in E$ deux vecteurs orthogonaux.\n\n**Étape 1 : Définition de l'orthogonalité**\n\nPar définition, $x$ et $y$ sont orthogonaux si leur produit scalaire est nul :\n\n$$ \\langle x, y \\rangle = 0 $$\n\nDans un espace hermitien, cela implique aussi $\\langle y, x \\rangle = \\overline{\\langle x, y \\rangle} = \\overline{0} = 0$.\n\n**Étape 2 : Développer le carré de la norme de la somme**\n\nOn exprime $\\|x+y\\|^2$ à l'aide du produit scalaire :\n\n$$ \\|x+y\\|^2 = \\langle x+y, x+y \\rangle $$\n\nPar (sesqui-)linéarité du produit scalaire, on développe :\n\n$$ \\|x+y\\|^2 = \\langle x, x \\rangle + \\langle x, y \\rangle + \\langle y, x \\rangle + \\langle y, y \\rangle $$\n\nEn utilisant la notation de la norme, cela devient :\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + \\langle x, y \\rangle + \\langle y, x \\rangle + \\|y\\|^2 $$\n\n**Étape 3 : Appliquer l'hypothèse d'orthogonalité**\n\nPuisque $x$ et $y$ sont orthogonaux, $\\langle x, y \\rangle = 0$ et $\\langle y, x \\rangle = 0$. En substituant ces valeurs dans l'équation précédente :\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + 0 + 0 + \\|y\\|^2 $$\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + \\|y\\|^2 $$\n\n**Conclusion :**\n\nNous avons démontré que pour deux vecteurs orthogonaux, le carré de la norme de leur somme est égal à la somme de leurs carrés, ce qui est l'énoncé du théorème de Pythagore.\n\n",
      "options": []
    },
    {
      "id": "7",
      "stackId": "a76472c4",
      "content": "#### Liberté d'une Famille Orthogonale\n\nProuver que toute famille orthogonale de vecteurs non nuls d'un espace préhilbertien est une famille libre.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nSoit $(v_1, v_2, \\dots, v_n)$ une famille orthogonale de vecteurs non nuls.\n\nPour prouver qu'elle est libre, partez de la définition : supposez qu'il existe une combinaison linéaire nulle de ces vecteurs, $\\sum_{i=1}^n \\lambda_i v_i = 0_E$.\n\nL'objectif est de montrer que tous les scalaires $\\lambda_i$ sont nuls. Pour isoler un scalaire particulier $\\lambda_j$, prenez le produit scalaire de la combinaison linéaire avec le vecteur $v_j$.\n\n</details>",
      "solution": "\n\nSoit $S = (v_1, v_2, \\dots, v_n)$ une famille orthogonale de vecteurs non nuls dans un espace préhilbertien $E$.\n\n**Étape 1 : Hypothèses sur la famille $S$**\n\n- **Orthogonale :** Pour tout $i \\neq j$, $\\langle v_i, v_j \\rangle = 0$.\n- **Vecteurs non nuls :** Pour tout $i$, $v_i \\neq 0_E$, ce qui implique $\\langle v_i, v_i \\rangle = \\|v_i\\|^2 > 0$.\n\n**Étape 2 : Écrire la condition de dépendance linéaire**\n\nPour montrer que $S$ est une famille libre, nous devons montrer que la seule combinaison linéaire de ses vecteurs qui soit égale au vecteur nul est celle où tous les coefficients sont nuls.\n\nSupposons qu'il existe des scalaires $\\lambda_1, \\lambda_2, \\dots, \\lambda_n$ tels que :\n\n$$ \\sum_{i=1}^n \\lambda_i v_i = 0_E $$\n\n**Étape 3 : Isoler un coefficient $\\lambda_j$**\n\nFixons un indice $j \\in \\{1, \\dots, n\\}$. Pour isoler $\\lambda_j$, calculons le produit scalaire de l'équation ci-dessus avec le vecteur $v_j$ :\n\n$$ \\left\\langle \\sum_{i=1}^n \\lambda_i v_i, v_j \\right\\rangle = \\langle 0_E, v_j \\rangle $$\n\nLe membre de droite est nul. Utilisons la linéarité à gauche pour le membre de gauche :\n\n$$ \\sum_{i=1}^n \\lambda_i \\langle v_i, v_j \\rangle = 0 $$\n\n**Étape 4 : Utiliser l'orthogonalité**\n\nLa famille est orthogonale, donc $\\langle v_i, v_j \\rangle = 0$ pour tous les indices $i$ différents de $j$. La somme se simplifie donc radicalement, car un seul terme est potentiellement non nul (celui pour $i=j$) :\n\n$$ \\lambda_1 \\langle v_1, v_j \\rangle + \\dots + \\lambda_j \\langle v_j, v_j \\rangle + \\dots + \\lambda_n \\langle v_n, v_j \\rangle = 0 $$\n\n$$ 0 + \\dots + \\lambda_j \\langle v_j, v_j \\rangle + \\dots + 0 = 0 $$\n\n$$ \\lambda_j \\|v_j\\|^2 = 0 $$\n\n**Étape 5 : Conclure sur la nullité du coefficient**\n\nPar hypothèse, tous les vecteurs $v_j$ de la famille sont non nuls, donc $\\|v_j\\|^2 \\neq 0$.\n\nPuisque le produit $\\lambda_j \\|v_j\\|^2$ est nul et que $\\|v_j\\|^2$ n'est pas nul, c'est nécessairement le scalaire $\\lambda_j$ qui doit être nul.\n\n$$ \\lambda_j = 0 $$\n\nComme ce raisonnement est valable pour n'importe quel indice $j$ de $1$ à $n$, nous avons montré que $\\lambda_1 = \\lambda_2 = \\dots = \\lambda_n = 0$.\n\n**Conclusion :**\n\nLa seule combinaison linéaire des vecteurs de $S$ qui donne le vecteur nul est la combinaison triviale. La famille $S$ est donc libre.\n\n",
      "options": []
    },
    {
      "id": "8",
      "stackId": "a76472c4",
      "content": "#### Expression des Coordonnées dans une Base Orthonormée\n\nSoit $\\mathcal{B} = (e_1, \\dots, e_n)$ une base orthonormée d'un espace préhilbertien $E$. Prouver que pour tout vecteur $x \\in E$, ses coordonnées $(x_1, \\dots, x_n)$ dans la base $\\mathcal{B}$ sont données par $x_i = \\langle x, e_i \\rangle$. En d'autres termes, prouver que :\n\n$$ x = \\sum_{i=1}^n \\langle x, e_i \\rangle e_i $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nPuisque $\\mathcal{B}$ est une base, tout vecteur $x$ peut s'écrire de manière unique comme une combinaison linéaire $x = \\sum_{j=1}^n x_j e_j$, où les $x_j$ sont les coordonnées de $x$.\n\nVotre objectif est de trouver la valeur d'un coefficient particulier, disons $x_i$.\n\nPour cela, calculez le produit scalaire de l'expression de $x$ avec le vecteur de base $e_i$. Utilisez la propriété fondamentale d'une base orthonormée : $\\langle e_j, e_i \\rangle = \\delta_{ji}$.\n\n</details>",
      "solution": "\n\nSoit $\\mathcal{B} = (e_1, \\dots, e_n)$ une base orthonormée de $E$. Soit $x$ un vecteur quelconque de $E$.\n\n**Étape 1 : Décomposition de $x$ dans la base $\\mathcal{B}$**\n\nPuisque $\\mathcal{B}$ est une base de $E$, il existe un unique n-uplet de scalaires $(x_1, \\dots, x_n)$, appelés coordonnées de $x$ dans $\\mathcal{B}$, tel que :\n\n$$ x = \\sum_{j=1}^n x_j e_j $$\n\n**Étape 2 : Calcul du produit scalaire avec un vecteur de base $e_i$**\n\nFixons un indice $i \\in \\{1, \\dots, n\\}$. Calculons le produit scalaire de $x$ avec $e_i$ :\n\n$$ \\langle x, e_i \\rangle = \\left\\langle \\sum_{j=1}^n x_j e_j, e_i \\right\\rangle $$\n\nPar linéarité (ou semi-linéarité selon la variable) du produit scalaire, on peut écrire :\n\n$$ \\langle x, e_i \\rangle = \\sum_{j=1}^n \\langle x_j e_j, e_i \\rangle $$\n\nDans le cas euclidien (réel) : $\\langle x, e_i \\rangle = \\sum_{j=1}^n x_j \\langle e_j, e_i \\rangle$.\n\nDans le cas hermitien (complexe) : $\\langle x, e_i \\rangle = \\sum_{j=1}^n x_j \\langle e_j, e_i \\rangle$. La formule est identique.\n\n**Étape 3 : Utilisation de l'orthonormalité de la base**\n\nLa base $\\mathcal{B}$ est orthonormée, ce qui signifie par définition que $\\langle e_j, e_i \\rangle = \\delta_{ji}$, où $\\delta_{ji}$ est le symbole de Kronecker ($\\delta_{ji}=1$ si $j=i$ et $\\delta_{ji}=0$ si $j \\neq i$).\n\nSubstituons cette propriété dans la somme. Tous les termes de la somme vont s'annuler, sauf celui pour lequel l'indice $j$ est égal à $i$ :\n\n$$ \\langle x, e_i \\rangle = x_1 \\langle e_1, e_i \\rangle + \\dots + x_i \\langle e_i, e_i \\rangle + \\dots + x_n \\langle e_n, e_i \\rangle $$\n\n$$ \\langle x, e_i \\rangle = x_1 \\cdot 0 + \\dots + x_i \\cdot 1 + \\dots + x_n \\cdot 0 $$\n\n$$ \\langle x, e_i \\rangle = x_i $$\n\n**Étape 4 : Conclusion**\n\nNous avons montré que la i-ème coordonnée $x_i$ du vecteur $x$ est égale au produit scalaire $\\langle x, e_i \\rangle$. Ce résultat étant valable pour tout $i \\in \\{1, \\dots, n\\}$, on peut substituer ces expressions dans la décomposition de $x$ :\n\n$$ x = \\sum_{i=1}^n x_i e_i = \\sum_{i=1}^n \\langle x, e_i \\rangle e_i $$\n\nCeci prouve la formule requise.\n\n",
      "options": []
    },
    {
      "id": "9",
      "stackId": "a76472c4",
      "content": "#### Caractérisation des Endomorphismes Orthogonaux\n\nSoit $f$ un endomorphisme d'un espace euclidien $E$. Prouver que $f$ est un endomorphisme orthogonal (c'est-à-dire qu'il préserve le produit scalaire) si et seulement si il préserve la norme.\n\n$$ (\\forall x,y \\in E, \\langle f(x), f(y) \\rangle = \\langle x, y \\rangle) \\iff (\\forall z \\in E, \\|f(z)\\| = \\|z\\|) $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nL'implication \"préserve le produit scalaire $\\implies$ préserve la norme\" est directe. Il suffit de considérer le cas $x=y$.\n\nPour l'implication \"préserve la norme $\\implies$ préserve le produit scalaire\", utilisez l'identité de polarisation qui exprime le produit scalaire en fonction de la norme. L'identité pour le cas euclidien est :\n\n$$ \\langle u, v \\rangle = \\frac{1}{2} (\\|u+v\\|^2 - \\|u\\|^2 - \\|v\\|^2) $$\n\nAppliquez cette identité à $\\langle f(x), f(y) \\rangle$.\n\n</details>",
      "solution": "\n\n**Partie 1 : Un endomorphisme orthogonal préserve la norme.**\n\nSupposons que $f$ est un endomorphisme orthogonal. Par définition, pour tous $x, y \\in E$, on a :\n\n$$ \\langle f(x), f(y) \\rangle = \\langle x, y \\rangle $$\n\nPour montrer que $f$ préserve la norme, nous devons prouver que $\\|f(z)\\| = \\|z\\|$ pour tout $z \\in E$. Cela est équivalent à $\\|f(z)\\|^2 = \\|z\\|^2$.\n\nSoit $z \\in E$. On a :\n\n$$ \\|f(z)\\|^2 = \\langle f(z), f(z) \\rangle $$\n\nEn utilisant la propriété de conservation du produit scalaire avec $x=z$ et $y=z$, on obtient :\n\n$$ \\langle f(z), f(z) \\rangle = \\langle z, z \\rangle = \\|z\\|^2 $$\n\nDonc, $\\|f(z)\\|^2 = \\|z\\|^2$. Comme les normes sont positives, on en déduit $\\|f(z)\\| = \\|z\\|$.\n\nL'implication est démontrée.\n\n**Partie 2 : Un endomorphisme qui préserve la norme est orthogonal.**\n\nSupposons maintenant que $f$ préserve la norme, c'est-à-dire que pour tout $z \\in E$, $\\|f(z)\\| = \\|z\\|$. Nous voulons montrer que $\\langle f(x), f(y) \\rangle = \\langle x, y \\rangle$ pour tous $x,y \\in E$.\n\n**Étape 1 : Utiliser l'identité de polarisation**\n\nL'identité de polarisation dans un espace euclidien permet d'exprimer le produit scalaire à partir de la norme :\n\n$$ \\langle u, v \\rangle = \\frac{1}{2} (\\|u+v\\|^2 - \\|u\\|^2 - \\|v\\|^2) $$\n\nAppliquons cette identité au produit scalaire $\\langle f(x), f(y) \\rangle$ en posant $u = f(x)$ et $v = f(y)$.\n\n$$ \\langle f(x), f(y) \\rangle = \\frac{1}{2} (\\|f(x)+f(y)\\|^2 - \\|f(x)\\|^2 - \\|f(y)\\|^2) $$\n\n**Étape 2 : Utiliser la linéarité de $f$ et l'hypothèse de conservation de la norme**\n\nPar linéarité de $f$, on a $f(x)+f(y) = f(x+y)$. On peut donc réécrire le premier terme :\n\n$$ \\|f(x)+f(y)\\|^2 = \\|f(x+y)\\|^2 $$\n\nMaintenant, nous utilisons notre hypothèse : $f$ préserve la norme. Donc, pour tout vecteur $z$, $\\|f(z)\\|^2 = \\|z\\|^2$. Appliquons ceci à $x$, $y$ et $x+y$ :\n\n- $\\|f(x)\\|^2 = \\|x\\|^2$\n- $\\|f(y)\\|^2 = \\|y\\|^2$\n- $\\|f(x+y)\\|^2 = \\|x+y\\|^2$\n\n**Étape 3 : Substituer et conclure**\n\nEn substituant ces égalités dans l'expression de $\\langle f(x), f(y) \\rangle$ :\n\n$$ \\langle f(x), f(y) \\rangle = \\frac{1}{2} (\\|x+y\\|^2 - \\|x\\|^2 - \\|y\\|^2) $$\n\nOn reconnaît le membre de droite comme étant l'expression de $\\langle x, y \\rangle$ par l'identité de polarisation.\n\n$$ \\langle f(x), f(y) \\rangle = \\langle x, y \\rangle $$\n\n**Conclusion :**\n\nNous avons démontré les deux implications, ce qui prouve l'équivalence entre la préservation du produit scalaire et la préservation de la norme pour un endomorphisme en espace euclidien.\n\n",
      "options": []
    },
    {
      "id": "10",
      "stackId": "a76472c4",
      "content": "#### Adjoint d'une Composition d'Endomorphismes\n\nSoient $f$ et $g$ deux endomorphismes d'un espace préhilbertien $E$ de dimension finie. Prouver que l'adjoint de la composition $f \\circ g$ est la composition des adjoints en ordre inversé :\n\n$$ (f \\circ g)^* = g^* \\circ f^* $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nL'adjoint d'un endomorphisme $h$, noté $h^*$, est défini par la relation unique $\\langle h(x), y \\rangle = \\langle x, h^*(y) \\rangle$ pour tous $x, y \\in E$.\n\nVotre but est de trouver un endomorphisme $h'$ tel que $\\langle (f \\circ g)(x), y \\rangle = \\langle x, h'(y) \\rangle$. Par unicité de l'adjoint, vous aurez alors $h' = (f \\circ g)^*$.\n\nCommencez par $\\langle (f \\circ g)(x), y \\rangle = \\langle f(g(x)), y \\rangle$ et appliquez la définition de l'adjoint successivement pour $f$ puis pour $g$.\n\n</details>",
      "solution": "\n\nSoient $f, g$ deux endomorphismes de $E$. Nous cherchons à déterminer l'endomorphisme $(f \\circ g)^*$.\n\n**Étape 1 : Définition de l'adjoint**\n\nPar définition, l'adjoint $(f \\circ g)^*$ est l'unique endomorphisme qui vérifie pour tous $x, y \\in E$ :\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle x, (f \\circ g)^*(y) \\rangle $$\n\nNotre stratégie est de partir du membre de gauche et de le transformer en une expression de la forme $\\langle x, h(y) \\rangle$. L'endomorphisme $h$ sera alors, par unicité, l'adjoint recherché.\n\n**Étape 2 : Application successive de la définition de l'adjoint**\n\nPartons du membre de gauche.\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle f(g(x)), y \\rangle $$\n\nConsidérons le vecteur $g(x)$ comme un seul bloc. On peut appliquer la définition de l'adjoint de $f$, qui est $f^*$. On a $\\langle f(u), v \\rangle = \\langle u, f^*(v) \\rangle$. En posant $u = g(x)$ et $v = y$ :\n\n$$ \\langle f(g(x)), y \\rangle = \\langle g(x), f^*(y) \\rangle $$\n\nMaintenant, nous avons une nouvelle expression $\\langle g(x), f^*(y) \\rangle$. On peut y appliquer la définition de l'adjoint de $g$, qui est $g^*$. On a $\\langle g(u), v \\rangle = \\langle u, g^*(v) \\rangle$. En posant $u = x$ et $v = f^*(y)$ :\n\n$$ \\langle g(x), f^*(y) \\rangle = \\langle x, g^*(f^*(y)) \\rangle $$\n\n**Étape 3 : Identification de l'adjoint**\n\nEn combinant les étapes, nous avons montré que pour tous $x, y \\in E$ :\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle x, g^*(f^*(y)) \\rangle $$\n\nL'expression $g^*(f^*(y))$ peut s'écrire comme la composition $(g^* \\circ f^*)(y)$.\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle x, (g^* \\circ f^*)(y) \\rangle $$\n\nEn comparant cette égalité avec la relation de définition $\\langle (f \\circ g)(x), y \\rangle = \\langle x, (f \\circ g)^*(y) \\rangle$, par unicité de l'endomorphisme adjoint, on doit avoir :\n\n$$ (f \\circ g)^* = g^* \\circ f^* $$\n\n**Conclusion :**\n\nL'adjoint de la composition de deux endomorphismes est bien la composition de leurs adjoints, avec inversion de l'ordre.\n\n",
      "options": []
    }
  ]
}