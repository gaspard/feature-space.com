{
  "info": {
    "id": "70793e46",
    "title": "Espaces Euclidiens et Hermitiens - preuves (A)",
    "type": "proofs",
    "level": "regular",
    "chapter": "Espaces Euclidiens et Hermitiens",
    "course": "Géométrie",
    "tags": [
      "Espaces Euclidiens",
      "Espaces Hermitiens",
      "Produit scalaire",
      "Gram-Schmidt",
      "Projection orthogonale",
      "Endomorphismes adjoints",
      "Théorème de Riesz"
    ],
    "count": 10
  },
  "cards": [
    {
      "id": "1",
      "stackId": "70793e46",
      "content": "#### Propriété de Réalité de la Forme Hermitienne\n\nProuvez que pour une forme sesquilinéaire hermitienne $\\varphi$ sur un espace vectoriel complexe $E$, la valeur $\\varphi(x, x)$ est toujours un nombre réel pour tout vecteur $x \\in E$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nLa clé de cette preuve réside dans l'utilisation directe de la définition d'une forme hermitienne.\n\nRappelez-vous la propriété de symétrie hermitienne : $\\varphi(x, y) = \\overline{\\varphi(y, x)}$.\n\nAppliquez cette propriété au cas particulier où $y=x$. Vous obtiendrez une relation entre $\\varphi(x, x)$ et son propre conjugué complexe.\n\nRappelez-vous qu'un nombre complexe $z$ est réel si et seulement si $z = \\bar{z}$.\n\n</details>",
      "solution": "\n\nSoit $E$ un espace vectoriel sur $\\mathbb{C}$ et $\\varphi: E \\times E \\to \\mathbb{C}$ une forme sesquilinéaire hermitienne.\n\n**Étape 1 : Énoncer la propriété de symétrie hermitienne**\n\nPar définition, une forme hermitienne satisfait la condition suivante pour tous les vecteurs $x, y \\in E$ :\n\n$$ \\varphi(x, y) = \\overline{\\varphi(y, x)} $$\n\n**Étape 2 : Appliquer la propriété au cas $y=x$**\n\nNous voulons étudier la nature de $\\varphi(x, x)$. Posons $y=x$ dans la relation de symétrie hermitienne. On obtient :\n\n$$ \\varphi(x, x) = \\overline{\\varphi(x, x)} $$\n\n**Étape 3 : Conclure en utilisant les propriétés des nombres complexes**\n\nSoit $z = \\varphi(x, x)$. L'équation de l'étape 2 devient $z = \\bar{z}$.\n\nUn nombre complexe est égal à son propre conjugué si et seulement si sa partie imaginaire est nulle. C'est la définition d'un nombre réel.\n\n**Conclusion :**\n\nPuisque $\\varphi(x, x)$ est égal à son propre conjugué complexe, nous pouvons conclure que $\\varphi(x, x)$ est un nombre réel pour tout $x \\in E$. Cette propriété est fondamentale car elle permet de définir la notion de positivité pour ces formes, qui est à la base de la définition d'une norme.\n\n",
      "options": []
    },
    {
      "id": "2",
      "stackId": "70793e46",
      "content": "#### Nullité de la Forme sur le Vecteur Nul\n\nProuvez que pour toute forme bilinéaire ou sesquilinéaire $\\varphi$ sur un espace vectoriel $E$, on a $\\varphi(x, 0_E) = \\varphi(0_E, x) = 0$ pour tout $x \\in E$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nUtilisez la propriété de linéarité (à gauche ou à droite) de la forme.\n\nRappelez-vous que le vecteur nul $0_E$ peut s'écrire de plusieurs manières, par exemple $0_E = 0 \\cdot y$ pour n'importe quel vecteur $y$, ou $0_E = 0_E + 0_E$.\n\nPour prouver $\\varphi(0_E, x) = 0$, utilisez la linéarité à gauche. Écrivez $0_E = 0 \\cdot 0_E$ et sortez le scalaire 0.\n\nPour prouver $\\varphi(x, 0_E) = 0$, utilisez la linéarité à droite (ou la semi-linéarité dans le cas sesquilinéaire). La démarche est similaire.\n\n</details>",
      "solution": "\n\nSoit $E$ un $\\mathbb{K}$-espace vectoriel et $\\varphi: E \\times E \\to \\mathbb{K}$ une forme bilinéaire ou sesquilinéaire. Soit $x \\in E$ un vecteur quelconque.\n\n**Étape 1 : Prouver que $\\varphi(0_E, x) = 0$**\n\nNous utilisons la linéarité à gauche de $\\varphi$. Pour tous vecteurs $u_1, u_2 \\in E$ et tout scalaire $\\lambda \\in \\mathbb{K}$, on a $\\varphi(\\lambda u_1 + u_2, x) = \\lambda \\varphi(u_1, x) + \\varphi(u_2, x)$.\n\nChoisissons $\\lambda=0$ et $u_1 = x$. La propriété de linéarité implique :\n\n$$ \\varphi(0 \\cdot x, x) = 0 \\cdot \\varphi(x, x) $$\n\nPuisque $0 \\cdot x = 0_E$ dans l'espace vectoriel $E$, et $0 \\cdot \\varphi(x, x) = 0$ dans le corps $\\mathbb{K}$, on obtient :\n\n$$ \\varphi(0_E, x) = 0 $$\n\n**Étape 2 : Prouver que $\\varphi(x, 0_E) = 0$**\n\nLa preuve est similaire en utilisant la propriété de la deuxième variable.\n\n*   **Cas bilinéaire :** On utilise la linéarité à droite.\n\n    $$ \\varphi(x, 0 \\cdot x) = 0 \\cdot \\varphi(x, x) $$\n\n    Ce qui donne :\n\n    $$ \\varphi(x, 0_E) = 0 $$\n\n*   **Cas sesquilinéaire :** On utilise la semi-linéarité à droite. Le scalaire sort conjugué.\n\n    $$ \\varphi(x, 0 \\cdot x) = \\bar{0} \\cdot \\varphi(x, x) $$\n\n    Puisque $\\bar{0} = 0$, on obtient :\n\n    $$ \\varphi(x, 0_E) = 0 $$\n\n**Conclusion :**\n\nDans tous les cas, en utilisant les propriétés de linéarité ou de semi-linéarité par rapport à l'une ou l'autre des variables, nous avons montré que le produit de n'importe quel vecteur avec le vecteur nul est le scalaire nul.\n\n",
      "options": []
    },
    {
      "id": "3",
      "stackId": "70793e46",
      "content": "#### Inégalité de Cauchy-Schwarz (Cas Réel)\n\nProuvez l'inégalité de Cauchy-Schwarz pour un espace euclidien $(E, \\langle \\cdot, \\cdot \\rangle)$. Pour tous vecteurs $x, y \\in E$, on a :\n\n$$ |\\langle x, y \\rangle| \\le \\|x\\| \\|y\\| $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nL'idée principale est d'utiliser la positivité du produit scalaire. Pour tout vecteur $v \\in E$, on a $\\langle v, v \\rangle = \\|v\\|^2 \\ge 0$.\n\nConsidérez le vecteur $v = x + \\lambda y$ pour un scalaire réel $\\lambda \\in \\mathbb{R}$.\n\nDéveloppez l'expression $\\|x + \\lambda y\\|^2 = \\langle x + \\lambda y, x + \\lambda y \\rangle$. Vous obtiendrez un polynôme du second degré en $\\lambda$.\n\nPuisque ce polynôme est toujours positif ou nul (car c'est une norme au carré), que pouvez-vous dire de son discriminant $\\Delta$ ?\n\nL'inégalité sur le discriminant vous donnera directement le résultat attendu.\n\n</details>",
      "solution": "\n\nSoit $(E, \\langle \\cdot, \\cdot \\rangle)$ un espace euclidien. Soient $x, y \\in E$.\n\n**Cas 1 : $y = 0_E$**\n\nSi $y$ est le vecteur nul, alors $\\langle x, y \\rangle = \\langle x, 0_E \\rangle = 0$ et $\\|y\\| = 0$.\n\nL'inégalité devient $|0| \\le \\|x\\| \\cdot 0$, soit $0 \\le 0$, ce qui est vrai.\n\n**Cas 2 : $y \\neq 0_E$**\n\n**Étape 1 : Construire un polynôme du second degré**\n\nPour tout scalaire $\\lambda \\in \\mathbb{R}$, considérons le vecteur $x + \\lambda y$. Par la propriété de positivité du produit scalaire, la norme au carré de ce vecteur est toujours positive ou nulle :\n\n$$ \\|x + \\lambda y\\|^2 \\ge 0 $$\n\nDéveloppons cette expression en utilisant la bilinéarité du produit scalaire :\n\n$$ \\langle x + \\lambda y, x + \\lambda y \\rangle = \\langle x, x \\rangle + \\langle x, \\lambda y \\rangle + \\langle \\lambda y, x \\rangle + \\langle \\lambda y, \\lambda y \\rangle $$\n\n$$ = \\langle x, x \\rangle + \\lambda \\langle x, y \\rangle + \\lambda \\langle y, x \\rangle + \\lambda^2 \\langle y, y \\rangle $$\n\nPuisque le produit scalaire est symétrique ($\\langle x,y \\rangle = \\langle y,x \\rangle$), cela se simplifie en :\n\n$$ \\|x\\|^2 + 2\\lambda \\langle x, y \\rangle + \\lambda^2 \\|y\\|^2 \\ge 0 $$\n\n**Étape 2 : Analyser le polynôme**\n\nSoit $P(\\lambda) = \\|y\\|^2 \\lambda^2 + 2\\langle x, y \\rangle \\lambda + \\|x\\|^2$.\n\nCeci est un polynôme du second degré en $\\lambda$ de la forme $a\\lambda^2 + b\\lambda + c$, avec $a=\\|y\\|^2$, $b=2\\langle x, y \\rangle$ et $c=\\|x\\|^2$.\n\nComme $y \\neq 0_E$, on a $a = \\|y\\|^2 > 0$.\n\nLa condition $P(\\lambda) \\ge 0$ pour tout $\\lambda \\in \\mathbb{R}$ signifie que ce polynôme (qui représente une parabole ouverte vers le haut) ne peut avoir au plus qu'une seule racine réelle. Son discriminant $\\Delta$ doit donc être négatif ou nul.\n\n**Étape 3 : Calculer le discriminant et conclure**\n\nLe discriminant du polynôme est $\\Delta = b^2 - 4ac$.\n\n$$ \\Delta = (2\\langle x, y \\rangle)^2 - 4(\\|y\\|^2)(\\|x\\|^2) \\le 0 $$\n\n$$ 4\\langle x, y \\rangle^2 - 4\\|x\\|^2 \\|y\\|^2 \\le 0 $$\n\n$$ 4\\langle x, y \\rangle^2 \\le 4\\|x\\|^2 \\|y\\|^2 $$\n\n$$ \\langle x, y \\rangle^2 \\le \\|x\\|^2 \\|y\\|^2 $$\n\nEn prenant la racine carrée des deux côtés (qui sont positifs), on obtient :\n\n$$ \\sqrt{\\langle x, y \\rangle^2} \\le \\sqrt{\\|x\\|^2 \\|y\\|^2} $$\n\n$$ |\\langle x, y \\rangle| \\le \\|x\\| \\|y\\| $$\n\n**Conclusion :**\n\nL'inégalité est donc prouvée pour tous les vecteurs $x, y \\in E$.\n\n",
      "options": []
    },
    {
      "id": "4",
      "stackId": "70793e46",
      "content": "#### Inégalité Triangulaire pour la Norme\n\nProuvez que la norme $\\| \\cdot \\|$ induite par un produit scalaire $\\langle \\cdot, \\cdot \\rangle$ sur un espace euclidien ou hermitien $E$ vérifie l'inégalité triangulaire :\n\n$$ \\|x+y\\| \\le \\|x\\| + \\|y\\| $$\n\npour tous les vecteurs $x, y \\in E$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nComme les deux membres de l'inégalité sont positifs, prouver $\\|x+y\\| \\le \\|x\\| + \\|y\\|$ est équivalent à prouver $\\|x+y\\|^2 \\le (\\|x\\| + \\|y\\|)^2$.\n\nCommencez par développer le membre de gauche, $\\|x+y\\|^2 = \\langle x+y, x+y \\rangle$.\n\nDéveloppez ensuite le membre de droite, $(\\|x\\| + \\|y\\|)^2$.\n\nComparez les deux expressions développées. À un moment, vous devriez avoir besoin d'utiliser l'inégalité de Cauchy-Schwarz pour majorer un terme. Dans le cas hermitien, n'oubliez pas que $\\langle y,x \\rangle = \\overline{\\langle x,y \\rangle}$, et que pour tout nombre complexe $z$, $z+\\bar{z} = 2\\text{Re}(z)$ et $\\text{Re}(z) \\le |z|$.\n\n</details>",
      "solution": "\n\nSoient $x, y \\in E$. Nous voulons prouver que $\\|x+y\\| \\le \\|x\\| + \\|y\\|$.\n\nPuisque les normes sont des nombres réels positifs, cette inégalité est équivalente à $\\|x+y\\|^2 \\le (\\|x\\| + \\|y\\|)^2$.\n\n**Étape 1 : Développer le membre de gauche**\n\nEn utilisant la définition de la norme et les propriétés du produit scalaire :\n\n$$ \\|x+y\\|^2 = \\langle x+y, x+y \\rangle $$\n\n$$ = \\langle x, x \\rangle + \\langle x, y \\rangle + \\langle y, x \\rangle + \\langle y, y \\rangle $$\n\n$$ = \\|x\\|^2 + \\langle x, y \\rangle + \\overline{\\langle x, y \\rangle} + \\|y\\|^2 $$\n\nRappelons que pour tout nombre complexe $z$, $z + \\bar{z} = 2\\text{Re}(z)$, où $\\text{Re}(z)$ est la partie réelle de $z$. Donc :\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + 2\\text{Re}(\\langle x, y \\rangle) + \\|y\\|^2 $$\n\n(Note : dans le cas réel, $\\text{Re}(\\langle x, y \\rangle) = \\langle x, y \\rangle$, la formule reste donc valable).\n\n**Étape 2 : Utiliser l'inégalité de Cauchy-Schwarz**\n\nPour tout nombre complexe $z$, on sait que sa partie réelle est inférieure ou égale à son module : $\\text{Re}(z) \\le |z|$.\n\nDonc, $\\text{Re}(\\langle x, y \\rangle) \\le |\\langle x, y \\rangle|$.\n\nEn appliquant cette inégalité à l'expression de l'étape 1, nous obtenons :\n\n$$ \\|x+y\\|^2 \\le \\|x\\|^2 + 2|\\langle x, y \\rangle| + \\|y\\|^2 $$\n\nMaintenant, nous utilisons l'inégalité de Cauchy-Schwarz, $|\\langle x, y \\rangle| \\le \\|x\\| \\|y\\|$, pour majorer ce terme :\n\n$$ \\|x+y\\|^2 \\le \\|x\\|^2 + 2\\|x\\|\\|y\\| + \\|y\\|^2 $$\n\n**Étape 3 : Conclure**\n\nLe membre de droite est une identité remarquable :\n\n$$ \\|x\\|^2 + 2\\|x\\|\\|y\\| + \\|y\\|^2 = (\\|x\\| + \\|y\\|)^2 $$\n\nNous avons donc montré que :\n\n$$ \\|x+y\\|^2 \\le (\\|x\\| + \\|y\\|)^2 $$\n\nPuisque la fonction racine carrée est croissante sur $\\mathbb{R}^+$, nous pouvons prendre la racine carrée des deux côtés pour obtenir :\n\n$$ \\|x+y\\| \\le \\|x\\| + \\|y\\| $$\n\n**Conclusion :**\n\nL'inégalité triangulaire est vérifiée, ce qui confirme que l'application $\\|x\\| = \\sqrt{\\langle x, x \\rangle}$ est bien une norme.\n\n",
      "options": []
    },
    {
      "id": "5",
      "stackId": "70793e46",
      "content": "#### Théorème de Pythagore\n\nProuvez que si deux vecteurs $x$ et $y$ d'un espace euclidien ou hermitien sont orthogonaux, alors $\\|x+y\\|^2 = \\|x\\|^2 + \\|y\\|^2$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nLa preuve est une application très directe de la définition de la norme.\n\nCommencez par écrire l'expression $\\|x+y\\|^2$ en utilisant le produit scalaire : $\\|x+y\\|^2 = \\langle x+y, x+y \\rangle$.\n\nDéveloppez ce produit scalaire en utilisant la bilinéarité (ou sesquilinéarité).\n\nUtilisez l'hypothèse que $x$ et $y$ sont orthogonaux. Qu'est-ce que cela signifie pour $\\langle x, y \\rangle$ ? Et pour $\\langle y, x \\rangle$ ? Simplifiez l'expression développée.\n\n</details>",
      "solution": "\n\nSoient $x$ et $y$ deux vecteurs dans un espace euclidien ou hermitien $E$.\n\n**Étape 1 : Hypothèse d'orthogonalité**\n\nL'hypothèse est que $x$ et $y$ sont orthogonaux. Par définition, cela signifie que leur produit scalaire est nul :\n\n$$ \\langle x, y \\rangle = 0 $$\n\nDans le cas hermitien, cela implique aussi $\\langle y, x \\rangle = \\overline{\\langle x, y \\rangle} = \\bar{0} = 0$.\n\nDans le cas euclidien, $\\langle y, x \\rangle = \\langle x, y \\rangle = 0$.\n\nDonc, dans tous les cas, $\\langle x, y \\rangle = 0$ et $\\langle y, x \\rangle = 0$.\n\n**Étape 2 : Développer la norme au carré de la somme**\n\nNous partons de l'expression $\\|x+y\\|^2$ et utilisons la définition de la norme :\n\n$$ \\|x+y\\|^2 = \\langle x+y, x+y \\rangle $$\n\nEn utilisant les propriétés de linéarité du produit scalaire, nous développons cette expression :\n\n$$ \\|x+y\\|^2 = \\langle x, x \\rangle + \\langle x, y \\rangle + \\langle y, x \\rangle + \\langle y, y \\rangle $$\n\n**Étape 3 : Appliquer l'hypothèse et conclure**\n\nNous remplaçons maintenant les termes $\\langle x, y \\rangle$ et $\\langle y, x \\rangle$ par 0, conformément à l'hypothèse d'orthogonalité :\n\n$$ \\|x+y\\|^2 = \\langle x, x \\rangle + 0 + 0 + \\langle y, y \\rangle $$\n\nEn revenant à la notation de la norme, où $\\|v\\|^2 = \\langle v, v \\rangle$, nous obtenons :\n\n$$ \\|x+y\\|^2 = \\|x\\|^2 + \\|y\\|^2 $$\n\n**Conclusion :**\n\nNous avons démontré le théorème de Pythagore dans le cadre général des espaces préhilbertiens. Ce résultat étend la relation géométrique familière des triangles rectangles à des espaces abstraits de dimension quelconque.\n\n",
      "options": []
    },
    {
      "id": "6",
      "stackId": "70793e46",
      "content": "#### Identité du Parallélogramme\n\nProuvez l'identité du parallélogramme pour une norme induite par un produit scalaire. Pour tous vecteurs $x, y \\in E$ :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = 2(\\|x\\|^2 + \\|y\\|^2) $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nLa preuve est un calcul direct.\n\nCommencez par développer le premier terme, $\\|x+y\\|^2$, en utilisant le produit scalaire.\n\nFaites de même pour le second terme, $\\|x-y\\|^2 = \\langle x-y, x-y \\rangle$. Soyez attentif aux signes.\n\nAdditionnez les deux expressions développées. Vous devriez voir des termes s'annuler.\n\nRegroupez les termes restants pour obtenir l'expression de droite.\n\n</details>",
      "solution": "\n\nSoient $x, y$ deux vecteurs d'un espace euclidien ou hermitien $E$.\n\n**Étape 1 : Développer le premier terme**\n\nNous développons $\\|x+y\\|^2$ en utilisant le produit scalaire :\n\n$$ \\|x+y\\|^2 = \\langle x+y, x+y \\rangle $$\n\n$$ = \\langle x, x \\rangle + \\langle x, y \\rangle + \\langle y, x \\rangle + \\langle y, y \\rangle \\quad (*)$$\n\n**Étape 2 : Développer le second terme**\n\nDe la même manière, nous développons $\\|x-y\\|^2$ :\n\n$$ \\|x-y\\|^2 = \\langle x-y, x-y \\rangle $$\n\n$$ = \\langle x, x \\rangle - \\langle x, y \\rangle - \\langle y, x \\rangle + \\langle y, y \\rangle \\quad (**) $$\n\n**Étape 3 : Additionner les deux expressions**\n\nMaintenant, nous additionnons les résultats des équations $(*)$ et $(**)$ :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = (\\langle x, x \\rangle + \\langle x, y \\rangle + \\langle y, x \\rangle + \\langle y, y \\rangle) + (\\langle x, x \\rangle - \\langle x, y \\rangle - \\langle y, x \\rangle + \\langle y, y \\rangle) $$\n\nLes termes \"croisés\" s'annulent : $\\langle x, y \\rangle$ s'annule avec $-\\langle x, y \\rangle$, et $\\langle y, x \\rangle$ s'annule avec $-\\langle y, x \\rangle$. Il nous reste :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = \\langle x, x \\rangle + \\langle y, y \\rangle + \\langle x, x \\rangle + \\langle y, y \\rangle $$\n\n$$ = 2\\langle x, x \\rangle + 2\\langle y, y \\rangle $$\n\n**Étape 4 : Conclure**\n\nEn revenant à la notation de la norme, $\\langle v,v \\rangle = \\|v\\|^2$, nous obtenons :\n\n$$ \\|x+y\\|^2 + \\|x-y\\|^2 = 2\\|x\\|^2 + 2\\|y\\|^2 $$\n\n$$ = 2(\\|x\\|^2 + \\|y\\|^2) $$\n\n**Conclusion :**\n\nL'identité est prouvée. Cette relation est fondamentale car elle caractérise les normes qui proviennent d'un produit scalaire. Si une norme vérifie cette identité, alors on peut définir un produit scalaire qui induit cette norme (via les identités de polarisation).\n\n",
      "options": []
    },
    {
      "id": "7",
      "stackId": "70793e46",
      "content": "#### Liberté d'une Famille Orthogonale\n\nProuvez que toute famille orthogonale de vecteurs non nuls est une famille libre.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nPour prouver qu'une famille de vecteurs $(v_1, v_2, \\dots, v_n)$ est libre, vous devez montrer que la seule combinaison linéaire de ces vecteurs qui égale le vecteur nul est celle où tous les coefficients sont nuls.\n\nCommencez par poser une combinaison linéaire égale au vecteur nul :\n\n$$ \\sum_{i=1}^n \\lambda_i v_i = 0_E $$\n\nL'objectif est de montrer que $\\lambda_j = 0$ pour chaque $j \\in \\{1, \\dots, n\\}$.\n\nPour isoler un coefficient particulier $\\lambda_j$, utilisez l'arme de l'orthogonalité : faites le produit scalaire de l'équation entière avec le vecteur $v_j$.\n\nDéveloppez le produit scalaire $\\langle \\sum_{i=1}^n \\lambda_i v_i, v_j \\rangle$. Que se passe-t-il avec les termes où $i \\neq j$ ? Que reste-t-il ?\n\nN'oubliez pas d'utiliser l'hypothèse que les vecteurs $v_j$ sont non nuls. Qu'est-ce que cela implique pour $\\|v_j\\|^2$ ?\n\n</details>",
      "solution": "\n\nSoit $(v_1, v_2, \\dots, v_n)$ une famille orthogonale de vecteurs d'un espace euclidien ou hermitien $E$. On suppose de plus que pour tout $i$, $v_i \\neq 0_E$.\n\n**Étape 1 : Poser l'équation de dépendance linéaire**\n\nPour montrer que la famille est libre, nous devons prouver que si une combinaison linéaire de ces vecteurs est nulle, alors tous les coefficients de cette combinaison sont nuls. Soient $\\lambda_1, \\lambda_2, \\dots, \\lambda_n$ des scalaires tels que :\n\n$$ \\sum_{i=1}^n \\lambda_i v_i = 0_E $$\n\n**Étape 2 : Isoler un coefficient $\\lambda_j$**\n\nSoit $j$ un indice quelconque entre $1$ et $n$. Pour trouver la valeur de $\\lambda_j$, nous calculons le produit scalaire de l'équation ci-dessus avec le vecteur $v_j$ :\n\n$$ \\left\\langle \\sum_{i=1}^n \\lambda_i v_i, v_j \\right\\rangle = \\langle 0_E, v_j \\rangle $$\n\nLe membre de droite est nul : $\\langle 0_E, v_j \\rangle = 0$.\n\nUtilisons la linéarité à gauche du produit scalaire pour développer le membre de gauche :\n\n$$ \\sum_{i=1}^n \\left\\langle \\lambda_i v_i, v_j \\right\\rangle = 0 $$\n\n$$ \\sum_{i=1}^n \\lambda_i \\langle v_i, v_j \\rangle = 0 $$\n\n**Étape 3 : Utiliser l'hypothèse d'orthogonalité**\n\nLa famille $(v_1, \\dots, v_n)$ est orthogonale, ce qui signifie que $\\langle v_i, v_j \\rangle = 0$ pour tout $i \\neq j$.\n\nDans la somme ci-dessus, tous les termes sont nuls, sauf potentiellement celui où $i=j$. La somme se réduit donc à ce seul terme :\n\n$$ \\lambda_j \\langle v_j, v_j \\rangle = 0 $$\n\n**Étape 4 : Utiliser l'hypothèse de vecteurs non nuls**\n\nL'équation se réécrit :\n\n$$ \\lambda_j \\|v_j\\|^2 = 0 $$\n\nPar hypothèse, le vecteur $v_j$ est non nul. La propriété de \"caractère défini\" du produit scalaire implique que si $v_j \\neq 0_E$, alors $\\|v_j\\|^2 \\neq 0$.\n\nPuisque $\\|v_j\\|^2$ est un scalaire non nul, nous pouvons diviser l'équation par $\\|v_j\\|^2$ pour obtenir :\n\n$$ \\lambda_j = 0 $$\n\n**Conclusion :**\n\nNous avons montré que pour un indice $j$ arbitraire, le coefficient $\\lambda_j$ doit être nul. Comme cela est vrai pour tous les $j$ de $1$ à $n$, tous les coefficients de la combinaison linéaire sont nuls.\n\nCeci est la définition d'une famille libre.\n\n",
      "options": []
    },
    {
      "id": "8",
      "stackId": "70793e46",
      "content": "#### Caractérisation des Endomorphismes Orthogonaux\n\nSoit $f$ un endomorphisme d'un espace euclidien $E$. Prouvez que $f$ est un endomorphisme orthogonal si et seulement si $f$ préserve la norme, c'est-à-dire, pour tout $x \\in E$, $\\|f(x)\\| = \\|x\\|$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nC'est une preuve par double implication (\"si et seulement si\"). Il faut prouver les deux sens.\n\n**Sens 1 : $f$ est orthogonal $\\implies$ $f$ préserve la norme.**\n\nC'est le sens le plus simple. Partez de la définition d'un endomorphisme orthogonal : $\\langle f(x), f(y) \\rangle = \\langle x, y \\rangle$ pour tous $x, y \\in E$.\n\nAppliquez cette définition au cas particulier où $y=x$. Vous obtiendrez une relation entre $\\|f(x)\\|^2$ et $\\|x\\|^2$.\n\n**Sens 2 : $f$ préserve la norme $\\implies$ $f$ est orthogonal.**\n\nC'est le sens le plus délicat. L'hypothèse est que $\\|f(v)\\|^2 = \\|v\\|^2$ pour tout vecteur $v \\in E$. Vous devez prouver que $\\langle f(x), f(y) \\rangle = \\langle x, y \\rangle$ pour tous $x, y \\in E$.\n\nL'astuce consiste à utiliser une identité de polarisation, qui relie le produit scalaire à la norme. La plus simple est :\n\n$$ \\langle u, v \\rangle = \\frac{1}{2} (\\|u+v\\|^2 - \\|u\\|^2 - \\|v\\|^2) $$\n\nAppliquez cette identité à $\\langle f(x), f(y) \\rangle$. Utilisez la linéarité de $f$ et l'hypothèse de conservation de la norme pour simplifier l'expression et retrouver $\\langle x, y \\rangle$.\n\n</details>",
      "solution": "\n\n**Partie 1 : Implication ( $\\implies$ )**\n\nSupposons que $f$ est un endomorphisme orthogonal. Nous voulons montrer que $\\|f(x)\\| = \\|x\\|$ pour tout $x \\in E$.\n\nPar définition d'un endomorphisme orthogonal, pour tous vecteurs $u, v \\in E$, nous avons :\n\n$$ \\langle f(u), f(v) \\rangle = \\langle u, v \\rangle $$\n\nSoit $x \\in E$ un vecteur quelconque. Appliquons cette égalité au cas où $u=v=x$ :\n\n$$ \\langle f(x), f(x) \\rangle = \\langle x, x \\rangle $$\n\nPar définition de la norme, ceci s'écrit :\n\n$$ \\|f(x)\\|^2 = \\|x\\|^2 $$\n\nPuisque la norme est toujours un nombre réel positif, nous pouvons prendre la racine carrée des deux côtés :\n\n$$ \\|f(x)\\| = \\|x\\| $$\n\nLe premier sens est donc prouvé.\n\n**Partie 2 : Implication ( $\\impliedby$ )**\n\nSupposons maintenant que $f$ préserve la norme, c'est-à-dire que pour tout $v \\in E$, $\\|f(v)\\| = \\|v\\|$, ce qui est équivalent à $\\|f(v)\\|^2 = \\|v\\|^2$. Nous voulons montrer que $f$ est orthogonal, c'est-à-dire $\\langle f(x), f(y) \\rangle = \\langle x, y \\rangle$ pour tous $x, y \\in E$.\n\n**Étape 1 : Utiliser une identité de polarisation**\n\nL'identité de polarisation dans un espace euclidien nous permet d'exprimer le produit scalaire en termes de normes :\n\n$$ \\langle u, v \\rangle = \\frac{1}{2} (\\|u+v\\|^2 - \\|u\\|^2 - \\|v\\|^2) $$\n\nAppliquons cette identité au produit scalaire $\\langle f(x), f(y) \\rangle$ :\n\n$$ \\langle f(x), f(y) \\rangle = \\frac{1}{2} (\\|f(x)+f(y)\\|^2 - \\|f(x)\\|^2 - \\|f(y)\\|^2) $$\n\n**Étape 2 : Utiliser la linéarité de $f$ et l'hypothèse**\n\nPuisque $f$ est un endomorphisme, il est linéaire, donc $f(x)+f(y) = f(x+y)$. Remplaçons cela dans l'équation :\n\n$$ \\langle f(x), f(y) \\rangle = \\frac{1}{2} (\\|f(x+y)\\|^2 - \\|f(x)\\|^2 - \\|f(y)\\|^2) $$\n\nMaintenant, nous utilisons notre hypothèse de conservation de la norme. Pour tout vecteur $v$, $\\|f(v)\\|^2 = \\|v\\|^2$. Appliquons ceci à $x+y$, $x$ et $y$ :\n\n$$ \\|f(x+y)\\|^2 = \\|x+y\\|^2 $$\n\n$$ \\|f(x)\\|^2 = \\|x\\|^2 $$\n\n$$ \\|f(y)\\|^2 = \\|y\\|^2 $$\n\nSubstituons ces égalités dans notre expression pour $\\langle f(x), f(y) \\rangle$ :\n\n$$ \\langle f(x), f(y) \\rangle = \\frac{1}{2} (\\|x+y\\|^2 - \\|x\\|^2 - \\|y\\|^2) $$\n\n**Étape 3 : Conclure**\n\nNous reconnaissons que le membre de droite est simplement l'identité de polarisation pour $\\langle x, y \\rangle$ :\n\n$$ \\frac{1}{2} (\\|x+y\\|^2 - \\|x\\|^2 - \\|y\\|^2) = \\langle x, y \\rangle $$\n\nNous avons donc montré que :\n\n$$ \\langle f(x), f(y) \\rangle = \\langle x, y \\rangle $$\n\nCeci étant vrai pour tous $x, y \\in E$, l'endomorphisme $f$ est orthogonal.\n\n**Conclusion :**\n\nNous avons prouvé les deux implications, établissant ainsi l'équivalence entre le fait d'être un endomorphisme orthogonal et le fait de préserver la norme.\n\n",
      "options": []
    },
    {
      "id": "9",
      "stackId": "70793e46",
      "content": "#### Théorème de la Meilleure Approximation (Projection Orthogonale)\n\nSoit $F$ un sous-espace vectoriel d'un espace euclidien $E$. Prouvez que pour tout $x \\in E$, le projeté orthogonal $P_F(x)$ de $x$ sur $F$ est l'unique vecteur de $F$ qui minimise la distance à $x$. Autrement dit, pour tout $y \\in F$ avec $y \\neq P_F(x)$, on a :\n\n$$ \\|x - P_F(x)\\| < \\|x - y\\| $$\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nL'idée principale est d'utiliser le théorème de Pythagore.\n\nConsidérez la distance au carré $\\|x-y\\|^2$ pour un $y$ quelconque dans $F$.\n\nUtilisez une astuce en ajoutant et en soustrayant $P_F(x)$ à l'intérieur de la norme :\n\n$$ x-y = (x - P_F(x)) + (P_F(x) - y) $$\n\nVous avez maintenant une somme de deux vecteurs. Pour appliquer le théorème de Pythagore, vous devez montrer que ces deux vecteurs sont orthogonaux.\n\nLe premier vecteur, $x - P_F(x)$, est dans $F^\\perp$ par définition de la projection.\n\nLe second vecteur, $P_F(x) - y$, est une différence de deux vecteurs de $F$. Dans quel sous-espace se trouve-t-il ?\n\nUne fois que vous avez établi l'orthogonalité, appliquez le théorème de Pythagore à $\\|(x - P_F(x)) + (P_F(x) - y)\\|^2$.\n\nAnalysez l'expression obtenue pour voir quand elle est minimale.\n\n</details>",
      "solution": "\n\nSoit $x \\in E$ et $F$ un sous-espace vectoriel de $E$. Soit $P_F(x)$ le projeté orthogonal de $x$ sur $F$. Soit $y$ un vecteur quelconque de $F$.\n\n**Étape 1 : Décomposer le vecteur $x-y$**\n\nNous voulons comparer $\\|x-y\\|$ à $\\|x - P_F(x)\\|$. Pour ce faire, nous étudions $\\|x-y\\|^2$. Nous introduisons $P_F(x)$ dans l'expression :\n\n$$ x-y = (x - P_F(x)) + (P_F(x) - y) $$\n\n**Étape 2 : Montrer l'orthogonalité des deux composantes**\n\nSoient $v_1 = x - P_F(x)$ et $v_2 = P_F(x) - y$.\n\nPar définition de la projection orthogonale, le vecteur $x$ se décompose de manière unique en $x = P_F(x) + P_{F^\\perp}(x)$. Le vecteur $v_1 = x - P_F(x) = P_{F^\\perp}(x)$ appartient donc à l'orthogonal de $F$, c'est-à-dire $v_1 \\in F^\\perp$.\n\nLe vecteur $P_F(x)$ est dans $F$ par définition. Le vecteur $y$ est dans $F$ par hypothèse. Comme $F$ est un sous-espace vectoriel, la différence de deux de ses vecteurs, $v_2 = P_F(x) - y$, est aussi dans $F$.\n\nNous avons donc $v_1 \\in F^\\perp$ et $v_2 \\in F$. Par définition de l'orthogonal d'un sous-espace, tout vecteur de $F^\\perp$ est orthogonal à tout vecteur de $F$. Donc, $\\langle v_1, v_2 \\rangle = 0$.\n\n**Étape 3 : Appliquer le théorème de Pythagore**\n\nPuisque les vecteurs $v_1 = x - P_F(x)$ et $v_2 = P_F(x) - y$ sont orthogonaux, nous pouvons appliquer le théorème de Pythagore à leur somme :\n\n$$ \\|x-y\\|^2 = \\|v_1 + v_2\\|^2 = \\|v_1\\|^2 + \\|v_2\\|^2 $$\n\n$$ \\|x-y\\|^2 = \\|x - P_F(x)\\|^2 + \\|P_F(x) - y\\|^2 $$\n\n**Étape 4 : Analyser le résultat et conclure**\n\nL'équation ci-dessus est $\\|x-y\\|^2 = \\|x - P_F(x)\\|^2 + \\|P_F(x) - y\\|^2$.\n\nLe terme $\\|P_F(x) - y\\|^2$ est une norme au carré, il est donc toujours positif ou nul.\n\n$$ \\|P_F(x) - y\\|^2 \\ge 0 $$\n\nPar conséquent, nous avons l'inégalité :\n\n$$ \\|x-y\\|^2 \\ge \\|x - P_F(x)\\|^2 $$\n\nEn prenant la racine carrée, on obtient $\\|x-y\\| \\ge \\|x - P_F(x)\\|$. Cela montre que la distance est bien minimisée lorsque $y=P_F(x)$.\n\nPour l'unicité, l'égalité $\\|x-y\\|^2 = \\|x - P_F(x)\\|^2$ a lieu si et seulement si le terme supplémentaire est nul :\n\n$$ \\|P_F(x) - y\\|^2 = 0 $$\n\nPar la propriété de séparation de la norme, cela est équivalent à :\n\n$$ P_F(x) - y = 0_E \\iff y = P_F(x) $$\n\nDonc, si $y \\neq P_F(x)$, l'inégalité est stricte : $\\|x - y\\| > \\|x - P_F(x)\\|$.\n\n**Conclusion :**\n\nLe projeté orthogonal $P_F(x)$ est bien l'unique vecteur de $F$ qui minimise la distance à $x$.\n\n",
      "options": []
    },
    {
      "id": "10",
      "stackId": "70793e46",
      "content": "#### Propriétés de l'Adjoint\n\nProuvez que pour deux endomorphismes $f$ et $g$ d'un espace hermitien $E$, on a $(f \\circ g)^* = g^* \\circ f^*$.\n\n<details class=\"hint\">\n\n<summary>Indice</summary>\n\nPour prouver que l'adjoint de l'endomorphisme $A = f \\circ g$ est l'endomorphisme $B = g^* \\circ f^*$, vous devez montrer que $B$ satisfait la définition de l'adjoint de $A$.\n\nLa définition de l'adjoint $A^*$ de $A$ est l'unique endomorphisme tel que pour tous $x, y \\in E$ :\n\n$$ \\langle A(x), y \\rangle = \\langle x, A^*(y) \\rangle $$\n\nVous devez donc prouver que pour tous $x, y \\in E$ :\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle x, (g^* \\circ f^*)(y) \\rangle $$\n\nCommencez par le membre de gauche $\\langle f(g(x)), y \\rangle$ et appliquez la définition de l'adjoint successivement pour \"déplacer\" $f$ puis $g$ de l'autre côté du produit scalaire.\n\n</details>",
      "solution": "\n\nSoient $f, g$ deux endomorphismes de $E$. Soient $x, y \\in E$ des vecteurs quelconques.\n\nNous cherchons l'adjoint de l'endomorphisme composé $f \\circ g$. Notons-le $(f \\circ g)^*$. Par définition, il doit satisfaire pour tous $x, y$ :\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle x, (f \\circ g)^*(y) \\rangle $$\n\nNotre but est de montrer que l'endomorphisme $g^* \\circ f^*$ vérifie cette propriété.\n\n**Étape 1 : Partir du membre de gauche**\n\nCommençons par l'expression $\\langle (f \\circ g)(x), y \\rangle$.\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle f(g(x)), y \\rangle $$\n\n**Étape 2 : Utiliser la définition de l'adjoint de $f$**\n\nOn peut voir $g(x)$ comme un seul vecteur. En appliquant la définition de $f^*$, qui est $\\langle f(u), v \\rangle = \\langle u, f^*(v) \\rangle$, avec $u=g(x)$ et $v=y$, on obtient :\n\n$$ \\langle f(g(x)), y \\rangle = \\langle g(x), f^*(y) \\rangle $$\n\n**Étape 3 : Utiliser la définition de l'adjoint de $g$**\n\nMaintenant, nous avons une expression de la forme $\\langle g(u), v \\rangle$. En appliquant la définition de $g^*$, qui est $\\langle g(u), v \\rangle = \\langle u, g^*(v) \\rangle$, avec $u=x$ et $v=f^*(y)$, on obtient :\n\n$$ \\langle g(x), f^*(y) \\rangle = \\langle x, g^*(f^*(y)) \\rangle $$\n\n**Étape 4 : Conclure**\n\nPar définition de la composition d'applications, $g^*(f^*(y)) = (g^* \\circ f^*)(y)$.\n\nEn rassemblant les étapes, nous avons montré que :\n\n$$ \\langle (f \\circ g)(x), y \\rangle = \\langle x, (g^* \\circ f^*)(y) \\rangle $$\n\nEn comparant cette équation avec la définition de l'adjoint de $(f \\circ g)$, nous voyons que l'endomorphisme $g^* \\circ f^*$ se comporte exactement comme $(f \\circ g)^*$. Par unicité de l'adjoint, nous pouvons conclure :\n\n$$ (f \\circ g)^* = g^* \\circ f^* $$\n\n**Conclusion :**\n\nNous avons prouvé que l'adjoint d'une composée d'endomorphismes est la composée des adjoints, mais en inversant l'ordre.\n\n",
      "options": []
    }
  ]
}