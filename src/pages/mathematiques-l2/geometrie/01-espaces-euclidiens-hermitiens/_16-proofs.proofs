---
id: a76472c4
type: proofs
order: 15
title: Espaces Euclidiens et Hermitiens - preuves (A)
tags:
  - Espaces Euclidiens
  - Espaces Hermitiens
  - Produit scalaire
  - Gram-Schmidt
  - Projection orthogonale
  - Endomorphismes adjoints
  - Théorème de Riesz
createdAt: '2025-10-12T18:13:04.161Z'
level: regular
course: Géométrie
courseId: d9494343
chapter: Espaces Euclidiens et Hermitiens
chapterId: 67b3d760
---
# Preuves "Espaces Euclidiens et Hermitiens" (A)

---

#### Propriété de Réalité de la Forme Quadratique Hermitienne

Prouver que pour une forme sesquilinéaire hermitienne $\varphi$ sur un $\mathbb{C}$-espace vectoriel $E$, la valeur $\varphi(x, x)$ est un nombre réel pour tout vecteur $x \in E$.

<details class="hint">

<summary>Hint</summary>

Utilisez la définition de la symétrie hermitienne, qui relie $\varphi(x, y)$ à $\varphi(y, x)$.

Appliquez cette propriété au cas particulier où $y = x$.

Rappelez-vous qu'un nombre complexe $z$ est réel si et seulement si $z = \bar{z}$.

</details>

<details>

<summary>Solution</summary>

Soit $\varphi: E \times E \to \mathbb{C}$ une forme sesquilinéaire hermitienne.

**Étape 1 : Rappel de la définition de la symétrie hermitienne**

Par définition, une forme sesquilinéaire $\varphi$ est hermitienne si pour tous vecteurs $x, y \in E$, on a :

$$ \varphi(x, y) = \overline{\varphi(y, x)} $$

**Étape 2 : Appliquer la définition au cas $y=x$**

Nous nous intéressons à la valeur $\varphi(x, x)$. Appliquons la propriété de symétrie hermitienne en posant $y = x$. On obtient :

$$ \varphi(x, x) = \overline{\varphi(x, x)} $$

**Étape 3 : Conclure sur la nature de $\varphi(x, x)$**

Soit $z = \varphi(x, x)$. L'équation de l'étape 2 s'écrit $z = \bar{z}$.

Un nombre complexe est égal à son propre conjugué si et seulement si sa partie imaginaire est nulle. C'est la définition d'un nombre réel.

**Conclusion :**

Par conséquent, pour tout $x \in E$, la valeur $\varphi(x, x)$ est un nombre réel.

</details>

---

#### Inégalité de Cauchy-Schwarz (Cas Réel)

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace euclidien. Prouver que pour tous vecteurs $x, y \in E$, on a :

$$ |\langle x, y \rangle| \le \|x\| \|y\| $$

<details class="hint">

<summary>Hint</summary>

Considérez le vecteur $x + \lambda y$ pour un scalaire réel $\lambda$.

Utilisez la propriété de positivité du produit scalaire, qui stipule que $\langle v, v \rangle \ge 0$ pour tout vecteur $v \in E$.

Développez $\langle x + \lambda y, x + \lambda y \rangle$ et analysez l'expression obtenue comme un polynôme du second degré en $\lambda$. Quel doit être le signe de son discriminant ?

</details>

<details>

<summary>Solution</summary>

Soient $x, y \in E$.

**Cas 1 : $y = 0_E$**

Si $y$ est le vecteur nul, alors $\langle x, y \rangle = \langle x, 0_E \rangle = 0$ et $\|y\| = 0$. L'inégalité devient $0 \le 0$, ce qui est vrai.

**Cas 2 : $y \neq 0_E$**

Soit $\lambda \in \mathbb{R}$ un scalaire quelconque. Considérons le vecteur $v = x + \lambda y$.

**Étape 1 : Utiliser la positivité de la norme**

Par définition de la norme associée à un produit scalaire, nous savons que $\|v\|^2 = \langle v, v \rangle \ge 0$.

Donc, pour tout $\lambda \in \mathbb{R}$ :

$$ \langle x + \lambda y, x + \lambda y \rangle \ge 0 $$

**Étape 2 : Développer l'expression**

En utilisant la bilinéarité du produit scalaire réel :

$$ \langle x + \lambda y, x + \lambda y \rangle = \langle x, x \rangle + \langle x, \lambda y \rangle + \langle \lambda y, x \rangle + \langle \lambda y, \lambda y \rangle $$

$$ = \langle x, x \rangle + \lambda \langle x, y \rangle + \lambda \langle y, x \rangle + \lambda^2 \langle y, y \rangle $$

Comme le produit scalaire est symétrique ($\langle x, y \rangle = \langle y, x \rangle$), cela se simplifie en :

$$ = \langle x, x \rangle + 2\lambda \langle x, y \rangle + \lambda^2 \langle y, y \rangle $$

En notation de norme, on a le polynôme $P(\lambda)$:

$$ P(\lambda) = \|y\|^2 \lambda^2 + 2\langle x, y \rangle \lambda + \|x\|^2 $$

**Étape 3 : Analyser le signe du discriminant**

Nous avons établi que $P(\lambda) \ge 0$ pour tout $\lambda \in \mathbb{R}$. C'est un polynôme du second degré en $\lambda$ qui est toujours positif ou nul. Cela signifie qu'il a au plus une racine réelle. Par conséquent, son discriminant $\Delta$ doit être négatif ou nul.

Le discriminant de $A\lambda^2 + B\lambda + C$ est $\Delta = B^2 - 4AC$. Ici, $A=\|y\|^2$, $B=2\langle x, y \rangle$, $C=\|x\|^2$.

$$ \Delta = (2\langle x, y \rangle)^2 - 4 (\|y\|^2) (\|x\|^2) \le 0 $$

$$ 4 \langle x, y \rangle^2 - 4 \|x\|^2 \|y\|^2 \le 0 $$

$$ \langle x, y \rangle^2 \le \|x\|^2 \|y\|^2 $$

**Étape 4 : Conclure**

En prenant la racine carrée des deux côtés (qui sont des nombres réels positifs), on obtient :

$$ \sqrt{\langle x, y \rangle^2} \le \sqrt{\|x\|^2 \|y\|^2} $$

$$ |\langle x, y \rangle| \le \|x\| \|y\| $$

**Conclusion :**

L'inégalité est donc prouvée pour tous les vecteurs $x, y$ de l'espace euclidien $E$.

</details>

---

#### Cas d'Égalité de l'Inégalité de Cauchy-Schwarz

Prouver que dans l'inégalité de Cauchy-Schwarz $|\langle x, y \rangle| \le \|x\| \|y\|$, l'égalité a lieu si et seulement si les vecteurs $x$ et $y$ sont colinéaires (c'est-à-dire, linéairement dépendants).

<details class="hint">

<summary>Hint</summary>

Reprenez la démonstration de l'inégalité de Cauchy-Schwarz. L'égalité se produit lorsque le discriminant du polynôme $P(\lambda) = \|x+\lambda y\|^2$ est nul.

Que signifie, pour un polynôme du second degré toujours positif, d'avoir un discriminant nul ? Cela signifie qu'il admet une unique racine réelle $\lambda_0$.

Quelle est la signification de $P(\lambda_0) = \|x+\lambda_0 y\|^2 = 0$ ? Utilisez la propriété de séparation de la norme (ou le caractère défini du produit scalaire).

</details>

<details>

<summary>Solution</summary>

Nous devons prouver l'équivalence : $|\langle x, y \rangle| = \|x\| \|y\| \iff (x \text{ et } y \text{ sont colinéaires})$.

**Partie 1 : (Colinéarité $\implies$ Égalité)**

Supposons que $x$ et $y$ sont colinéaires. Il existe donc un scalaire $k$ tel que $x = ky$.

Calculons les deux membres de l'inégalité :

- $|\langle x, y \rangle| = |\langle ky, y \rangle| = |k \langle y, y \rangle| = |k| \langle y, y \rangle = |k| \|y\|^2$.
- $\|x\| \|y\| = \|ky\| \|y\| = (|k| \|y\|) \|y\| = |k| \|y\|^2$.

Les deux membres sont égaux. Donc, si les vecteurs sont colinéaires, il y a égalité.

**Partie 2 : (Égalité $\implies$ Colinéarité)**

Supposons que $|\langle x, y \rangle| = \|x\| \|y\|$. Cela équivaut à $\langle x, y \rangle^2 = \|x\|^2 \|y\|^2$.

Reprenons la preuve de Cauchy-Schwarz, basée sur le polynôme $P(\lambda) = \|x+\lambda y\|^2 = \|y\|^2 \lambda^2 + 2\langle x, y \rangle \lambda + \|x\|^2$.

L'hypothèse d'égalité signifie que le discriminant $\Delta$ de ce polynôme est nul :

$$ \Delta = (2\langle x, y \rangle)^2 - 4 \|y\|^2 \|x\|^2 = 4(\langle x, y \rangle^2 - \|x\|^2 \|y\|^2) = 0 $$

Si $y=0_E$, $x$ et $y$ sont colinéaires (car $y=0x$). Supposons donc $y \neq 0_E$.

Un polynôme du second degré avec un discriminant nul admet une unique racine réelle, notée $\lambda_0$.

Pour cette valeur $\lambda_0$, on a $P(\lambda_0) = 0$.

$$ P(\lambda_0) = \|x + \lambda_0 y\|^2 = 0 $$

Par la propriété de séparation de la norme (ou le caractère défini du produit scalaire), une norme nulle implique un vecteur nul :

$$ \|x + \lambda_0 y\| = 0 \iff x + \lambda_0 y = 0_E $$

Cette dernière égalité s'écrit $x = -\lambda_0 y$. Ceci est la définition de la colinéarité de $x$ et $y$.

**Conclusion :**

Nous avons montré les deux implications. L'égalité dans l'inégalité de Cauchy-Schwarz est vérifiée si et seulement si les vecteurs $x$ et $y$ sont colinéaires.

</details>

---

#### Inégalité Triangulaire pour la Norme

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace préhilbertien. Prouver que la norme associée $\|x\| = \sqrt{\langle x, x \rangle}$ vérifie l'inégalité triangulaire :

$$ \|x+y\| \le \|x\| + \|y\| $$

pour tous vecteurs $x, y \in E$.

<details class="hint">

<summary>Hint</summary>

Comme la norme est toujours positive, l'inégalité est équivalente à $\|x+y\|^2 \le (\|x\| + \|y\|)^2$.

Commencez par développer $\|x+y\|^2 = \langle x+y, x+y \rangle$.

Dans l'expression obtenue, utilisez l'inégalité de Cauchy-Schwarz sur le terme $\langle x, y \rangle$. Dans le cas complexe, vous devrez manipuler le terme $\langle x,y \rangle + \overline{\langle x,y \rangle} = 2 \text{Re}(\langle x,y \rangle)$.

</details>

<details>

<summary>Solution</summary>

Soient $x, y \in E$.

**Étape 1 : Travailler avec le carré de la norme**

Les termes de l'inégalité sont positifs, il est donc équivalent de prouver $\|x+y\|^2 \le (\|x\| + \|y\|)^2$.

Développons le membre de gauche en utilisant les propriétés du produit scalaire :

$$ \|x+y\|^2 = \langle x+y, x+y \rangle = \langle x,x \rangle + \langle x,y \rangle + \langle y,x \rangle + \langle y,y \rangle $$

En utilisant la symétrie (hermitienne), on sait que $\langle y,x \rangle = \overline{\langle x,y \rangle}$.

$$ \|x+y\|^2 = \|x\|^2 + \langle x,y \rangle + \overline{\langle x,y \rangle} + \|y\|^2 $$

Rappelons que pour tout nombre complexe $z$, $z + \bar{z} = 2 \text{Re}(z)$.

$$ \|x+y\|^2 = \|x\|^2 + 2 \text{Re}(\langle x,y \rangle) + \|y\|^2 $$

(Dans le cas réel, $\text{Re}(\langle x,y \rangle) = \langle x,y \rangle$, la formule reste donc juste).

**Étape 2 : Appliquer l'inégalité de Cauchy-Schwarz**

Pour tout nombre complexe $z$, on a $\text{Re}(z) \le |z|$. Donc :

$$ 2 \text{Re}(\langle x,y \rangle) \le 2 |\langle x,y \rangle| $$

L'inégalité de Cauchy-Schwarz nous dit que $|\langle x,y \rangle| \le \|x\|\|y\|$. En combinant ces deux inégalités :

$$ 2 \text{Re}(\langle x,y \rangle) \le 2 \|x\|\|y\| $$

**Étape 3 : Substituer et conclure**

En substituant ce résultat dans l'expression de $\|x+y\|^2$ :

$$ \|x+y\|^2 \le \|x\|^2 + 2 \|x\|\|y\| + \|y\|^2 $$

On reconnaît le développement d'une identité remarquable :

$$ \|x+y\|^2 \le (\|x\| + \|y\|)^2 $$

**Étape 4 : Revenir à la norme**

Puisque la norme est une quantité positive, on peut prendre la racine carrée des deux côtés de l'inégalité pour obtenir le résultat final :

$$ \|x+y\| \le \|x\| + \|y\| $$

**Conclusion :**

La norme induite par un produit scalaire satisfait bien l'inégalité triangulaire.

</details>

---

#### Identité du Parallélogramme

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace préhilbertien. Prouver que pour tous vecteurs $x, y \in E$, la norme associée au produit scalaire vérifie l'identité du parallélogramme :

$$ \|x+y\|^2 + \|x-y\|^2 = 2(\|x\|^2 + \|y\|^2) $$

<details class="hint">

<summary>Hint</summary>

Exprimez les termes $\|x+y\|^2$ et $\|x-y\|^2$ en utilisant la définition de la norme, c'est-à-dire $\|v\|^2 = \langle v, v \rangle$.

Développez les deux expressions $\langle x+y, x+y \rangle$ et $\langle x-y, x-y \rangle$ en utilisant la linéarité (et semi-linéarité) du produit scalaire.

Additionnez les deux expressions développées et observez les simplifications.

</details>

<details>

<summary>Solution</summary>

Soient $x, y \in E$.

**Étape 1 : Développer $\|x+y\|^2$**

En utilisant la définition de la norme et les propriétés du produit scalaire :

$$ \|x+y\|^2 = \langle x+y, x+y \rangle = \langle x,x \rangle + \langle x,y \rangle + \langle y,x \rangle + \langle y,y \rangle $$

$$ \|x+y\|^2 = \|x\|^2 + \langle x,y \rangle + \langle y,x \rangle + \|y\|^2 \quad (1) $$

**Étape 2 : Développer $\|x-y\|^2$**

De manière similaire :

$$ \|x-y\|^2 = \langle x-y, x-y \rangle = \langle x,x \rangle - \langle x,y \rangle - \langle y,x \rangle + \langle y,y \rangle $$

$$ \|x-y\|^2 = \|x\|^2 - \langle x,y \rangle - \langle y,x \rangle + \|y\|^2 \quad (2) $$

**Étape 3 : Additionner les deux expressions**

Additionnons les équations (1) et (2) :

$$ \|x+y\|^2 + \|x-y\|^2 = (\|x\|^2 + \langle x,y \rangle + \langle y,x \rangle + \|y\|^2) + (\|x\|^2 - \langle x,y \rangle - \langle y,x \rangle + \|y\|^2) $$

Les termes "croisés" $\langle x,y \rangle$ et $\langle y,x \rangle$ s'annulent :

$$ \|x+y\|^2 + \|x-y\|^2 = \|x\|^2 + \|y\|^2 + \|x\|^2 + \|y\|^2 $$

$$ \|x+y\|^2 + \|x-y\|^2 = 2\|x\|^2 + 2\|y\|^2 $$

**Conclusion :**

En factorisant le membre de droite, on obtient l'identité du parallélogramme :

$$ \|x+y\|^2 + \|x-y\|^2 = 2(\|x\|^2 + \|y\|^2) $$

</details>

---

#### Théorème de Pythagore

Soit $(E, \langle \cdot, \cdot \rangle)$ un espace préhilbertien. Prouver que si deux vecteurs $x, y \in E$ sont orthogonaux, alors :

$$ \|x+y\|^2 = \|x\|^2 + \|y\|^2 $$

<details class="hint">

<summary>Hint</summary>

Commencez par développer $\|x+y\|^2$ en utilisant sa définition en termes de produit scalaire : $\langle x+y, x+y \rangle$.

Utilisez la définition de l'orthogonalité. Que vaut $\langle x, y \rangle$ si $x$ et $y$ sont orthogonaux ?

</details>

<details>

<summary>Solution</summary>

Soient $x, y \in E$ deux vecteurs orthogonaux.

**Étape 1 : Définition de l'orthogonalité**

Par définition, $x$ et $y$ sont orthogonaux si leur produit scalaire est nul :

$$ \langle x, y \rangle = 0 $$

Dans un espace hermitien, cela implique aussi $\langle y, x \rangle = \overline{\langle x, y \rangle} = \overline{0} = 0$.

**Étape 2 : Développer le carré de la norme de la somme**

On exprime $\|x+y\|^2$ à l'aide du produit scalaire :

$$ \|x+y\|^2 = \langle x+y, x+y \rangle $$

Par (sesqui-)linéarité du produit scalaire, on développe :

$$ \|x+y\|^2 = \langle x, x \rangle + \langle x, y \rangle + \langle y, x \rangle + \langle y, y \rangle $$

En utilisant la notation de la norme, cela devient :

$$ \|x+y\|^2 = \|x\|^2 + \langle x, y \rangle + \langle y, x \rangle + \|y\|^2 $$

**Étape 3 : Appliquer l'hypothèse d'orthogonalité**

Puisque $x$ et $y$ sont orthogonaux, $\langle x, y \rangle = 0$ et $\langle y, x \rangle = 0$. En substituant ces valeurs dans l'équation précédente :

$$ \|x+y\|^2 = \|x\|^2 + 0 + 0 + \|y\|^2 $$

$$ \|x+y\|^2 = \|x\|^2 + \|y\|^2 $$

**Conclusion :**

Nous avons démontré que pour deux vecteurs orthogonaux, le carré de la norme de leur somme est égal à la somme de leurs carrés, ce qui est l'énoncé du théorème de Pythagore.

</details>

---

#### Liberté d'une Famille Orthogonale

Prouver que toute famille orthogonale de vecteurs non nuls d'un espace préhilbertien est une famille libre.

<details class="hint">

<summary>Hint</summary>

Soit $(v_1, v_2, \dots, v_n)$ une famille orthogonale de vecteurs non nuls.

Pour prouver qu'elle est libre, partez de la définition : supposez qu'il existe une combinaison linéaire nulle de ces vecteurs, $\sum_{i=1}^n \lambda_i v_i = 0_E$.

L'objectif est de montrer que tous les scalaires $\lambda_i$ sont nuls. Pour isoler un scalaire particulier $\lambda_j$, prenez le produit scalaire de la combinaison linéaire avec le vecteur $v_j$.

</details>

<details>

<summary>Solution</summary>

Soit $S = (v_1, v_2, \dots, v_n)$ une famille orthogonale de vecteurs non nuls dans un espace préhilbertien $E$.

**Étape 1 : Hypothèses sur la famille $S$**

- **Orthogonale :** Pour tout $i \neq j$, $\langle v_i, v_j \rangle = 0$.
- **Vecteurs non nuls :** Pour tout $i$, $v_i \neq 0_E$, ce qui implique $\langle v_i, v_i \rangle = \|v_i\|^2 > 0$.

**Étape 2 : Écrire la condition de dépendance linéaire**

Pour montrer que $S$ est une famille libre, nous devons montrer que la seule combinaison linéaire de ses vecteurs qui soit égale au vecteur nul est celle où tous les coefficients sont nuls.

Supposons qu'il existe des scalaires $\lambda_1, \lambda_2, \dots, \lambda_n$ tels que :

$$ \sum_{i=1}^n \lambda_i v_i = 0_E $$

**Étape 3 : Isoler un coefficient $\lambda_j$**

Fixons un indice $j \in \{1, \dots, n\}$. Pour isoler $\lambda_j$, calculons le produit scalaire de l'équation ci-dessus avec le vecteur $v_j$ :

$$ \left\langle \sum_{i=1}^n \lambda_i v_i, v_j \right\rangle = \langle 0_E, v_j \rangle $$

Le membre de droite est nul. Utilisons la linéarité à gauche pour le membre de gauche :

$$ \sum_{i=1}^n \lambda_i \langle v_i, v_j \rangle = 0 $$

**Étape 4 : Utiliser l'orthogonalité**

La famille est orthogonale, donc $\langle v_i, v_j \rangle = 0$ pour tous les indices $i$ différents de $j$. La somme se simplifie donc radicalement, car un seul terme est potentiellement non nul (celui pour $i=j$) :

$$ \lambda_1 \langle v_1, v_j \rangle + \dots + \lambda_j \langle v_j, v_j \rangle + \dots + \lambda_n \langle v_n, v_j \rangle = 0 $$

$$ 0 + \dots + \lambda_j \langle v_j, v_j \rangle + \dots + 0 = 0 $$

$$ \lambda_j \|v_j\|^2 = 0 $$

**Étape 5 : Conclure sur la nullité du coefficient**

Par hypothèse, tous les vecteurs $v_j$ de la famille sont non nuls, donc $\|v_j\|^2 \neq 0$.

Puisque le produit $\lambda_j \|v_j\|^2$ est nul et que $\|v_j\|^2$ n'est pas nul, c'est nécessairement le scalaire $\lambda_j$ qui doit être nul.

$$ \lambda_j = 0 $$

Comme ce raisonnement est valable pour n'importe quel indice $j$ de $1$ à $n$, nous avons montré que $\lambda_1 = \lambda_2 = \dots = \lambda_n = 0$.

**Conclusion :**

La seule combinaison linéaire des vecteurs de $S$ qui donne le vecteur nul est la combinaison triviale. La famille $S$ est donc libre.

</details>

---

#### Expression des Coordonnées dans une Base Orthonormée

Soit $\mathcal{B} = (e_1, \dots, e_n)$ une base orthonormée d'un espace préhilbertien $E$. Prouver que pour tout vecteur $x \in E$, ses coordonnées $(x_1, \dots, x_n)$ dans la base $\mathcal{B}$ sont données par $x_i = \langle x, e_i \rangle$. En d'autres termes, prouver que :

$$ x = \sum_{i=1}^n \langle x, e_i \rangle e_i $$

<details class="hint">

<summary>Hint</summary>

Puisque $\mathcal{B}$ est une base, tout vecteur $x$ peut s'écrire de manière unique comme une combinaison linéaire $x = \sum_{j=1}^n x_j e_j$, où les $x_j$ sont les coordonnées de $x$.

Votre objectif est de trouver la valeur d'un coefficient particulier, disons $x_i$.

Pour cela, calculez le produit scalaire de l'expression de $x$ avec le vecteur de base $e_i$. Utilisez la propriété fondamentale d'une base orthonormée : $\langle e_j, e_i \rangle = \delta_{ji}$.

</details>

<details>

<summary>Solution</summary>

Soit $\mathcal{B} = (e_1, \dots, e_n)$ une base orthonormée de $E$. Soit $x$ un vecteur quelconque de $E$.

**Étape 1 : Décomposition de $x$ dans la base $\mathcal{B}$**

Puisque $\mathcal{B}$ est une base de $E$, il existe un unique n-uplet de scalaires $(x_1, \dots, x_n)$, appelés coordonnées de $x$ dans $\mathcal{B}$, tel que :

$$ x = \sum_{j=1}^n x_j e_j $$

**Étape 2 : Calcul du produit scalaire avec un vecteur de base $e_i$**

Fixons un indice $i \in \{1, \dots, n\}$. Calculons le produit scalaire de $x$ avec $e_i$ :

$$ \langle x, e_i \rangle = \left\langle \sum_{j=1}^n x_j e_j, e_i \right\rangle $$

Par linéarité (ou semi-linéarité selon la variable) du produit scalaire, on peut écrire :

$$ \langle x, e_i \rangle = \sum_{j=1}^n \langle x_j e_j, e_i \rangle $$

Dans le cas euclidien (réel) : $\langle x, e_i \rangle = \sum_{j=1}^n x_j \langle e_j, e_i \rangle$.

Dans le cas hermitien (complexe) : $\langle x, e_i \rangle = \sum_{j=1}^n x_j \langle e_j, e_i \rangle$. La formule est identique.

**Étape 3 : Utilisation de l'orthonormalité de la base**

La base $\mathcal{B}$ est orthonormée, ce qui signifie par définition que $\langle e_j, e_i \rangle = \delta_{ji}$, où $\delta_{ji}$ est le symbole de Kronecker ($\delta_{ji}=1$ si $j=i$ et $\delta_{ji}=0$ si $j \neq i$).

Substituons cette propriété dans la somme. Tous les termes de la somme vont s'annuler, sauf celui pour lequel l'indice $j$ est égal à $i$ :

$$ \langle x, e_i \rangle = x_1 \langle e_1, e_i \rangle + \dots + x_i \langle e_i, e_i \rangle + \dots + x_n \langle e_n, e_i \rangle $$

$$ \langle x, e_i \rangle = x_1 \cdot 0 + \dots + x_i \cdot 1 + \dots + x_n \cdot 0 $$

$$ \langle x, e_i \rangle = x_i $$

**Étape 4 : Conclusion**

Nous avons montré que la i-ème coordonnée $x_i$ du vecteur $x$ est égale au produit scalaire $\langle x, e_i \rangle$. Ce résultat étant valable pour tout $i \in \{1, \dots, n\}$, on peut substituer ces expressions dans la décomposition de $x$ :

$$ x = \sum_{i=1}^n x_i e_i = \sum_{i=1}^n \langle x, e_i \rangle e_i $$

Ceci prouve la formule requise.

</details>

---

#### Caractérisation des Endomorphismes Orthogonaux

Soit $f$ un endomorphisme d'un espace euclidien $E$. Prouver que $f$ est un endomorphisme orthogonal (c'est-à-dire qu'il préserve le produit scalaire) si et seulement si il préserve la norme.

$$ (\forall x,y \in E, \langle f(x), f(y) \rangle = \langle x, y \rangle) \iff (\forall z \in E, \|f(z)\| = \|z\|) $$

<details class="hint">

<summary>Hint</summary>

L'implication "préserve le produit scalaire $\implies$ préserve la norme" est directe. Il suffit de considérer le cas $x=y$.

Pour l'implication "préserve la norme $\implies$ préserve le produit scalaire", utilisez l'identité de polarisation qui exprime le produit scalaire en fonction de la norme. L'identité pour le cas euclidien est :

$$ \langle u, v \rangle = \frac{1}{2} (\|u+v\|^2 - \|u\|^2 - \|v\|^2) $$

Appliquez cette identité à $\langle f(x), f(y) \rangle$.

</details>

<details>

<summary>Solution</summary>

**Partie 1 : Un endomorphisme orthogonal préserve la norme.**

Supposons que $f$ est un endomorphisme orthogonal. Par définition, pour tous $x, y \in E$, on a :

$$ \langle f(x), f(y) \rangle = \langle x, y \rangle $$

Pour montrer que $f$ préserve la norme, nous devons prouver que $\|f(z)\| = \|z\|$ pour tout $z \in E$. Cela est équivalent à $\|f(z)\|^2 = \|z\|^2$.

Soit $z \in E$. On a :

$$ \|f(z)\|^2 = \langle f(z), f(z) \rangle $$

En utilisant la propriété de conservation du produit scalaire avec $x=z$ et $y=z$, on obtient :

$$ \langle f(z), f(z) \rangle = \langle z, z \rangle = \|z\|^2 $$

Donc, $\|f(z)\|^2 = \|z\|^2$. Comme les normes sont positives, on en déduit $\|f(z)\| = \|z\|$.

L'implication est démontrée.

**Partie 2 : Un endomorphisme qui préserve la norme est orthogonal.**

Supposons maintenant que $f$ préserve la norme, c'est-à-dire que pour tout $z \in E$, $\|f(z)\| = \|z\|$. Nous voulons montrer que $\langle f(x), f(y) \rangle = \langle x, y \rangle$ pour tous $x,y \in E$.

**Étape 1 : Utiliser l'identité de polarisation**

L'identité de polarisation dans un espace euclidien permet d'exprimer le produit scalaire à partir de la norme :

$$ \langle u, v \rangle = \frac{1}{2} (\|u+v\|^2 - \|u\|^2 - \|v\|^2) $$

Appliquons cette identité au produit scalaire $\langle f(x), f(y) \rangle$ en posant $u = f(x)$ et $v = f(y)$.

$$ \langle f(x), f(y) \rangle = \frac{1}{2} (\|f(x)+f(y)\|^2 - \|f(x)\|^2 - \|f(y)\|^2) $$

**Étape 2 : Utiliser la linéarité de $f$ et l'hypothèse de conservation de la norme**

Par linéarité de $f$, on a $f(x)+f(y) = f(x+y)$. On peut donc réécrire le premier terme :

$$ \|f(x)+f(y)\|^2 = \|f(x+y)\|^2 $$

Maintenant, nous utilisons notre hypothèse : $f$ préserve la norme. Donc, pour tout vecteur $z$, $\|f(z)\|^2 = \|z\|^2$. Appliquons ceci à $x$, $y$ et $x+y$ :

- $\|f(x)\|^2 = \|x\|^2$
- $\|f(y)\|^2 = \|y\|^2$
- $\|f(x+y)\|^2 = \|x+y\|^2$

**Étape 3 : Substituer et conclure**

En substituant ces égalités dans l'expression de $\langle f(x), f(y) \rangle$ :

$$ \langle f(x), f(y) \rangle = \frac{1}{2} (\|x+y\|^2 - \|x\|^2 - \|y\|^2) $$

On reconnaît le membre de droite comme étant l'expression de $\langle x, y \rangle$ par l'identité de polarisation.

$$ \langle f(x), f(y) \rangle = \langle x, y \rangle $$

**Conclusion :**

Nous avons démontré les deux implications, ce qui prouve l'équivalence entre la préservation du produit scalaire et la préservation de la norme pour un endomorphisme en espace euclidien.

</details>

---

#### Adjoint d'une Composition d'Endomorphismes

Soient $f$ et $g$ deux endomorphismes d'un espace préhilbertien $E$ de dimension finie. Prouver que l'adjoint de la composition $f \circ g$ est la composition des adjoints en ordre inversé :

$$ (f \circ g)^* = g^* \circ f^* $$

<details class="hint">

<summary>Hint</summary>

L'adjoint d'un endomorphisme $h$, noté $h^*$, est défini par la relation unique $\langle h(x), y \rangle = \langle x, h^*(y) \rangle$ pour tous $x, y \in E$.

Votre but est de trouver un endomorphisme $h'$ tel que $\langle (f \circ g)(x), y \rangle = \langle x, h'(y) \rangle$. Par unicité de l'adjoint, vous aurez alors $h' = (f \circ g)^*$.

Commencez par $\langle (f \circ g)(x), y \rangle = \langle f(g(x)), y \rangle$ et appliquez la définition de l'adjoint successivement pour $f$ puis pour $g$.

</details>

<details>

<summary>Solution</summary>

Soient $f, g$ deux endomorphismes de $E$. Nous cherchons à déterminer l'endomorphisme $(f \circ g)^*$.

**Étape 1 : Définition de l'adjoint**

Par définition, l'adjoint $(f \circ g)^*$ est l'unique endomorphisme qui vérifie pour tous $x, y \in E$ :

$$ \langle (f \circ g)(x), y \rangle = \langle x, (f \circ g)^*(y) \rangle $$

Notre stratégie est de partir du membre de gauche et de le transformer en une expression de la forme $\langle x, h(y) \rangle$. L'endomorphisme $h$ sera alors, par unicité, l'adjoint recherché.

**Étape 2 : Application successive de la définition de l'adjoint**

Partons du membre de gauche.

$$ \langle (f \circ g)(x), y \rangle = \langle f(g(x)), y \rangle $$

Considérons le vecteur $g(x)$ comme un seul bloc. On peut appliquer la définition de l'adjoint de $f$, qui est $f^*$. On a $\langle f(u), v \rangle = \langle u, f^*(v) \rangle$. En posant $u = g(x)$ et $v = y$ :

$$ \langle f(g(x)), y \rangle = \langle g(x), f^*(y) \rangle $$

Maintenant, nous avons une nouvelle expression $\langle g(x), f^*(y) \rangle$. On peut y appliquer la définition de l'adjoint de $g$, qui est $g^*$. On a $\langle g(u), v \rangle = \langle u, g^*(v) \rangle$. En posant $u = x$ et $v = f^*(y)$ :

$$ \langle g(x), f^*(y) \rangle = \langle x, g^*(f^*(y)) \rangle $$

**Étape 3 : Identification de l'adjoint**

En combinant les étapes, nous avons montré que pour tous $x, y \in E$ :

$$ \langle (f \circ g)(x), y \rangle = \langle x, g^*(f^*(y)) \rangle $$

L'expression $g^*(f^*(y))$ peut s'écrire comme la composition $(g^* \circ f^*)(y)$.

$$ \langle (f \circ g)(x), y \rangle = \langle x, (g^* \circ f^*)(y) \rangle $$

En comparant cette égalité avec la relation de définition $\langle (f \circ g)(x), y \rangle = \langle x, (f \circ g)^*(y) \rangle$, par unicité de l'endomorphisme adjoint, on doit avoir :

$$ (f \circ g)^* = g^* \circ f^* $$

**Conclusion :**

L'adjoint de la composition de deux endomorphismes est bien la composition de leurs adjoints, avec inversion de l'ordre.

</details>
