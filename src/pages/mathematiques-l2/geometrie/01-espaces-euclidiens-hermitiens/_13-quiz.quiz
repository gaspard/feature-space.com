---
title: Quiz
order: 13
level: regular
chapter: A - Concepts
course: Géométrie
tags: ["quiz", "assessment", "regular"]
---

# Quiz : A - Concepts

---

#### Question 1 : Définition d'un produit scalaire

Quelles sont les propriétés requises pour qu'une forme bilinéaire $\varphi$ sur un espace vectoriel réel $E$ soit un produit scalaire ?

- [x] **A)** $\varphi$ est symétrique ($\varphi(u,v) = \varphi(v,u)$ pour tous $u,v \in E$).
- [ ] **B)** $\varphi$ est anti-symétrique ($\varphi(u,v) = -\varphi(v,u)$ pour tous $u,v \in E$).
- [x] **C)** $\varphi$ est définie positive ($\varphi(u,u) > 0$ pour tout $u \neq 0_E$).
- [ ] **D)** $\varphi(u,u)$ peut être négatif pour certains vecteurs non nuls.

<details>

<summary>Solution</summary>

**Réponses : [A, C]**

Un produit scalaire sur un espace vectoriel réel $E$ est une application $\varphi: E \times E \to \mathbb{R}$ qui doit satisfaire trois conditions : être une forme bilinéaire, être symétrique et être définie positive. La question stipule déjà que $\varphi$ est bilinéaire.

- **A)** La symétrie est une condition essentielle. Elle assure que la "mesure" de la relation entre $u$ et $v$ est la même que celle entre $v$ et $u$, ce qui est fondamental pour la géométrie euclidienne. Cette option est correcte.

- **B)** L'anti-symétrie est la propriété des formes alternées, pas des produits scalaires. Une forme anti-symétrique vérifierait $\varphi(u,u) = -\varphi(u,u)$, ce qui implique $\varphi(u,u)=0$ pour tout $u$. Cela contredit directement la condition "définie positive". Cette option est incorrecte.

- **C)** La condition "définie positive" est cruciale. Elle garantit que tout vecteur non nul a une "longueur au carré" strictement positive, ce qui permet de définir une norme cohérente. Si $\varphi(u,u)$ pouvait être nul pour $u \neq 0_E$, on ne pourrait pas distinguer les vecteurs non nuls du vecteur nul en termes de longueur. Cette option est correcte.

- **D)** Si $\varphi(u,u)$ pouvait être négatif, on ne pourrait pas définir la norme comme $\sqrt{\varphi(u,u)}$ (dans $\mathbb{R}$). Cette condition est en contradiction directe avec la propriété de positivité requise pour un produit scalaire. Cette option est incorrecte.

</details>

---

#### Question 2 : Calcul de produit scalaire hermitien

Soit $E=\mathbb{C}^2$ muni du produit scalaire hermitien canonique $\langle u, v \rangle = z_1 \bar{w}_1 + z_2 \bar{w}_2$. Calculez le produit scalaire entre $u=(i, 2)$ et $v=(1, 1-i)$.

- [ ] **A)** $2-i$
- [ ] **B)** $3i$
- [x] **C)** $2+3i$
- [ ] **D)** $-i$

<details>

<summary>Solution</summary>

**Réponse : [C]**

La définition du produit scalaire hermitien canonique sur $\mathbb{C}^2$ pour $u=(z_1, z_2)$ et $v=(w_1, w_2)$ est $\langle u, v \rangle = z_1 \bar{w}_1 + z_2 \bar{w}_2$. L'étape clé est de ne pas oublier de prendre le conjugué des composantes du *deuxième* vecteur.

Ici, $u=(z_1, z_2)=(i, 2)$ et $v=(w_1, w_2)=(1, 1-i)$.

1.  La première composante de $v$ est $w_1 = 1$. Son conjugué est $\bar{w}_1 = 1$.
2.  La deuxième composante de $v$ est $w_2 = 1-i$. Son conjugué est $\bar{w}_2 = 1+i$.

Maintenant, appliquons la formule :

$$ \langle u, v \rangle = z_1 \bar{w}_1 + z_2 \bar{w}_2 = (i)(1) + (2)(1+i) $$

$$ \langle u, v \rangle = i + 2 + 2i = 2 + 3i $$

- **A)** Cette réponse, $2-i$, est obtenue si on oublie de conjuguer la deuxième composante de $v$ : $i \cdot 1 + 2 \cdot (1-i) = i+2-2i = 2-i$. C'est une erreur fréquente.
- **B)** C'est une erreur de calcul.
- **C)** C'est le résultat correct du calcul.
- **D)** C'est une erreur de calcul.

</details>

---

#### Question 3 : Conséquence de l'orthogonalité

Dans un espace euclidien, si deux vecteurs non nuls $u$ et $v$ sont orthogonaux ($u \perp v$), laquelle de ces affirmations est nécessairement vraie ?

- [ ] **A)** $u$ et $v$ doivent être colinéaires.
- [x] **B)** $\|u+v\|^2 = \|u\|^2 + \|v\|^2$.
- [ ] **C)** Le produit scalaire $\langle u, v \rangle = \|u\| \|v\|$.
- [ ] **D)** $\|u-v\| = \|u\| - \|v\|$.

<details>

<summary>Solution</summary>

**Réponse : [B]**

L'orthogonalité est définie par $\langle u, v \rangle = 0$. Analysons les conséquences.

- **A)** Deux vecteurs non nuls sont colinéaires s'il existe un scalaire $\lambda$ tel que $u=\lambda v$. Dans ce cas, $\langle u,v \rangle = \langle \lambda v, v \rangle = \lambda \|v\|^2$. Pour que ce produit soit nul, il faudrait que $\lambda=0$ (donc $u=0$) ou $\|v\|=0$ (donc $v=0$), ce qui contredit l'hypothèse de vecteurs non nuls. L'orthogonalité et la colinéarité sont (pour des vecteurs non nuls) des concepts mutuellement exclusifs. Cette option est incorrecte.

- **B)** C'est le théorème de Pythagore généralisé. Développons $\|u+v\|^2$:

    $$ \|u+v\|^2 = \langle u+v, u+v \rangle = \langle u,u \rangle + \langle u,v \rangle + \langle v,u \rangle + \langle v,v \rangle $$

    $$ = \|u\|^2 + 2\langle u,v \rangle + \|v\|^2 $$

    Puisque $u$ et $v$ sont orthogonaux, $\langle u,v \rangle = 0$, et l'expression se simplifie en $\|u+v\|^2 = \|u\|^2 + \|v\|^2$. Cette option est correcte.

- **C)** Cette égalité correspond au cas d'égalité dans l'inégalité de Cauchy-Schwarz pour des vecteurs colinéaires et de même sens. Pour des vecteurs orthogonaux, le produit scalaire est nul. Cette option est incorrecte.

- **D)** Ceci est incorrect. L'inégalité triangulaire nous dit que $\|u-v\| \ge |\|u\|-\|v\||$. L'égalité n'est généralement pas vérifiée.

</details>

---

#### Question 4 : Inégalité de Cauchy-Schwarz

Selon l'inégalité de Cauchy-Schwarz dans un espace euclidien, quand l'égalité $|\langle u, v \rangle| = \|u\| \|v\|$ est-elle vérifiée ?

- [ ] **A)** Uniquement si $u$ et $v$ sont orthogonaux.
- [x] **B)** Si et seulement si les vecteurs $u$ et $v$ sont colinéaires.
- [ ] **C)** Toujours, par définition du produit scalaire.
- [ ] **D)** Uniquement si l'un des vecteurs est le vecteur nul.

<details>

<summary>Solution</summary>

**Réponse : [B]**

L'inégalité de Cauchy-Schwarz est un résultat fondamental qui s'énonce $|\langle u, v \rangle| \le \|u\| \|v\|$. Le cas d'égalité est un point clé de ce théorème.

- **A)** Si $u$ et $v$ sont orthogonaux (et non nuls), le côté gauche $|\langle u, v \rangle|$ est 0, tandis que le côté droit $\|u\| \|v\|$ est strictement positif. L'égalité n'a donc pas lieu. C'est le cas de l'inégalité la plus "stricte" possible. Cette option est incorrecte.

- **B)** C'est la condition exacte du cas d'égalité. Si $u$ et $v$ sont colinéaires, alors $u = \lambda v$ pour un scalaire $\lambda$.

    $|\langle u,v \rangle| = |\langle \lambda v, v \rangle| = |\lambda| \langle v,v \rangle = |\lambda| \|v\|^2$.

    $\|u\|\|v\| = \|\lambda v\|\|v\| = |\lambda|\|v\|\|v\| = |\lambda|\|v\|^2$.

    Les deux termes sont égaux. Réciproquement, si l'égalité a lieu, on peut montrer que la famille $(u,v)$ est liée. Cette option est correcte.

- **C)** L'inégalité n'est pas une égalité en général. Par exemple, pour $u=(1,1)$ et $v=(1,-1)$ dans $\mathbb{R}^2$, $\langle u,v \rangle = 0$ mais $\|u\|\|v\| = \sqrt{2}\sqrt{2}=2$. Donc $0 < 2$. Cette option est incorrecte.

- **D)** Si l'un des vecteurs est nul, par exemple $u=0_E$, alors $|\langle 0_E, v \rangle| = 0$ et $\|0_E\| \|v\| = 0$. L'égalité a bien lieu. Cependant, ce n'est pas le seul cas. C'est un cas particulier de "vecteurs colinéaires" ($0_E = 0 \cdot v$). La condition générale est la colinéarité. Cette option est trop restrictive.

</details>

---

#### Question 5 : Avantages des bases orthonormées

Quels sont les avantages de travailler avec une base orthonormée $(e_1, \dots, e_n)$ dans un espace euclidien ?

- [ ] **A)** Le procédé de Gram-Schmidt permet de la transformer en une base quelconque.
- [x] **B)** Le produit scalaire de deux vecteurs $x=\sum x_i e_i$ et $y=\sum y_i e_i$ se calcule simplement par $\sum x_i y_i$.
- [x] **C)** La norme d'un vecteur $x$ se calcule via l'identité de Parseval : $\|x\|^2 = \sum_{i=1}^n |\langle x, e_i \rangle|^2$.
- [x] **D)** Les coordonnées d'un vecteur $x$ sont données directement par la formule $x_i = \langle x, e_i \rangle$.

<details>

<summary>Solution</summary>

**Réponses : [B, C, D]**

Les bases orthonormées (BON) simplifient radicalement les calculs dans les espaces euclidiens ou hermitiens.

- **A)** C'est l'inverse. Le procédé de Gram-Schmidt transforme une base quelconque en une base orthonormée. Cette affirmation est incorrecte.

- **B)** C'est l'une des propriétés les plus utiles. Le produit scalaire, qui peut avoir une forme compliquée, se ramène à la somme des produits des coordonnées, comme le produit scalaire canonique dans $\mathbb{R}^n$.

    $\langle x, y \rangle = \langle \sum_i x_i e_i, \sum_j y_j e_j \rangle = \sum_i \sum_j x_i y_j \langle e_i, e_j \rangle$. Comme $\langle e_i, e_j \rangle = \delta_{ij}$, il ne reste que les termes où $i=j$, d'où $\sum_i x_i y_i$. Cette option est correcte.

- **C)** C'est l'identité de Parseval, une conséquence directe du calcul de la norme dans une BON. $\|x\|^2 = \langle x, x \rangle = \sum_i x_i^2$. Or, on sait que les coordonnées $x_i$ sont $\langle x, e_i \rangle$. En substituant, on obtient $\|x\|^2 = \sum_i |\langle x, e_i \rangle|^2$. Cette option est correcte.

- **D)** C'est la formule de calcul des coordonnées dans une BON. Si $x = \sum_j x_j e_j$, alors $\langle x, e_i \rangle = \langle \sum_j x_j e_j, e_i \rangle = \sum_j x_j \langle e_j, e_i \rangle = \sum_j x_j \delta_{ji} = x_i$. Cette simplicité est un avantage majeur. Cette option est correcte.

</details>

---

#### Question 6 : Procédé de Gram-Schmidt

On applique le procédé de Gram-Schmidt à la base $(v_1, v_2)$ de $\mathbb{R}^2$ avec $v_1=(1,1)$ et $v_2=(0,2)$. Quel est le deuxième vecteur $u_2$ (avant l'étape de normalisation) obtenu par le procédé ?

- [ ] **A)** $(1,-1)$
- [x] **B)** $(-1,1)$
- [ ] **C)** $(0,2)$
- [ ] **D)** $(1,1)$

<details>

<summary>Solution</summary>

**Réponse : [B]**

Le procédé de Gram-Schmidt construit une base orthogonale $(u_1, \dots, u_n)$ puis une base orthonormée $(e_1, \dots, e_n)$ à partir d'une base quelconque $(v_1, \dots, v_n)$.

1.  **Première étape :** On pose $u_1 = v_1 = (1,1)$. On calcule le premier vecteur normé $e_1$:

    $\|u_1\| = \sqrt{1^2+1^2} = \sqrt{2}$.

    $e_1 = \frac{u_1}{\|u_1\|} = \frac{1}{\sqrt{2}}(1,1)$.

2.  **Deuxième étape :** On calcule $u_2$ en soustrayant à $v_2$ sa projection sur la droite dirigée par $e_1$. La formule est $u_2 = v_2 - P_{\text{Vect}(e_1)}(v_2) = v_2 - \langle v_2, e_1 \rangle e_1$.

    -   Calculons le produit scalaire :

        $$ \langle v_2, e_1 \rangle = \left\langle (0,2), \frac{1}{\sqrt{2}}(1,1) \right\rangle = \frac{1}{\sqrt{2}} (0 \cdot 1 + 2 \cdot 1) = \frac{2}{\sqrt{2}} = \sqrt{2} $$

    -   Calculons $u_2$ :

        $$ u_2 = v_2 - \langle v_2, e_1 \rangle e_1 = (0,2) - \sqrt{2} \cdot \left(\frac{1}{\sqrt{2}}(1,1)\right) $$

        $$ u_2 = (0,2) - (1,1) = (-1,1) $$

Le vecteur $u_2$ (avant normalisation) est donc $(-1,1)$.

- **A)** C'est le signe opposé du bon résultat.
- **B)** C'est le résultat correct.
- **C)** C'est simplement le vecteur de départ $v_2$.
- **D)** C'est le premier vecteur $u_1$.

</details>

---

#### Question 7 : Formule de la projection orthogonale

Soit $F$ un sous-espace vectoriel d'un espace euclidien $E$ et $(e_1, \dots, e_p)$ une base orthonormée de $F$. Quelle est la formule correcte pour la projection orthogonale $P_F(x)$ d'un vecteur $x \in E$ sur $F$ ?

- [x] **A)** $P_F(x) = \sum_{i=1}^p \langle x, e_i \rangle e_i$
- [ ] **B)** $P_F(x) = x - \sum_{i=1}^p \langle x, e_i \rangle e_i$
- [ ] **C)** $P_F(x) = \sum_{i=1}^p \langle x, e_i \rangle$
- [ ] **D)** $P_F(x) = \sum_{i=1}^p \frac{\langle x, e_i \rangle}{\|e_i\|^2} e_i$

<details>

<summary>Solution</summary>

**Réponse : [A]**

La projection orthogonale d'un vecteur $x$ sur un sous-espace $F$ est la somme des projections de $x$ sur chaque vecteur d'une base orthonormée de $F$.

- **A)** Cette formule est correcte. Le scalaire $\langle x, e_i \rangle$ est la coordonnée de la projection de $x$ le long du vecteur de base $e_i$. On multiplie cette coordonnée par le vecteur $e_i$ pour obtenir le vecteur de projection sur cet axe, et on somme sur tous les vecteurs de la base de $F$.

- **B)** Cette formule représente $x - P_F(x)$. Puisque tout vecteur $x$ se décompose de manière unique en $x = P_F(x) + P_{F^\perp}(x)$, cette formule calcule en fait la projection de $x$ sur l'orthogonal de $F$, soit $P_{F^\perp}(x)$. C'est incorrect.

- **C)** La somme des produits scalaires $\sum \langle x, e_i \rangle$ est un scalaire (un nombre), alors que la projection $P_F(x)$ doit être un vecteur. Cette formule est dimensionnellement incorrecte.

- **D)** Cette formule est correcte mais redondante. Comme $(e_1, \dots, e_p)$ est une base orthonormée, chaque vecteur $e_i$ a une norme de 1, donc $\|e_i\|^2=1$. La division par 1 ne change rien. Cette formule est plus générale et s'applique à une base simplement orthogonale, mais dans le contexte d'une base orthonormée comme stipulé, la formule A est la forme standard et la plus simple.

</details>

---

#### Question 8 : Théorème de la meilleure approximation

Le théorème de la meilleure approximation stipule que pour un vecteur $x$ et un sous-espace vectoriel $F$, la projection orthogonale $P_F(x)$ est...

- [ ] **A)** un vecteur de $F^\perp$.
- [ ] **B)** toujours égal à $x$.
- [ ] **C)** ...l'unique vecteur $y \in F$ qui maximise la distance $\|x - y\|$.
- [x] **D)** ...l'unique vecteur $y \in F$ qui minimise la distance $\|x - y\|$.

<details>

<summary>Solution</summary>

**Réponse : [D]**

Ce théorème est une des applications les plus importantes de la projection orthogonale.

- **A)** Par définition, le projeté $P_F(x)$ appartient au sous-espace $F$. Le vecteur $x - P_F(x)$, qui représente l'erreur d'approximation, appartient à $F^\perp$, mais $P_F(x)$ lui-même est dans $F$. Cette option est incorrecte.

- **B)** Le projeté $P_F(x)$ n'est égal à $x$ que si $x$ appartient déjà au sous-espace $F$. En général, ce n'est pas le cas. Cette option est incorrecte.

- **C)** La projection orthogonale minimise la distance. Maximiser la distance n'a souvent pas de sens (la distance peut être infinie si $F$ n'est pas l'espace entier). Cette option est l'opposé du théorème.

- **D)** C'est l'énoncé exact du théorème de la meilleure approximation. Parmi tous les vecteurs $y$ que l'on peut choisir dans le sous-espace $F$, celui qui est "le plus proche" de $x$ (au sens de la norme euclidienne) est précisément la projection orthogonale de $x$ sur $F$. Cette option est correcte.

</details>

---

#### Question 9 : Matrice de l'adjoint

Soit $f$ un endomorphisme d'un espace hermitien $E$ de dimension finie. Si la matrice de $f$ dans une base orthonormée est $A = \begin{pmatrix} i & 1 \\ 2 & 1-i \end{pmatrix}$, quelle est la matrice de son adjoint $f^*$ dans la même base ?

- [x] **A)** $\begin{pmatrix} -i & 2 \\ 1 & 1+i \end{pmatrix}$
- [ ] **B)** $\begin{pmatrix} i & 2 \\ 1 & 1-i \end{pmatrix}$
- [ ] **C)** $\begin{pmatrix} -i & 1 \\ 2 & 1+i \end{pmatrix}$
- [ ] **D)** $\begin{pmatrix} 1+i & 2 \\ 1 & -i \end{pmatrix}$

<details>

<summary>Solution</summary>

**Réponse : [A]**

Dans un espace hermitien (complexe), la matrice de l'endomorphisme adjoint $f^*$ dans une base **orthonormée** est la **transconjuguée** (ou adjointe) de la matrice de $f$. On la note $A^\dagger$ ou $A^*$. L'opération consiste à transposer la matrice puis à prendre le conjugué de chaque coefficient (ou l'inverse).

Soit $A = \begin{pmatrix} i & 1 \\ 2 & 1-i \end{pmatrix}$.

1.  **Transposition :** On échange les lignes et les colonnes.

    $$ {}^tA = \begin{pmatrix} i & 2 \\ 1 & 1-i \end{pmatrix} $$

2.  **Conjugaison :** On prend le conjugué de chaque coefficient. Rappel : $\overline{a+ib} = a-ib$.

    $$ \overline{{}^tA} = \begin{pmatrix} \bar{i} & \bar{2} \\ \bar{1} & \overline{1-i} \end{pmatrix} = \begin{pmatrix} -i & 2 \\ 1 & 1+i \end{pmatrix} $$

La matrice de $f^*$ est donc $\begin{pmatrix} -i & 2 \\ 1 & 1+i \end{pmatrix}$.

- **A)** C'est le résultat correct.
- **B)** C'est la transposée ${}^tA$, mais sans la conjugaison. C'est la formule pour un espace euclidien (réel).
- **C)** C'est la matrice conjuguée $\bar{A}$, mais sans la transposition.
- **D)** C'est une erreur de calcul.

</details>

---

#### Question 10 : Propriétés de l'adjoint

Parmi les propriétés suivantes de l'opérateur adjoint, laquelle est **incorrecte** pour des endomorphismes $f, g$ d'un espace hermitien et un scalaire $\lambda \in \mathbb{C}$ ?

- [ ] **A)** $(f \circ g)^* = g^* \circ f^*$
- [ ] **B)** $(f+g)^* = f^* + g^*$
- [x] **C)** $(\lambda f)^* = \lambda f^*$
- [ ] **D)** $(f^*)^* = f$

<details>

<summary>Solution</summary>

**Réponse : [C]**

La question demande d'identifier la propriété incorrecte parmi celles proposées.

- **A)** L'adjoint d'une composée d'endomorphismes est la composée des adjoints, mais en inversant l'ordre. Cette propriété est correcte.

- **B)** L'adjoint d'une somme est la somme des adjoints. L'opération d'adjonction est linéaire. Cette propriété est correcte.

- **C)** C'est ici que se trouve l'erreur. Pour un scalaire complexe $\lambda$, la propriété est $(\lambda f)^* = \bar{\lambda} f^*$. L'adjoint est une application semi-linéaire (ou anti-linéaire). Le scalaire doit être conjugué. L'affirmation $(\lambda f)^* = \lambda f^*$ est donc incorrecte.

- **D)** Appliquer l'adjonction deux fois de suite redonne l'endomorphisme de départ. L'adjonction est une involution. Cette propriété est correcte.

La propriété incorrecte est donc la C.

</details>

---

#### Question 11 : Théorème de Représentation de Riesz

Que dit le théorème de représentation de Riesz pour un espace euclidien $E$ de dimension finie ?

- [ ] **A)** Tout espace vectoriel de dimension finie admet une base orthonormée.
- [x] **B)** Toute forme linéaire $l$ sur $E$ peut être représentée de manière unique par un produit scalaire avec un vecteur $y_l \in E$ (c'est-à-dire $l(x) = \langle x, y_l \rangle$ pour tout $x$).
- [ ] **C)** Tout vecteur peut être projeté orthogonalement sur un sous-espace.
- [ ] **D)** Tout endomorphisme peut être représenté par une matrice carrée.

<details>

<summary>Solution</summary>

**Réponse : [B]**

Ce théorème établit un lien fondamental entre un espace euclidien et son dual (l'espace des formes linéaires).

- **A)** Cette affirmation est vraie (c'est une conséquence du procédé de Gram-Schmidt), mais ce n'est pas le théorème de Riesz.

- **B)** C'est l'énoncé précis du théorème de Riesz. Il garantit que pour chaque application linéaire $l: E \to \mathbb{R}$ (une forme linéaire), il existe un et un seul vecteur $y_l$ dans $E$ qui "fait le travail" de $l$ via le produit scalaire. Cela crée une correspondance (un isomorphisme) entre l'espace $E$ et son dual $E^*$.

- **C)** C'est le théorème de la projection orthogonale, qui est un autre résultat important de la géométrie euclidienne, mais ce n'est pas le théorème de Riesz.

- **D)** Cette affirmation est vraie pour tout endomorphisme sur un espace de dimension finie, qu'il soit euclidien ou non. Ce n'est pas le théorème de Riesz.

</details>

---

#### Question 12 : Identification d'un produit scalaire

Laquelle des formes suivantes, définies pour $u=(x_1, x_2)$ et $v=(y_1, y_2)$ dans $\mathbb{R}^2$, est un produit scalaire valide ?

- [ ] **A)** $\varphi(u,v) = x_1 y_1$
- [ ] **B)** $\varphi(u,v) = x_1 y_2 - x_2 y_1$
- [ ] **C)** $\varphi(u,v) = x_1 y_1 - x_2 y_2$
- [x] **D)** $\varphi(u,v) = 2x_1 y_1 + x_2 y_2$

<details>

<summary>Solution</summary>

**Réponse : [D]**

Pour être un produit scalaire, une forme bilinéaire doit être symétrique et définie positive.

- **A)** $\varphi(u,v) = x_1 y_1$. C'est symétrique. Cependant, ce n'est pas défini positif. Pour le vecteur non nul $u=(0,1)$, on a $\varphi(u,u) = 0 \cdot 0 = 0$. La condition $\varphi(u,u) > 0$ pour $u \neq 0_E$ n'est pas respectée.

- **B)** $\varphi(u,v) = x_1 y_2 - x_2 y_1$. Ce n'est pas symétrique, car $\varphi(v,u) = y_1 x_2 - y_2 x_1 = -\varphi(u,v)$. C'est une forme bilinéaire alternée (le déterminant).

- **C)** $\varphi(u,v) = x_1 y_1 - x_2 y_2$. C'est symétrique. Cependant, ce n'est pas positif. Pour le vecteur $u=(0,1)$, on a $\varphi(u,u) = 0 - 1^2 = -1 < 0$.

- **D)** $\varphi(u,v) = 2x_1 y_1 + x_2 y_2$.
    1.  **Symétrie :** $\varphi(v,u) = 2y_1 x_1 + y_2 x_2 = \varphi(u,v)$. C'est symétrique.
    2.  **Définie positive :** $\varphi(u,u) = 2x_1^2 + x_2^2$. Cette somme de carrés est toujours $\ge 0$. Elle ne peut être nulle que si $2x_1^2=0$ et $x_2^2=0$, ce qui implique $x_1=0$ et $x_2=0$, donc $u=(0,0)$. La forme est bien définie positive.

    Cette forme définit un produit scalaire valide.

</details>

---

#### Question 13 : Famille orthogonale ou orthonormée ?

On considère les vecteurs $v_1 = (1, 0, 1)$ et $v_2 = (1, 1, -1)$ dans $\mathbb{R}^3$ muni du produit scalaire usuel. La famille $(v_1, v_2)$ est :

- [ ] **A)** Orthonormée
- [ ] **B)** Ni orthogonale, ni orthonormée
- [x] **C)** Orthogonale, mais pas orthonormée
- [ ] **D)** Une base de $\mathbb{R}^3$

<details>

<summary>Solution</summary>

**Réponse : [C]**

Il faut vérifier deux propriétés : l'orthogonalité (le produit scalaire des vecteurs distincts est nul) et la normalisation (chaque vecteur est de norme 1).

1.  **Orthogonalité :** Calculons le produit scalaire entre $v_1$ et $v_2$.

    $$ \langle v_1, v_2 \rangle = \langle (1,0,1), (1,1,-1) \rangle = 1 \cdot 1 + 0 \cdot 1 + 1 \cdot (-1) = 1 + 0 - 1 = 0 $$

    Le produit scalaire est nul, donc la famille est **orthogonale**.

2.  **Normalisation :** Calculons la norme de chaque vecteur.

    $$ \|v_1\| = \sqrt{1^2 + 0^2 + 1^2} = \sqrt{2} $$

    $$ \|v_2\| = \sqrt{1^2 + 1^2 + (-1)^2} = \sqrt{3} $$

    Aucun des deux vecteurs n'est de norme 1. La famille n'est donc **pas orthonormée**.

- **A)** Faux, car les vecteurs ne sont pas de norme 1.
- **B)** Faux, car la famille est orthogonale.
- **C)** Vrai, la famille est orthogonale mais pas orthonormée.
- **D)** Faux, une famille de deux vecteurs ne peut pas former une base d'un espace de dimension 3.

</details>

---

#### Question 14 : Propriétés de l'orthogonal d'un sous-espace

Soit $F$ un sous-espace vectoriel d'un espace euclidien $E$ de dimension finie. Lesquelles de ces affirmations concernant son orthogonal $F^\perp$ sont toujours vraies ?

- [ ] **A)** Tout vecteur de $E$ appartient soit à $F$, soit à $F^\perp$.
- [x] **B)** $F \cap F^\perp$ contient uniquement le vecteur nul.
- [ ] **C)** $\dim(F) - \dim(F^\perp) = 0$.
- [x] **D)** $(F^\perp)^\perp = F$.

<details>

<summary>Solution</summary>

**Réponses : [B, D]**

Analysons chaque proposition sur les propriétés de l'orthogonal $F^\perp = \{ x \in E \mid \forall y \in F, \langle x, y \rangle = 0 \}$.

- **A)** Ceci est faux. Un vecteur $x$ se décompose en $x = y+z$ avec $y \in F$ et $z \in F^\perp$. Si $y$ et $z$ sont tous les deux non nuls, alors $x$ n'appartient ni à $F$, ni à $F^\perp$. Par exemple dans $\mathbb{R}^2$, si $F$ est l'axe des abscisses, $F^\perp$ est l'axe des ordonnées. Le vecteur $(1,1)$ n'est sur aucun des deux axes.

- **B)** Soit $x \in F \cap F^\perp$. Comme $x \in F$ et $x \in F^\perp$, il doit être orthogonal à lui-même, c'est-à-dire $\langle x, x \rangle = 0$. Par la propriété "définie" du produit scalaire, cela implique que $x=0_E$. L'intersection est donc bien le sous-espace $\{0_E\}$. Cette affirmation est correcte.

- **C)** La relation correcte entre les dimensions est $\dim(F) + \dim(F^\perp) = \dim(E)$. L'affirmation $\dim(F) = \dim(F^\perp)$ n'est vraie que dans le cas particulier où $\dim(F) = \frac{1}{2}\dim(E)$. C'est donc faux en général.

- **D)** C'est une propriété fondamentale en dimension finie, connue sous le nom de "théorème du double orthogonal". Prendre l'orthogonal deux fois redonne le sous-espace de départ. Cette affirmation est correcte.

</details>

---