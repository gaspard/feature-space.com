---
id: '51661757'
type: cards
order: 22
title: Espaces Euclidiens et Hermitiens - fiches de révision (B)
tags:
  - Espaces Euclidiens
  - Espaces Hermitiens
  - Produit scalaire
  - Gram-Schmidt
  - Projection orthogonale
  - Endomorphismes adjoints
  - Théorème de Riesz
createdAt: '2025-10-12T18:14:20.536Z'
level: pro
course: Géométrie
courseId: d9494343
chapter: Espaces Euclidiens et Hermitiens
chapterId: 67b3d760
---
# Fiches de révision "Espaces Euclidiens et Hermitiens" (B)

---

Prouver l'inégalité de Cauchy-Schwarz dans un espace préhilbertien complexe $(E, \langle \cdot, \cdot \rangle)$.

<details>

<summary>Answer</summary>

**Théorème (Inégalité de Cauchy-Schwarz) :** Pour tous vecteurs $x, y \in E$, on a $|\langle x, y \rangle| \le \|x\| \|y\|$. L'égalité a lieu si et seulement si $x$ et $y$ sont colinéaires.

**Preuve :**

1.  **Cas trivial :** Si $y = 0_E$, alors $\langle x, y \rangle = 0$ et $\|y\| = 0$. L'inégalité devient $0 \le 0$, ce qui est vrai.

2.  **Cas général ($y \neq 0_E$) :** Pour tout scalaire $\lambda \in \mathbb{C}$, la positivité de la norme implique $\|x - \lambda y\|^2 \ge 0$. Développons cette expression :
    
    $0 \le \langle x - \lambda y, x - \lambda y \rangle = \langle x, x \rangle - \lambda \langle y, x \rangle - \bar{\lambda} \langle x, y \rangle + \lambda \bar{\lambda} \langle y, y \rangle$
    
    $0 \le \|x\|^2 - \lambda \overline{\langle x, y \rangle} - \bar{\lambda} \langle x, y \rangle + |\lambda|^2 \|y\|^2$

3.  **Choix optimal de $\lambda$ :** Le minimum de la distance $\|x - \lambda y\|$ est atteint pour $\lambda y$ égal à la projection de $x$ sur $y$. On choisit donc $\lambda = \frac{\langle x, y \rangle}{\|y\|^2}$. Ce choix est bien défini car $y \neq 0_E$.

4.  **Substitution :** En remplaçant $\lambda$ dans l'inégalité :
    
    $0 \le \|x\|^2 - \frac{\langle x, y \rangle}{\|y\|^2} \overline{\langle x, y \rangle} - \frac{\overline{\langle x, y \rangle}}{\|y\|^2} \langle x, y \rangle + \frac{|\langle x, y \rangle|^2}{\|y\|^4} \|y\|^2$
    
    $0 \le \|x\|^2 - \frac{|\langle x, y \rangle|^2}{\|y\|^2} - \frac{|\langle x, y \rangle|^2}{\|y\|^2} + \frac{|\langle x, y \rangle|^2}{\|y\|^2}$
    
    $0 \le \|x\|^2 - \frac{|\langle x, y \rangle|^2}{\|y\|^2}$

5.  **Conclusion :** En multipliant par $\|y\|^2 > 0$, on obtient $|\langle x, y \rangle|^2 \le \|x\|^2 \|y\|^2$. En prenant la racine carrée, on a l'inégalité voulue : $|\langle x, y \rangle| \le \|x\| \|y\|$.

**Cas d'égalité :** L'égalité a lieu si et seulement si $\|x - \lambda y\|^2 = 0$, ce qui, par la propriété de définition de la norme, équivaut à $x - \lambda y = 0_E$, c'est-à-dire $x = \lambda y$. La famille $(x, y)$ est donc liée. Réciproquement, si $x = \alpha y$, on a $|\langle \alpha y, y \rangle| = |\alpha| |\langle y, y \rangle| = |\alpha| \|y\|^2$ et $\|\alpha y\|\|y\| = |\alpha|\|y\|\|y\| = |\alpha|\|y\|^2$, d'où l'égalité.

</details>

---

Énoncer le théorème de Fréchet-von Neumann-Jordan et expliquer sa signification.

<details>

<summary>Answer</summary>

**Théorème (Fréchet-von Neumann-Jordan) :** Une norme $\|\cdot\|$ sur un $\mathbb{K}$-espace vectoriel $E$ (avec $\mathbb{K}=\mathbb{R}$ ou $\mathbb{C}$) dérive d'un produit scalaire si et seulement si elle satisfait **l'identité du parallélogramme** :

$$ \forall x,y \in E, \quad \|x+y\|^2 + \|x-y\|^2 = 2(\|x\|^2 + \|y\|^2) $$

**Signification et implications :**

Ce théorème fournit un critère fondamental pour déterminer si un espace normé est également un espace préhilbertien. Il établit un pont entre la structure géométrique (liée aux longueurs et aux parallélogrammes) et la structure algébrique d'un produit scalaire.

- **Suffisance :** Si une norme vérifie cette identité, on peut construire explicitement le produit scalaire qui l'induit en utilisant les **identités de polarisation**.
  - **Cas réel :** $\langle x, y \rangle = \frac{1}{4}(\|x+y\|^2 - \|x-y\|^2)$.
  - **Cas complexe :** $\langle x, y \rangle = \frac{1}{4}(\|x+y\|^2 - \|x-y\|^2 + i\|x+iy\|^2 - i\|x-iy\|^2)$.
  
  La partie non triviale de la preuve consiste à montrer que les formes ainsi définies sont bien bilinéaires (ou sesquilinéaires) symétriques (ou hermitiennes) définies positives.

- **Nécessité :** Si la norme dérive d'un produit scalaire, i.e., $\|v\|^2 = \langle v, v \rangle$, la vérification de l'identité est un calcul direct :

  $\|x+y\|^2 = \|x\|^2 + 2\text{Re}(\langle x,y \rangle) + \|y\|^2$

  $\|x-y\|^2 = \|x\|^2 - 2\text{Re}(\langle x,y \rangle) + \|y\|^2$

  En les sommant, on obtient le résultat.

**Exemple de norme non-euclidienne :** La norme $\|x\|_1 = \sum |x_i|$ sur $\mathbb{R}^n$ ($n \ge 2$) ne dérive pas d'un produit scalaire car elle ne vérifie pas l'identité du parallélogramme.

</details>

---

Pourquoi utilise-t-on des formes sesquilinéaires plutôt que bilinéaires pour définir le produit scalaire sur des espaces vectoriels complexes ?

<details>

<summary>Answer</summary>

L'utilisation de formes sesquilinéaires (linéaires à gauche, semi-linéaires à droite) au lieu de formes bilinéaires sur un $\mathbb{C}$-espace vectoriel $E$ est cruciale pour obtenir une norme ayant les propriétés désirées, notamment d'être à valeurs réelles et positive.

Soit $\varphi: E \times E \to \mathbb{C}$ une forme servant à définir une norme via $\|x\|^2 = \varphi(x,x)$.

**Hypothèse 1 : $\varphi$ est bilinéaire.**

Si $\varphi$ était bilinéaire, on aurait $\varphi(\lambda x, \lambda x) = \lambda^2 \varphi(x,x)$.

Pour $x \in E$ et $\lambda=i \in \mathbb{C}$, cela donnerait :

$\|ix\|^2 = \varphi(ix, ix) = i^2 \varphi(x,x) = - \varphi(x,x) = -\|x\|^2$.

Cela pose deux problèmes majeurs :

1.  **Positivité non garantie :** Si $\|x\|^2 > 0$, alors $\|ix\|^2 < 0$. Une "norme au carré" ne peut pas être négative.
2.  **Homogénéité de la norme :** La propriété de la norme $\|\lambda x\| = |\lambda| \|x\|$ ne serait pas respectée. On aurait $\|ix\| = \sqrt{-\|x\|^2}$ qui n'est même pas un nombre réel si $\|x\| \neq 0$.

**Hypothèse 2 : $\varphi$ est sesquilinéaire hermitienne.**

Si $\varphi$ est sesquilinéaire, on a $\varphi(\lambda x, \lambda x) = \lambda \bar{\lambda} \varphi(x,x) = |\lambda|^2 \varphi(x,x)$.

Ainsi, $\| \lambda x \|^2 = |\lambda|^2 \|x\|^2$, ce qui donne en prenant la racine : $\|\lambda x\| = |\lambda| \|x\|$. C'est la propriété d'homogénéité requise pour une norme.

De plus, la condition de symétrie hermitienne, $\varphi(x,y) = \overline{\varphi(y,x)}$, implique que $\varphi(x,x) = \overline{\varphi(x,x)}$, ce qui garantit que **$\varphi(x,x)$ est toujours un nombre réel**.

En conclusion, la structure sesquilinéaire est la construction "naturelle" qui assure que la quantité $\varphi(x,x)$ soit un réel positif, permettant de définir une norme cohérente sur un espace vectoriel complexe.

</details>

---

Démontrer que toute famille orthogonale de vecteurs non nuls est libre.

<details>

<summary>Answer</summary>

**Théorème :** Soit $(v_1, v_2, ..., v_n)$ une famille orthogonale de vecteurs d'un espace préhilbertien $E$. Si tous les $v_i$ sont non nuls, alors la famille est libre.

**Preuve :**

Soit une combinaison linéaire nulle de ces vecteurs :

$$ \sum_{i=1}^n \lambda_i v_i = 0_E $$

où les $\lambda_i$ sont des scalaires du corps $\mathbb{K}$.

Pour montrer que la famille est libre, nous devons prouver que tous les coefficients $\lambda_i$ sont nuls.

Fixons un indice $j \in \{1, ..., n\}$. Effectuons le produit scalaire de l'équation ci-dessus par le vecteur $v_j$ :

$$ \left\langle \sum_{i=1}^n \lambda_i v_i, v_j \right\rangle = \langle 0_E, v_j \rangle = 0 $$

Par linéarité (à gauche) du produit scalaire, nous pouvons développer le membre de gauche :

$$ \sum_{i=1}^n \lambda_i \langle v_i, v_j \rangle = 0 $$

La famille $(v_i)$ étant orthogonale, on a $\langle v_i, v_j \rangle = 0$ pour tout $i \neq j$. La somme se simplifie donc radicalement, car seul le terme pour $i=j$ est potentiellement non nul :

$$ \lambda_1 \langle v_1, v_j \rangle + \dots + \lambda_j \langle v_j, v_j \rangle + \dots + \lambda_n \langle v_n, v_j \rangle = 0 $$

$$ \lambda_j \langle v_j, v_j \rangle = 0 $$

Cette équation peut s'écrire :

$$ \lambda_j \|v_j\|^2 = 0 $$

Par hypothèse, les vecteurs $v_i$ sont non nuls. Par conséquent, $\|v_j\| \neq 0$, et donc $\|v_j\|^2 \neq 0$.

Pour que le produit $\lambda_j \|v_j\|^2$ soit nul, il faut nécessairement que $\lambda_j = 0$.

Comme ce raisonnement est valable pour n'importe quel indice $j \in \{1, ..., n\}$, nous avons démontré que $\lambda_1 = \lambda_2 = \dots = \lambda_n = 0$.

Ceci prouve que la famille $(v_1, ..., v_n)$ est libre.

</details>

---

Montrer que $\langle A, B \rangle = \text{Tr}(A B^*)$ définit un produit scalaire hermitien sur l'espace $M_p(\mathbb{C})$.

<details>

<summary>Answer</summary>

Soit $E = M_p(\mathbb{C})$. On définit $\varphi(A,B) = \text{Tr}(A B^*)$ où $B^* = \overline{{}^tB}$ est la transconjuguée de $B$. Nous devons vérifier les trois axiomes d'un produit scalaire hermitien.

**1. Sesquilinéarité :**

- **Linéarité à gauche :** Soient $A_1, A_2, B \in E$ et $\lambda \in \mathbb{C}$.
  
  $\varphi(A_1 + \lambda A_2, B) = \text{Tr}((A_1 + \lambda A_2)B^*) = \text{Tr}(A_1 B^* + \lambda A_2 B^*)$
  
  Par linéarité de la trace :
  
  $= \text{Tr}(A_1 B^*) + \lambda \text{Tr}(A_2 B^*) = \varphi(A_1, B) + \lambda \varphi(A_2, B)$.
  
  La linéarité à gauche est vérifiée.

- **Semi-linéarité à droite :** Soient $A, B_1, B_2 \in E$ et $\lambda \in \mathbb{C}$.
  
  $\varphi(A, B_1 + \lambda B_2) = \text{Tr}(A (B_1 + \lambda B_2)^*) = \text{Tr}(A (B_1^* + \overline{\lambda} B_2^*))$
  
  $= \text{Tr}(A B_1^* + \overline{\lambda} A B_2^*) = \text{Tr}(A B_1^*) + \overline{\lambda} \text{Tr}(A B_2^*) = \varphi(A, B_1) + \overline{\lambda} \varphi(A, B_2)$.
  
  La semi-linéarité à droite est vérifiée.

**2. Symétrie hermitienne :**

Nous devons montrer que $\varphi(A,B) = \overline{\varphi(B,A)}$.

$\overline{\varphi(B,A)} = \overline{\text{Tr}(B A^*)} = \text{Tr}(\overline{B A^*})$.

En utilisant les propriétés de la conjugaison et de la trace : $\overline{\text{Tr}(M)} = \text{Tr}(\overline{M})$ et $\overline{MN} = \overline{M}\overline{N}$.

$\overline{\varphi(B,A)} = \text{Tr}(\overline{B} \overline{A^*})$.

Puisque $\overline{A^*} = \overline{\overline{{}^tA}} = {}^tA$, on a :

$\overline{\varphi(B,A)} = \text{Tr}(\overline{B} {}^tA)$.

On utilise la propriété $\text{Tr}(XY) = \text{Tr}(YX)$. Soit $X=\overline{B}$ et $Y={}^tA$.

$\text{Tr}(\overline{B} {}^tA) = \text{Tr}({}^tA \overline{B})$.

Enfin, on utilise $\text{Tr}(M) = \text{Tr}({}^tM)$.

$\text{Tr}({}^tA \overline{B}) = \text{Tr}({}^t({}^tA \overline{B})) = \text{Tr}({}^t(\overline{B}) A) = \text{Tr}(B^* A) = \text{Tr}(A B^*) = \varphi(A,B)$.

La symétrie hermitienne est vérifiée.

**3. Définie-positivité :**

- **Positivité :**

  $\varphi(A,A) = \text{Tr}(A A^*) = \sum_{i=1}^p (AA^*)_{ii}$.

  L'élément $(i,i)$ de $AA^*$ est donné par le produit de la $i$-ème ligne de $A$ et de la $i$-ème colonne de $A^*$.

  $(AA^*)_{ii} = \sum_{j=1}^p a_{ij} (A^*)_{ji} = \sum_{j=1}^p a_{ij} \overline{a_{ij}} = \sum_{j=1}^p |a_{ij}|^2$.

  Donc, $\varphi(A,A) = \sum_{i=1}^p \sum_{j=1}^p |a_{ij}|^2$.

  C'est une somme de termes réels positifs, donc $\varphi(A,A) \ge 0$.

- **Définie :**

  $\varphi(A,A) = 0 \iff \sum_{i,j} |a_{ij}|^2 = 0$.

  Une somme de termes positifs est nulle si et seulement si chaque terme est nul.

  $\iff |a_{ij}|^2 = 0$ pour tous $i,j$.

  $\iff a_{ij} = 0$ pour tous $i,j$.

  $\iff A = 0_{M_p(\mathbb{C})}$.

La forme est bien définie positive.

Les trois axiomes étant vérifiés, $\langle A, B \rangle = \text{Tr}(A B^*)$ est un produit scalaire hermitien sur $M_p(\mathbb{C})$.

</details>

---

Énoncer les identités de polarisation dans les cas euclidien et hermitien, et expliquer leur rôle fondamental.

<details>

<summary>Answer</summary>

Les identités de polarisation expriment le produit scalaire en termes de la norme qu'il induit. Elles sont différentes dans le cas réel (euclidien) et complexe (hermitien).

**Cas Euclidien ($\mathbb{K}=\mathbb{R}$)**

Pour une forme bilinéaire symétrique $\varphi(x,y) = \langle x,y \rangle$ et sa norme associée $\|x\|^2 = \langle x,x \rangle$:

$$ \langle x, y \rangle = \frac{1}{2} (\|x+y\|^2 - \|x\|^2 - \|y\|^2) $$

ou, de manière plus symétrique :

$$ \langle x, y \rangle = \frac{1}{4}(\|x+y\|^2 - \|x-y\|^2) $$

*Preuve (pour la 2ème forme) :* $\|x+y\|^2 - \|x-y\|^2 = (\langle x,x \rangle + 2\langle x,y \rangle + \langle y,y \rangle) - (\langle x,x \rangle - 2\langle x,y \rangle + \langle y,y \rangle) = 4\langle x,y \rangle$.

**Cas Hermitien ($\mathbb{K}=\mathbb{C}$)**

Pour une forme sesquilinéaire hermitienne $\varphi(x,y) = \langle x,y \rangle$ :

$$ \langle x, y \rangle = \frac{1}{4} \sum_{k=0}^3 i^k \|x+i^k y\|^2 = \frac{1}{4} (\|x+y\|^2 - \|x-y\|^2 + i\|x+iy\|^2 - i\|x-iy\|^2) $$

*Note :* La partie réelle de $\langle x,y \rangle$ est $\text{Re}(\langle x,y \rangle) = \frac{1}{4}(\|x+y\|^2 - \|x-y\|^2)$ et sa partie imaginaire est $\text{Im}(\langle x,y \rangle) = \text{Re}(\langle x, -iy \rangle) = \frac{1}{4}(\|x-iy\|^2 - \|x+iy\|^2)$, ce qui mène à la formule complète.

**Rôle Fondamental :**

1.  **Unicité :** Les identités de polarisation montrent qu'un produit scalaire est **entièrement déterminé** par la norme qu'il induit. Si deux produits scalaires sur un même espace engendrent la même norme, alors ces produits scalaires sont identiques.

2.  **Caractérisation :** Elles sont au cœur de la preuve du théorème de Fréchet-von Neumann-Jordan. Si une norme vérifie l'identité du parallélogramme, on peut *définir* une forme bilinéaire ou sesquilinéaire via ces identités et ensuite prouver qu'elle a bien toutes les propriétés d'un produit scalaire.

3.  **Lien entre géométrie et algèbre :** Elles formalisent le lien intime entre la notion "géométrique" de longueur (la norme) et la notion "algébrique/géométrique" d'angle et de projection (le produit scalaire).

</details>

---

Expliquer la nature de l'espace-temps de Minkowski $\mathbb{R}^4$ muni de la forme $\varphi(x,y) = x_1y_1 + x_2y_2 + x_3y_3 - x_4y_4$. En quoi diffère-t-il d'un espace euclidien ?

<details>

<summary>Answer</summary>

L'espace-temps de Minkowski est l'espace vectoriel $\mathbb{R}^4$ muni de la forme bilinéaire symétrique $\varphi$ définie par :

$$ \varphi(x,y) = x_1y_1 + x_2y_2 + x_3y_3 - x_4y_4 $$

où les trois premières coordonnées sont spatiales et la quatrième est temporelle (parfois notée $x_0$ et affectée du signe $+$, avec un signe $-$ pour l'espace, selon les conventions). On l'appelle souvent une **métrique de Lorentz**.

**Différences fondamentales avec un espace euclidien :**

1.  **Non-positivité :** La forme $\varphi$ n'est pas positive, et donc encore moins définie positive. La quantité $\varphi(x,x)$ peut être positive, négative ou nulle pour des vecteurs $x$ non nuls.
    -   $\varphi(x,x) > 0$ : $x$ est un vecteur de **genre espace**.
    -   $\varphi(x,x) < 0$ : $x$ est un vecteur de **genre temps**.
    -   $\varphi(x,x) = 0$ (avec $x \neq 0$) : $x$ est un vecteur de **genre lumière** (ou isotrope). Ces vecteurs forment le **cône de lumière**.
    
    *Exemple :* Soit $x = (0,0,0,1)$. Alors $\varphi(x,x) = -1 < 0$. $x$ est de genre temps.

    *Exemple :* Soit $v = (1,0,0,1)$. Alors $\varphi(v,v) = 1^2 - 1^2 = 0$. $v$ est un vecteur de genre lumière.

2.  **Pas un produit scalaire :** Puisque la forme n'est pas définie positive, ce n'est pas un produit scalaire euclidien. L'espace de Minkowski **n'est pas** un espace euclidien.

3.  **Géométrie non-euclidienne :** La géométrie induite est radicalement différente.
    -   La "norme au carré" $\varphi(x,x)$ n'est pas toujours positive, donc on ne peut pas définir une norme au sens usuel. On parle de **pseudo-norme**.
    -   L'inégalité de Cauchy-Schwarz n'est pas valide dans sa forme habituelle. Pour deux vecteurs de genre temps orientés vers le futur, elle est même inversée.
    -   La notion d'orthogonalité est différente. Un vecteur non nul peut être orthogonal à lui-même ($\varphi(x,x)=0$).

**Signification en physique :**

L'espace de Minkowski est le cadre mathématique de la relativité restreinte.

- Les trajectoires des particules massives sont des courbes de genre temps.
- Les trajectoires des photons (particules de lumière) sont des courbes de genre lumière.
- La quantité $\varphi(x-y, x-y)$ représente le carré de l'**intervalle d'espace-temps** entre deux événements $x$ et $y$. Sa valeur est invariante par les transformations de Lorentz, qui sont les "isométries" de cet espace, remplaçant les rotations et translations de l'espace euclidien.

</details>

---

Démontrer l'inégalité triangulaire pour une norme induite par un produit scalaire.

<details>

<summary>Answer</summary>

**Théorème (Inégalité triangulaire) :** Soit $(E, \langle \cdot, \cdot \rangle)$ un espace préhilbertien. Pour tous $x, y \in E$, on a :

$$ \|x+y\| \le \|x\| + \|y\| $$

**Preuve :**

La preuve repose sur l'utilisation de l'inégalité de Cauchy-Schwarz.

1.  On commence par calculer le carré de la norme de la somme :
    
    $\|x+y\|^2 = \langle x+y, x+y \rangle$

2.  Par bilinéarité (ou sesquilinéarité) du produit scalaire :
    
    $\|x+y\|^2 = \langle x,x \rangle + \langle x,y \rangle + \langle y,x \rangle + \langle y,y \rangle$
    
    En utilisant la définition de la norme et le fait que $\langle y,x \rangle = \overline{\langle x,y \rangle}$ (symétrie hermitienne), on obtient :
    
    $\|x+y\|^2 = \|x\|^2 + \langle x,y \rangle + \overline{\langle x,y \rangle} + \|y\|^2$

3.  Rappelons que pour tout nombre complexe $z$, $z + \bar{z} = 2 \text{Re}(z)$. Donc :
    
    $\|x+y\|^2 = \|x\|^2 + 2 \text{Re}(\langle x,y \rangle) + \|y\|^2$

4.  On utilise maintenant l'inégalité de Cauchy-Schwarz, $|\langle x,y \rangle| \le \|x\|\|y\|$.
    
    Pour tout nombre complexe $z$, on a $\text{Re}(z) \le |z|$. Donc, $\text{Re}(\langle x,y \rangle) \le |\langle x,y \rangle|$.
    
    En combinant ces deux inégalités, on a :
    
    $\text{Re}(\langle x,y \rangle) \le \|x\|\|y\|$

5.  En substituant cette majoration dans l'expression de $\|x+y\|^2$ :
    
    $\|x+y\|^2 \le \|x\|^2 + 2 \|x\|\|y\| + \|y\|^2$

6.  Le membre de droite est une identité remarquable :
    
    $\|x+y\|^2 \le (\|x\| + \|y\|)^2$

7.  La norme étant une quantité positive, on peut prendre la racine carrée des deux côtés de l'inégalité pour obtenir le résultat final :
    
    $\|x+y\| \le \|x\| + \|y\|$

</details>

---

Soit $E = \mathbb{R}_n[X]$ l'espace des polynômes de degré au plus $n$. Montrer que l'application $\langle P, Q \rangle = \int_{-1}^{1} P(t)Q(t) dt$ définit bien un produit scalaire euclidien.

<details>

<summary>Answer</summary>

Pour montrer que $\langle \cdot, \cdot \rangle$ est un produit scalaire euclidien sur $E = \mathbb{R}_n[X]$, nous devons vérifier qu'il s'agit d'une forme bilinéaire symétrique définie positive.

**1. Forme bilinéaire :**

Soient $P_1, P_2, Q \in E$ et $\lambda \in \mathbb{R}$.

- **Linéarité à gauche :**

  $\langle P_1 + \lambda P_2, Q \rangle = \int_{-1}^{1} (P_1(t) + \lambda P_2(t))Q(t) dt$

  $= \int_{-1}^{1} (P_1(t)Q(t) + \lambda P_2(t)Q(t)) dt$

  Par linéarité de l'intégrale :

  $= \int_{-1}^{1} P_1(t)Q(t) dt + \lambda \int_{-1}^{1} P_2(t)Q(t) dt$

  $= \langle P_1, Q \rangle + \lambda \langle P_2, Q \rangle$.

- La **linéarité à droite** se démontre de manière identique.

**2. Symétrie :**

Soient $P, Q \in E$.

$\langle P, Q \rangle = \int_{-1}^{1} P(t)Q(t) dt$.

La multiplication dans $\mathbb{R}$ étant commutative, $P(t)Q(t) = Q(t)P(t)$.

Donc, $\langle P, Q \rangle = \int_{-1}^{1} Q(t)P(t) dt = \langle Q, P \rangle$.

La forme est symétrique.

**3. Définie-positivité :**

Soit $P \in E$.

- **Positivité :**

  $\langle P, P \rangle = \int_{-1}^{1} P(t)^2 dt$.

  Pour tout $t \in [-1, 1]$, $P(t)^2 \ge 0$. L'intégrale d'une fonction positive est positive.

  Donc, $\langle P, P \rangle \ge 0$.

- **Définie :**

  Supposons que $\langle P, P \rangle = 0$, c'est-à-dire $\int_{-1}^{1} P(t)^2 dt = 0$.

  La fonction $t \mapsto P(t)^2$ est :

  - Continue sur l'intervalle $[-1, 1]$ (car $P$ est un polynôme).
  - Positive sur cet intervalle.
  
  Le théorème de positivité de l'intégrale affirme que si l'intégrale d'une fonction continue et positive sur un intervalle $[a,b]$ (avec $a<b$) est nulle, alors la fonction est identiquement nulle sur cet intervalle.
  
  Donc, $P(t)^2 = 0$ pour tout $t \in [-1, 1]$.

  Ceci implique que $P(t) = 0$ pour tout $t \in [-1, 1]$.
  
  Un polynôme qui a une infinité de racines est nécessairement le polynôme nul. Puisque $P$ s'annule sur tout l'intervalle $[-1, 1]$, $P$ est le polynôme nul, $P=0_E$.

La forme est donc bien définie positive.

Ayant vérifié les trois propriétés, nous concluons que $\langle P, Q \rangle = \int_{-1}^{1} P(t)Q(t) dt$ est un produit scalaire sur $\mathbb{R}_n[X]$, qui devient ainsi un espace euclidien de dimension $n+1$.

</details>

---

Prouver le théorème de Pythagore généralisé pour une famille orthogonale de vecteurs.

<details>

<summary>Answer</summary>

**Théorème de Pythagore généralisé :** Soit $(v_1, v_2, ..., v_n)$ une famille orthogonale de vecteurs dans un espace préhilbertien $(E, \langle \cdot, \cdot \rangle)$. Alors :

$$ \left\| \sum_{i=1}^n v_i \right\|^2 = \sum_{i=1}^n \|v_i\|^2 $$

**Preuve :**

1.  Par définition de la norme, le carré de la norme de la somme est le produit scalaire de la somme avec elle-même :
    
    $$ \left\| \sum_{i=1}^n v_i \right\|^2 = \left\langle \sum_{i=1}^n v_i, \sum_{j=1}^n v_j \right\rangle $$

2.  On utilise la bilinéarité (ou sesquilinéarité) du produit scalaire pour développer cette expression. Cela donne une double somme :
    
    $$ \left\langle \sum_{i=1}^n v_i, \sum_{j=1}^n v_j \right\rangle = \sum_{i=1}^n \sum_{j=1}^n \langle v_i, v_j \rangle $$

3.  On utilise maintenant l'hypothèse cruciale : la famille $(v_k)$ est **orthogonale**. Par définition, cela signifie que pour tous indices $i$ et $j$ distincts ($i \neq j$), on a $\langle v_i, v_j \rangle = 0$.

4.  La double somme se simplifie donc considérablement. Les seuls termes qui ne s'annulent pas sont ceux pour lesquels $i=j$ :
    
    $$ \sum_{i=1}^n \sum_{j=1}^n \langle v_i, v_j \rangle = \sum_{i=1}^n \langle v_i, v_i \rangle $$
    
    (Tous les termes croisés $\langle v_i, v_j \rangle$ avec $i \neq j$ sont nuls).

5.  Enfin, on reconnaît que $\langle v_i, v_i \rangle$ est, par définition, le carré de la norme de $v_i$ :
    
    $$ \sum_{i=1}^n \langle v_i, v_i \rangle = \sum_{i=1}^n \|v_i\|^2 $$

En combinant les étapes, nous avons montré que :

$$ \left\| \sum_{i=1}^n v_i \right\|^2 = \sum_{i=1}^n \|v_i\|^2 $$

ce qui achève la démonstration.

</details>
