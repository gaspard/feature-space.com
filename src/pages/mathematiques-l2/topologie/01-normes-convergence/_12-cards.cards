---
id: fa47134d
type: cards
order: 12
title: Normes sur Rⁿ et suites convergentes - fiches de révision (A)
tags:
  - normes
  - suites
  - convergence
  - topologie
  - analyse
createdAt: '2025-10-12T15:02:23.733Z'
level: regular
course: Topologie I
courseId: 34e61f8e
chapter: Normes sur Rⁿ et suites convergentes
chapterId: 629d2832
---
# Fiches de révision "Normes sur Rⁿ et suites convergentes" (A)

---

Qu'est-ce qu'une norme sur l'espace vectoriel $\mathbb{R}^n$ ?

<details>

<summary>Réponse</summary>

Une **norme** sur $\mathbb{R}^n$ est une application, notée $\| \cdot \|$, qui associe à chaque vecteur $x \in \mathbb{R}^n$ un nombre réel positif ou nul $\|x\|$, et qui doit satisfaire trois propriétés fondamentales (appelées axiomes).

Pour tous vecteurs $x, y \in \mathbb{R}^n$ et tout scalaire $\lambda \in \mathbb{R}$ :

1.  **Séparation (ou non-dégénérescence)** : $\|x\| = 0 \iff x = 0_{\mathbb{R}^n}$.
    -   **Explication** : Seul le vecteur nul a une longueur nulle. Tout autre vecteur a une longueur strictement positive. C'est ce qui permet de "séparer" les points.

2.  **Homogénéité** : $\|\lambda x\| = |\lambda| \|x\|$.
    -   **Explication** : Si on multiplie un vecteur par un scalaire $\lambda$ (on l'étire ou le comprime), sa nouvelle longueur est l'ancienne longueur multipliée par la valeur absolue de $\lambda$.

3.  **Inégalité triangulaire (ou sous-additivité)** : $\|x + y\| \le \|x\| + \|y\|$.
    -   **Explication** : Géométriquement, la longueur du côté d'un triangle formé par les vecteurs $x$, $y$ et $x+y$ est toujours inférieure ou égale à la somme des longueurs des deux autres côtés. En d'autres termes, le chemin direct est le plus court.

Un espace vectoriel muni d'une norme est appelé un **espace vectoriel normé**. La norme généralise la notion intuitive de "longueur" d'un vecteur.

</details>

---

Expliquez l'inégalité triangulaire pour une norme et son interprétation géométrique.

<details>

<summary>Réponse</summary>

L'inégalité triangulaire est le troisième axiome de la définition d'une norme. Elle s'énonce ainsi :

Pour tous vecteurs $x, y \in \mathbb{R}^n$, on a :

$$ \|x + y\| \le \|x\| + \|y\| $$

**Interprétation conceptuelle :**

Cette propriété formalise l'idée que "le chemin le plus court entre deux points est la ligne droite".

**Interprétation géométrique :**

Imaginons trois points dans l'espace : l'origine $O$, le point $A$ (extrémité du vecteur $x$) et le point $B$ (extrémité du vecteur $x+y$).

- Le vecteur $x$ va de $O$ à $A$. Sa longueur est $\|x\|$.
- Le vecteur $y$ va de $A$ à $B$. Sa longueur est $\|y\|$.
- Le vecteur $x+y$ va directement de $O$ à $B$. Sa longueur est $\|x+y\|$.

Les points $O, A, B$ forment un triangle. L'inégalité triangulaire $\|x+y\| \le \|x\| + \|y\|$ signifie que la longueur du trajet direct de $O$ à $B$ est inférieure ou égale à la longueur du trajet qui passe par $A$ ($O \to A \to B$).

L'égalité $\|x+y\| = \|x\| + \|y\|$ se produit lorsque les vecteurs $x$ et $y$ sont colinéaires et de même sens (le point $A$ est sur le segment $[OB]$).

</details>

---

Quelles sont les formules des trois normes fondamentales sur $\mathbb{R}^n$ ?

<details>

<summary>Réponse</summary>

Pour un vecteur $x = (x_1, x_2, \dots, x_n) \in \mathbb{R}^n$, les trois normes les plus courantes sont :

**1. Norme 1 (ou Norme de Manhattan)**

$$ \|x\|_1 = \sum_{j=1}^{n} |x_j| = |x_1| + |x_2| + \dots + |x_n| $$

**Utilisée pour :** Mesurer une distance "en grille", comme un taxi qui ne peut se déplacer que le long des rues.

**2. Norme 2 (ou Norme Euclidienne)**

$$ \|x\|_2 = \sqrt{\sum_{j=1}^{n} x_j^2} = \sqrt{x_1^2 + x_2^2 + \dots + x_n^2} $$

**Utilisée pour :** C'est la notion habituelle de longueur "à vol d'oiseau", issue du théorème de Pythagore. C'est la norme la plus intuitive.

**3. Norme infinie (ou Norme du maximum)**

$$ \|x\|_\infty = \max_{1 \le j \le n} |x_j| = \max(|x_1|, |x_2|, \dots, |x_n|) $$

**Utilisée pour :** Mesurer la plus grande composante d'un vecteur en valeur absolue. Utile pour contrôler l'erreur maximale dans des approximations.

</details>

---

Calculez les normes $\| \cdot \|_1$, $\| \cdot \|_2$ et $\| \cdot \|_\infty$ pour le vecteur $v = (2, -4, 4)$ dans $\mathbb{R}^3$.

<details>

<summary>Réponse</summary>

Soit le vecteur $v = (2, -4, 4) \in \mathbb{R}^3$.

**1. Calcul de la norme 1 :**

La norme 1 est la somme des valeurs absolues des composantes.

$$ \|v\|_1 = |2| + |-4| + |4| = 2 + 4 + 4 = 10 $$

**2. Calcul de la norme 2 :**

La norme 2 est la racine carrée de la somme des carrés des composantes.

$$ \|v\|_2 = \sqrt{2^2 + (-4)^2 + 4^2} = \sqrt{4 + 16 + 16} = \sqrt{36} = 6 $$

**3. Calcul de la norme infinie :**

La norme infinie est le maximum des valeurs absolues des composantes.

$$ \|v\|_\infty = \max(|2|, |-4|, |4|) = \max(2, 4, 4) = 4 $$

On remarque bien que pour un même vecteur, les trois normes donnent des valeurs de "longueur" différentes.

</details>

---

Comment vérifier si une application $N: \mathbb{R}^2 \to \mathbb{R}_+$ est une norme ?

<details>

<summary>Réponse</summary>

Pour vérifier si une application $N$ est une norme sur $\mathbb{R}^2$, il faut vérifier un par un les trois axiomes de la définition pour des vecteurs génériques $x=(x_1, x_2)$, $y=(y_1, y_2)$ et un scalaire $\lambda \in \mathbb{R}$.

**Étapes :**

1.  **Vérifier la séparation :** Montrer que $N(x) = 0 \iff x = (0,0)$.
    -   Montrer que si $x=(0,0)$, alors $N(x)=0$.
    -   Montrer que si $N(x)=0$, alors cela implique nécessairement $x_1=0$ et $x_2=0$.

2.  **Vérifier l'homogénéité :** Montrer que $N(\lambda x) = |\lambda| N(x)$.
    -   Calculer $N(\lambda x) = N(\lambda x_1, \lambda x_2)$ en utilisant la définition de $N$.
    -   Manipuler l'expression pour faire apparaître $|\lambda|$ en facteur de l'expression de $N(x)$.

3.  **Vérifier l'inégalité triangulaire :** Montrer que $N(x+y) \le N(x) + N(y)$.
    -   Calculer $N(x+y) = N(x_1+y_1, x_2+y_2)$.
    -   Utiliser les propriétés de la valeur absolue (notamment $|a+b| \le |a|+|b|$) sur les composantes pour majorer l'expression.
    -   Réarranger les termes pour faire apparaître la somme $N(x) + N(y)$.

**Exemple rapide :** $N(x_1, x_2) = |x_1| + |x_2|$ (norme 1).

- **Séparation :** $|x_1|+|x_2|=0 \iff |x_1|=0$ et $|x_2|=0 \iff x_1=0$ et $x_2=0$. C'est vérifié.
- **Homogénéité :** $N(\lambda x_1, \lambda x_2) = |\lambda x_1| + |\lambda x_2| = |\lambda||x_1| + |\lambda||x_2| = |\lambda|(|x_1|+|x_2|) = |\lambda|N(x)$. C'est vérifié.
- **Inégalité triangulaire :** $N(x_1+y_1, x_2+y_2) = |x_1+y_1| + |x_2+y_2| \le (|x_1|+|y_1|) + (|x_2|+|y_2|) = (|x_1|+|x_2|) + (|y_1|+|y_2|) = N(x)+N(y)$. C'est vérifié.

Donc $N$ est bien une norme.

</details>

---

Quand dit-on que deux normes sur $\mathbb{R}^n$ sont équivalentes ?

<details>

<summary>Réponse</summary>

Soient $N_1$ et $N_2$ deux normes sur l'espace vectoriel $\mathbb{R}^n$.

On dit que $N_1$ et $N_2$ sont **équivalentes** s'il existe deux constantes réelles **strictement positives**, $\alpha > 0$ et $\beta > 0$, telles que pour **tout** vecteur $x \in \mathbb{R}^n$, l'encadrement suivant est vrai :

$$ \alpha N_1(x) \le N_2(x) \le \beta N_1(x) $$

**Explication :**

Cette double inégalité signifie que les deux normes se "contrôlent" mutuellement. Si un vecteur est considéré comme "petit" par la norme $N_1$ (c'est-à-dire que $N_1(x)$ est proche de zéro), alors il sera aussi considéré comme "petit" par la norme $N_2$, et inversement.

Les constantes $\alpha$ et $\beta$ sont universelles, c'est-à-dire qu'elles doivent être les mêmes pour tous les vecteurs $x$ de l'espace. Elles peuvent cependant dépendre de la dimension $n$ de l'espace.

</details>

---

Quel est le théorème fondamental sur l'équivalence des normes, et sa principale conséquence ?

<details>

<summary>Réponse</summary>

**Théorème fondamental :**

Dans un espace vectoriel de dimension finie, comme $\mathbb{R}^n$, **toutes les normes sont équivalentes entre elles**.

**Principale conséquence :**

La conséquence la plus importante de ce théorème est que les notions topologiques (liées à la "proximité") ne dépendent pas du choix de la norme. Plus précisément :

-   **Convergence des suites :** Une suite de vecteurs $(x^k)$ qui converge vers une limite $a$ pour une certaine norme, convergera aussi vers la même limite $a$ pour n'importe quelle autre norme.

On peut donc parler de "suite convergente dans $\mathbb{R}^n$" sans avoir à préciser la norme utilisée. Cela simplifie énormément l'étude de l'analyse dans $\mathbb{R}^n$, car on peut choisir la norme la plus pratique pour un problème donné (souvent la norme infinie $\| \cdot \|_\infty$ ou la norme 1 $\| \cdot \|_1$) en sachant que les résultats sur la convergence seront valables pour toutes les autres normes.

</details>

---

Comment définit-on la convergence d'une suite de vecteurs $(x^k)$ vers un vecteur $a$ dans $\mathbb{R}^n$ ?

<details>

<summary>Réponse</summary>

Soit $(x^k)_{k \in \mathbb{N}}$ une suite de vecteurs de $\mathbb{R}^n$, $a$ un vecteur de $\mathbb{R}^n$, et $\| \cdot \|$ une norme sur $\mathbb{R}^n$.

On dit que la suite $(x^k)$ **converge vers** $a$ si la suite des distances (qui est une suite de nombres réels positifs) $\|x^k - a\|$ tend vers $0$ lorsque $k$ tend vers l'infini.

La définition formelle, très similaire à celle pour les suites réelles, est :

$$ \forall \varepsilon > 0, \quad \exists k_\varepsilon \in \mathbb{N} \text{ tel que } \forall k \ge k_\varepsilon, \quad \|x^k - a\| < \varepsilon $$

**Interprétation :**

Pour n'importe quelle petite distance $\varepsilon > 0$ que vous choisissez, il existe un rang $k_\varepsilon$ à partir duquel tous les termes de la suite $x^k$ se trouvent à l'intérieur de la "boule" de centre $a$ et de rayon $\varepsilon$. La suite se "rapproche" indéfiniment de $a$.

On note alors $\lim_{k \to \infty} x^k = a$ ou $x^k \xrightarrow{k \to \infty} a$.

</details>

---

Quel est le lien entre la convergence d'une suite de vecteurs dans $\mathbb{R}^n$ et la convergence de ses composantes ?

<details>

<summary>Réponse</summary>

C'est une propriété fondamentale et très utile : une suite de vecteurs converge si et seulement si chacune de ses suites de composantes converge.

Soit une suite de vecteurs $x^k = (x_1^k, x_2^k, \dots, x_n^k)$ et un vecteur limite $a = (a_1, a_2, \dots, a_n)$. On a l'équivalence suivante :

$$ \lim_{k \to \infty} x^k = a \quad \iff \quad \forall j \in \{1, \dots, n\}, \quad \lim_{k \to \infty} x_j^k = a_j $$

**Explication :**

Cette propriété permet de ramener l'étude de la convergence d'une suite dans l'espace $\mathbb{R}^n$ à l'étude de $n$ suites de nombres réels, ce que l'on sait déjà faire.

**Preuve (idée) :**

Cette équivalence découle directement des inégalités liant une norme (par exemple la norme infinie) aux composantes.

Pour tout $j \in \{1, \dots, n\}$ :

$$ |x_j^k - a_j| \le \max_{i=1,\dots,n} |x_i^k - a_i| = \|x^k - a\|_\infty $$

- Si $\|x^k - a\|_\infty \to 0$, alors chaque $|x_j^k - a_j| \to 0$, donc chaque composante converge.
- Inversement, si chaque $|x_j^k - a_j| \to 0$, alors leur maximum, $\|x^k - a\|_\infty$, tend aussi vers 0.

Comme toutes les normes sont équivalentes, le résultat est valable pour n'importe quelle norme.

</details>

---

Déterminez si la suite $x^k = \left( \frac{1}{k}, (-1)^k \right)$ converge dans $\mathbb{R}^2$.

<details>

<summary>Réponse</summary>

Pour déterminer si la suite de vecteurs $(x^k)$ converge, nous étudions la convergence de chacune de ses composantes.

Le vecteur au rang $k$ est $x^k = (x_1^k, x_2^k)$ avec :

-   $x_1^k = \frac{1}{k}$
-   $x_2^k = (-1)^k$

**1. Étude de la première composante :**

La suite $(x_1^k) = (\frac{1}{k})_{k \ge 1}$ est une suite réelle de référence. On sait que :

$$ \lim_{k \to \infty} x_1^k = \lim_{k \to \infty} \frac{1}{k} = 0 $$

La première composante converge vers $0$.

**2. Étude de la deuxième composante :**

La suite $(x_2^k) = ((-1)^k)_{k \in \mathbb{N}}$ est la suite qui alterne entre $-1$ (pour $k$ impair) et $1$ (pour $k$ pair). Cette suite n'admet pas de limite ; elle est divergente.

**Conclusion :**

Pour qu'une suite de vecteurs converge, **toutes** ses composantes doivent converger. Puisque la deuxième composante de $(x^k)$ ne converge pas, la suite de vecteurs $(x^k)$ **ne converge pas** dans $\mathbb{R}^2$.

</details>

---

Qu'est-ce qu'une suite de Cauchy dans $\mathbb{R}^n$ ?

<details>

<summary>Réponse</summary>

Une suite de vecteurs $(x^k)_{k \in \mathbb{N}}$ dans $\mathbb{R}^n$ est dite **de Cauchy** si ses termes se rapprochent arbitrairement les uns des autres à mesure que leurs indices augmentent.

Formellement, cela signifie que pour toute "marge d'erreur" $\varepsilon > 0$, on peut trouver un rang $k_\varepsilon$ à partir duquel la distance entre n'importe quels deux termes de la suite est plus petite que $\varepsilon$.

$$ \forall \varepsilon > 0, \quad \exists k_\varepsilon \in \mathbb{N} \text{ tel que } \forall p, q \ge k_\varepsilon, \quad \|x^p - x^q\| < \varepsilon $$

**Intuition :**

La suite se "contracte" ou "se concentre" sur elle-même. Contrairement à la définition de la convergence, celle-ci ne fait pas référence à une potentielle limite $a$. C'est un critère **intrinsèque** à la suite.

</details>

---

Quelle est la relation fondamentale entre une suite de Cauchy et une suite convergente dans $\mathbb{R}^n$ ?

<details>

<summary>Réponse</summary>

Dans l'espace $\mathbb{R}^n$, les notions de suite de Cauchy et de suite convergente sont équivalentes.

1.  **Toute suite convergente est une suite de Cauchy.**
    -   **Idée :** Si les termes de la suite se rapprochent tous d'une même limite $a$, alors par l'inégalité triangulaire, ils doivent nécessairement se rapprocher les uns des autres.

2.  **Toute suite de Cauchy est une suite convergente.**
    -   **Idée :** Si les termes de la suite se "contractent" indéfiniment, ils ne peuvent le faire qu'autour d'un point limite qui doit exister dans l'espace.

Ce deuxième point est une propriété très importante appelée la **complétude** de $\mathbb{R}^n$. Un espace vectoriel normé où toute suite de Cauchy converge est dit **complet** (ou un **espace de Banach**).

**En résumé :**

Dans $\mathbb{R}^n$, une suite est de Cauchy si et seulement si elle est convergente.

</details>
